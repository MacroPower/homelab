"""
This file was generated by the KCL auto-gen tool. DO NOT EDIT.
Editing this file might prove futile when you re-run the KCL auto-gen generate command.
"""

schema Values:
    r"""
    Values

    Attributes
    ----------
    affinity : ValuesAffinity, optional
        # Assign a group of affinity scheduling rules
        #
    alloy : ValuesAlloy, optional
        # Various Alloy settings. For backwards compatibility with the grafana-agent
        # chart, this field may also be called "agent". Naming this field "agent" is
        # deprecated and will be removed in a future release.
    "alloy-logs" : ValuesAlloyLogs, optional
        An Alloy instance for collecting log data.
        To see all valid settings, please see the [Alloy Collector documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/collectors/alloy.md).
    "alloy-metrics" : ValuesAlloyMetrics, optional
        An Alloy instance for collecting metrics.
        To see all valid settings, please see the [Alloy Collector documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/collectors/alloy.md).
    "alloy-operator" : ValuesAlloyOperator, optional
        The Alloy Operator is a Kubernetes Operator that manages Alloy instances and their lifecycle.
        To see all valid settings, please see the [Alloy Operator documentation](https://github.com/grafana/alloy-operator/tree/main/charts/alloy-operator).
    "alloy-profiles" : ValuesAlloyProfiles, optional
        An Alloy instance for gathering profiles.
        To see all valid settings, please see the [Alloy Collector documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/collectors/alloy.md).
    "alloy-receiver" : ValuesAlloyReceiver, optional
        An Alloy instance for opening receivers to collect application data.
        To see all valid settings, please see the [Alloy Collector documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/collectors/alloy.md).
    "alloy-singleton" : ValuesAlloySingleton, optional
        An Alloy instance for data sources required to be deployed on a single replica.
        To see all valid settings, please see the [Alloy Collector documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/collectors/alloy.md).
    annotationAutodiscovery : ValuesAnnotationAutodiscovery, optional
        Annotation Autodiscovery enables gathering metrics from Kubernetes Pods and Services discovered by special annotations.
        Requires a destination that supports metrics.
        To see the valid options, please see the [Annotation Autodiscovery feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-annotation-autodiscovery).
    annotations : [any | ValuesAnnotations], optional
        Annotations to add to the Alloy Custom Resource. These annotations are not added to the workload or Pod.
    apiServer : ValuesApiServer, optional
        API Server metrics gather information about the Kubernetes API Server.
    applicationObservability : ValuesApplicationObservability, optional
        Application Observability.
        Requires destinations that supports metrics, logs, and traces.
        To see the valid options, please see the [Application Observability feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-application-observability).
    auth : ValuesAuth, optional
    autoInstrumentation : ValuesAutoInstrumentation, optional
        Auto-Instrumentation.
        Requires destinations that supports metrics, logs, and traces.
        To see the valid options, please see the [Auto-Instrumentation feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-auto-instrumentation).
    automountServiceAccountToken : bool, optional, default is True
        If false then the user will opt out of automounting API credentials.
    autosharding : ValuesAutosharding, optional
        If set to true, this will deploy kube-state-metrics as a StatefulSet and the data
        will be automatically sharded across <.Values.replicas> pods using the built-in
        autodiscovery feature: https://github.com/kubernetes/kube-state-metrics#automated-sharding
        This is an experimental feature and there are no stability guarantees.
    batchSize : str, optional
        Maximum batch size of logs to accumulate before sending.
    batchWait : str, optional
        Maximum amount of time to wait before sending a batch.
    bearerToken : ValuesBearerToken, optional
        Sets bearer_token_file line in the prometheus.scrape annotation_autodiscovery.
    beyla : ValuesBeyla, optional
    cadvisor : ValuesCadvisor, optional
        cAdvisor metrics gather information about containers on each node.
    canMount : ValuesCanMount, optional
    "cert-manager" : ValuesCertManager, optional
        Scrape metrics/logs from cert-manager
    cluster : ValuesCluster, optional
        yamllint disable rule:line-length rule:comments-indentation
    clusterEvents : ValuesClusterEvents, optional
        Cluster events.
        Requires a destination that supports logs.
        To see the valid options, please see the [Cluster Events feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-cluster-events).
    clusterLabels : [str], optional
        Labels to be set with the cluster name as the value.
    clusterMetrics : ValuesClusterMetrics, optional
        Cluster Monitoring enables observability and monitoring for your Kubernetes Cluster itself.
        Requires a destination that supports metrics.
        To see the valid options, please see the [Cluster Monitoring feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-cluster-metrics).
    clusterName : str, optional, default is "cluster.local"
        Override the default name of cluster - Can be found in /etc/kubernetes/admin.conf: clusters -> cluster -> name
    collectorCommon : ValuesCollectorCommon, optional
    collectors : [str], optional
        Available collectors for kube-state-metrics.
        By default, all available resources are enabled, comment out to disable.
    commonLabels : ValuesCommonLabels, optional
        # Extra labels to attach to all resources (can be templated)
    config : str | ValuesConfig, optional, default is "collectors:\n  enabled: '[defaults],memory,container'"
        The configuration for this destination.
        @ section -- General
    configReloader : ValuesConfigReloader, optional
        Options for the extra controller used for config reloading.
    configmaps : [any], optional
        # Additional configmaps to be mounted.
        #
    connectors : ValuesConnectors, optional
        Connectors are components that create new telemetry data from existing telemetry data.
    containerSecurityContext : ValuesContainerSecurityContext, optional
        # Specify security settings for a Container
        # Allows overrides and additional options compared to (Pod) securityContext
        # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
    containers : [any], optional
        # Containers allows injecting additional containers.
    contextPropagation : ValuesContextPropagation, optional
        Enables context propagation support.
    controlPlane : ValuesControlPlane, optional
    controller : ValuesController, optional
    crds : ValuesCrds, optional
        Skip installation of the Grafana Alloy CRDs, since we don't use them in this chart
    customLabels : ValuesCustomLabels, optional
        # Additional labels to add to all resources
    customResourceState : ValuesCustomResourceState, optional
        Enabling support for customResourceState, will create a configMap including your config that will be read from kube-state-metrics
    daemonsetAnnotations : ValuesDaemonsetAnnotations, optional
        Annotations to be added to windows exporter daemonset
    "dcgm-exporter" : ValuesDcgmExporter, optional
        Scrape metrics/logs from DCGM Exporter
    deployAsConfigMap : bool, optional, default is False
    destinations : [any], optional
        The list of destinations where telemetry data will be sent.
        See the [destinations documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/destinations/README.md) for more information.
    destinationsMap : ValuesDestinationsMap, optional
        A map of destinations where telemetry data will be sent. Keys will be used as the destination name.
        See the [destinations documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/destinations/README.md) for more information.
    dnsConfig : ValuesDnsConfig, optional
        Custom DNS configuration to be added to prometheus-windows-exporter pods
    dnsPolicy : str, optional, default is "ClusterFirst"
        # dnsPolicy allows to change the default DNS configuration for the pod
        # Ref: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy
    ebpf : ValuesEbpf, optional
        Settings for gathering profiles using eBPF
    ecosystem : str, optional
        The ecosystem for this destination. By setting this ecosystem, matching telemetry data sources might be
        auto-assigned to this destination. Options: `loki`, `otlp`, `prometheus`, `pyroscope`
        @ section -- General
    enabled : bool, optional
        Enable this Alloy instance.
    endpoints : [any], optional
        for deployments that have node_exporter deployed outside of the cluster, list
        their addresses here
    env : any | ValuesEnv, optional
        Additional environment variables that will be passed to the daemonset
    envValueFrom : ValuesEnvValueFrom, optional
        extra environment variables to be set from resources such as k8s configMaps/secrets
    etcd : ValuesEtcd, optional
        Scrape metrics/logs from etcd
    excludeLevels : [any], optional
        List of event levels to ignore. e.g. `["Normal", "Warning"]`
    excludeNamespaces : [any], optional
        Do not capture logs from any pods in these namespaces.
    excludeReasons : [any], optional
        List of event reasons to ignore. e.g. `["Pulling", "Started"]`
    exporter : ValuesExporter, optional
        Settings for the Alloy embedded MySQL Exporter
    extraArgs : [any], optional
        # Additional container arguments
        #
    extraCapabilities : [any], optional
        Extra capabilities for unprivileged / less privileged setup.
    extraConfig : str, optional
        Extra Alloy configuration to be added to the configuration file.
    extraDiscoveryRules : str, optional, default is ""
        Rules to filter pods for log gathering. Only used for "volumes" or "kubernetesApi" gather methods.
    extraEnvVars : ValuesExtraEnvVars, optional
        Extra environment variables
    extraHeaders : ValuesExtraHeaders, optional
        Extra headers to be set when sending data.
        All values are treated as strings and automatically quoted.
    extraHeadersFrom : ValuesExtraHeadersFrom, optional
        Extra headers to be set when sending data through a dynamic reference.
        All values are treated as raw strings and not quoted.
    extraHostVolumeMounts : [any], optional
        # Additional mounts from the host to windows-exporter container
        #
    extraInitContainers : [any], optional
        # Additional InitContainers to initialize the pod
        #
    extraLabels : ValuesExtraLabels, optional
        Extra labels to be added to all profiles before delivering to the destination.
        All values are treated as strings and automatically quoted.
    extraLabelsFrom : ValuesExtraLabelsFrom, optional
        Extra labels to be added to all profiles using a dynamic reference before delivering to the destination.
        All values are treated as raw strings and not quoted.
    extraLogProcessingStages : str, optional, default is ""
        Stage blocks to be added to the loki.process component for pod logs.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/loki/loki.process/#blocks))
        This value is templated so that you can refer to other values from this file.
    extraManifests : [any], optional
        Extra manifests to deploy as an array
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for discovered pods and services.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    extraObjects : [any], optional
        Deploy additional manifest objects
    extraVolumeMounts : [any], optional
        # Extra volume mounts in the node-exporter container
    extraVolumes : [any], optional
        # Extra volumes to become available in the pod
    fieldSelectors : [any], optional
        Discover Tempo instances based on field selectors.
    filelogGatherSettings : ValuesFilelogGatherSettings, optional
    fullnameOverride : any, optional, default is ""
        Overrides the chart's computed fullname. Used to change the full prefix of
        resource names.
    gatherMethod : str, optional, default is "volumes"
        The method to gather pod logs. Options are "volumes", "filelog" (experimental), "kubernetesApi", "OpenShiftClusterLogForwarder" (experimental).
        DEPRECATION WARNING: The "kubernetesApi" gather method is deprecated and will be removed in a future release.
        Please use the podLogsViaKubernetesApi feature instead.
    global : ValuesGlobal, optional

        Global settings

    grafana : ValuesGrafana, optional
        Scrape metrics/logs from Grafana
    hostIPC : bool, optional, default is False
        Share the host ipc namespace
    hostNetwork : bool, optional, default is True
        Expose the service to the host network
    hostPID : bool, optional, default is True
        Share the host process ID namespace
    hostProcFsMount : ValuesHostProcFsMount, optional
        Mount the node's proc file system (/proc) at /host/proc in the container
    hostRootFsMount : ValuesHostRootFsMount, optional
        Mount the node's root file system (/) at /host/root in the container
    hostSysFsMount : ValuesHostSysFsMount, optional
        Mount the node's sys file system (/sys) at /host/sys in the container
    image : ValuesImage, optional
        Default values for prometheus-node-exporter.
        This is a YAML-formatted file.
        Declare variables to be passed into your templates.
    imagePullSecrets : [any], optional
        List of secret names to use for pulling the images
    includeDestinations : [any], optional
        Include the configuration components for these destinations. Configuration is already added for destinations used
        By enabled features on this collector. This is useful when referencing destinations in the extraConfig.
    includeLevels : [any], optional
        List of event levels to include (`[]` means allow all event levels). e.g. `["Normal", "Warning"]`
    includeReasons : [any], optional
        List of event reasons to include (`[]` means allow all event reasons). e.g. `["Failed"]`
    ingress : ValuesIngress, optional
    initContainers : [any], optional
        # InitContainers allows injecting additional initContainers.
    integrations : ValuesIntegrations, optional
        Service Integrations enables gathering telemetry data for common services and applications deployed to Kubernetes.
        To see the valid options, please see the [Service Integrations documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-integrations).
    java : ValuesJava, optional
    jobLabel : str, optional, default is "integrations/kubernetes/eventhandler"
        The value of the job label for scraped metrics and logs
    journal : ValuesJournal, optional
    k8sCache : ValuesK8SCache, optional
        Options to deploy the Kubernetes metadata cache as a separate service
    kepler : ValuesKepler, optional
        Kepler gathers energy metrics for the Kubernetes Cluster and the objects running inside.
    "kube-state-metrics" : ValuesKubeStateMetrics, optional
        kube-state-metrics metrics gather information about Kubernetes resources.
    kubeControllerManager : ValuesKubeControllerManager, optional
        Metrics from the Kube Controller Manager
    kubeDNS : ValuesKubeDns, optional
        Metrics from the KubeDNS
    kubeProxy : ValuesKubeProxy, optional
        Metrics from the Kube Proxy
    kubeRBACProxy : ValuesKubeRbacproxy, optional
        Configure kube-rbac-proxy. When enabled, creates a kube-rbac-proxy to protect the node-exporter http endpoint.
        The requests are served through the same service but requests are HTTPS.
    kubeScheduler : ValuesKubeScheduler, optional
        Metrics from the Kube Scheduler
    kubeconfig : ValuesKubeconfig, optional
        Enabling kubeconfig will pass the --kubeconfig argument to the container
    kubelet : ValuesKubelet, optional
        Kubelet metrics gather information about Kubernetes information on each node.
    kubeletProbes : ValuesKubeletProbes, optional
        Kubelet Probe metrics gather information about liveness and readiness probe information.
    kubeletResource : ValuesKubeletResource, optional
        Kubelet Resource metrics gather information about resource information on each node.
    labelSelectors : ValuesLabelSelectors, optional
        Filter the list of discovered pods and services by labels. Only for the "volumes" gather method.
        Example: `labelSelectors: { 'app': 'myapp' }` will only discover pods with the label `app=myapp`.
        Example: `labelSelectors: { 'app': ['myapp', 'myotherapp'] }` will only discover pods with the label `app=myapp` or `app=myotherapp`.
    labels : [any | ValuesLabels], optional
        Labels to add to the Alloy Custom Resource. These labels are not added to the workload or Pod.
    labelsToKeep : [str], optional
        The list of labels to keep on the logs, all other pipeline labels will be dropped.
    leaderElection : ValuesLeaderElection, optional
        Leader election settings.
    liveDebugging : ValuesLiveDebugging, optional
    livenessProbe : ValuesLivenessProbe, optional
        # Liveness probe
        #
    logFormat : str, optional, default is "logfmt"
        Log format used to forward cluster events. Allowed values: `logfmt` (default), `json`.
    logProcessingRules : str, optional
        Rule blocks to be evaluated before printing the log messages to the standard output. See
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/loki/loki.relabel/#rule)) for more information.
    logProcessingStages : str, optional
        Stage blocks to be evaluated before delivering to the Loki destination. See
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/loki/loki.process/#blocks)) for more information.
    logging : ValuesLogging, optional
    loglevel : str, optional, default is "info"
    logs : ValuesLogs, optional
        Settings for log gathering using the Pod Logs feature
    loki : ValuesLoki, optional
        Scrape metrics/logs from Loki
    maxBackoffPeriod : str, optional
        The maximum backoff period for the Pyroscope destination.
    maxBackoffRetries : int, optional
        The maximum number of backoff retries for the Pyroscope destination.
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for cadvisor prometheus.relabel component.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides global.maxCacheSize
    metricAllowlist : [any], optional
        Comma-separated list of metrics to be exposed.
        This list comprises of exact metric names and/or regex patterns.
        The allowlist and denylist are mutually exclusive.
    metricAnnotationsAllowList : [any], optional
        Comma-separated list of Kubernetes annotations keys that will be used in the resource'
        labels metric. By default the metric contains only name and namespace labels.
        To include additional annotations provide a list of resource names in their plural form and Kubernetes
        annotation keys you would like to allow for them (Example: '=namespaces=[kubernetes.io/team,...],pods=[kubernetes.io/team],...)'.
        A single '*' can be provided per resource instead to allow any annotations, but that has
        severe performance implications (Example: '=pods=[*]').
    metricDenylist : [any], optional
        Comma-separated list of metrics not to be enabled.
        This list comprises of exact metric names and/or regex patterns.
        The allowlist and denylist are mutually exclusive.
    metricLabelsAllowlist : [any], optional
        Comma-separated list of additional Kubernetes label keys that will be used in the resource's
        labels metric. By default the metric contains only name and namespace labels.
        To include additional labels, provide a list of resource names in their plural form and Kubernetes
        label keys you would like to allow for them (Example: '=namespaces=[k8s-label-1,k8s-label-n,...],pods=[app],...)'.
        A single '*' can be provided per resource instead to allow any labels, but that has
        severe performance implications (Example: '=pods=[*]').
    metricProcessingRules : str, optional
        Rule blocks to apply to all metrics. Uses the [write_relabel_config block](https://grafana.com/docs/alloy/latest/reference/components/prometheus.remote_write/#write_relabel_config-block)
        of the prometheus.remote_write component. Format:
        write_relabel_config {
          source_labels = ["..."]
          action = "..."
          ...
        }
    metrics : ValuesMetrics, optional
        Settings for metrics collection
    metricsTuning : ValuesMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of metrics sent to storage.
    mimir : ValuesMimir, optional
        Scrape metrics/logs from Mimir
    minBackoffPeriod : str, optional
        The minimum backoff period for the Pyroscope destination.
    modelServer : ValuesModelServer, optional
        Configure kepler [model-server](https://sustainable-computing.io/kepler_model_server/get_started/)
    mysql : ValuesMysql, optional
        Scrape metrics/logs from MySQL
    name : str, optional
        The name for this Pyroscope destination.
    nameOverride : any, optional, default is ""
        Overrides the chart's name. Used to change the infix in the resource names.
    namespaceAnnotations : ValuesNamespaceAnnotations, optional
        Log labels to set with values copied from the Kubernetes Namespace annotations.
        Only used for "filelog" gather method.
        Format: `<log_label>: <kubernetes_namespace_annotation>`.
    namespaceLabels : ValuesNamespaceLabels, optional
        Log labels to set with values copied from the Kubernetes Namespace labels.
        Only used for "filelog" gather method.
        Format: `<log_label>: <kubernetes_namespace_label>`.
    namespaceOverride : any, optional, default is ""
        Overrides the chart's namespace.
    namespaces : [any], optional
        Only capture logs from pods in these namespaces (`[]` means all namespaces).
    namespacesDenylist : str, optional, default is ""
        Comma-separated list of namespaces not to be enabled. If namespaces and namespaces-denylist are both set,
        only namespaces that are excluded in namespaces-denylist will be used.
    networkPolicies : ValuesNetworkPolicies, optional
        NetworkPolicies for ingress
    networkPolicy : ValuesNetworkPolicy, optional
        Set a NetworkPolicy with:
        ingress only on service.port or custom policy
        no egress permitted
    noProxy : str, optional
        Comma-separated list of IP addresses, CIDR notations, and domain names to exclude from proxying.
    "node-exporter" : ValuesNodeExporter, optional
        Node Exporter metrics gathers hardware information about Linux nodes.
    nodeAnnotations : ValuesNodeAnnotations, optional
        Log labels to set with values copied from the Kubernetes Node annotations.
        Only used for "filelog" gather method.
        Format: `<log_label>: <kubernetes_node_annotation>`.
    nodeLabels : ValuesNodeLabels, optional
        Log labels to set with values copied from the Kubernetes Node labels.
        Only used for "filelog" gather method.
        Format: `<log_label>: <kubernetes_node_label>`.
    nodeLogs : ValuesNodeLogs, optional
        Node logs.
        Requires a destination that supports logs.
        To see the valid options, please see the [Node Logs feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-node-logs).
    nodeSelector : ValuesNodeSelector, optional
        # Assign a nodeSelector if operating a hybrid cluster
        #
    nodeSelectors : ValuesNodeSelectors, optional
        Filter the list of discovered nodes by labels. Only for the "volumes" gather method.
        Example: `nodeSelectors: { 'kubernetes.io/os': 'linux' }`
    openTelemetryConversion : ValuesOpenTelemetryConversion, optional
        Settings for converting OpenTelemetry ecosystem metrics to Prometheus ecosystem metrics.
    opencost : ValuesOpencost, optional
        OpenCost gathers cost metrics for the Kubernetes Cluster and the objects running inside.
    ownNamespaceOnly : bool, optional, default is False
        Restrict the Alloy Operator to its own namespace only. Overrides the `namespaces` setting.
    pdb : ValuesPdb, optional
        PodDisruptionBudget for high availability
    plugins : ValuesPlugins, optional
    podAnnotations : ValuesPodAnnotations, optional
        Annotations to be added to windows exporter pods
    podAutomountServiceAccountToken : bool, optional, default is True
         Enable automounting of service account token at the pod level
    podDisruptionBudget : ValuesPodDisruptionBudget, optional
        Ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
    podLabels : ValuesPodLabels, optional
        Extra labels to be added to windows exporter pods
    podLogs : ValuesPodLogs, optional
        Pod logs.
        Requires a destination that supports logs.
        To see the valid options, please see the [Pod Logs feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-pod-logs).
    podLogsViaKubernetesApi : ValuesPodLogsViaKubernetesApi, optional
        Pod logs via Kubernetes API.
        Requires a destination that supports logs.
        To see the valid options, please see the [Pod Logs via Kubernetes API feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-pod-logs-via-kubernetes-api).
    podMonitors : ValuesPodMonitors, optional
        Prometheus Operator PodMonitors
    podSecurityContext : ValuesPodSecurityContext, optional
        Holds pod-level security attributes and common container settings
    pods : ValuesPods, optional
    port : int, optional, default is 4040
        Port number on which the server listens for new connections.
    pprof : ValuesPprof, optional
    preset : str, optional, default is "application"
        Preconfigures some default properties for network or application observability.
        Accepted values are "network" or "application".
    priorityClassName : any, optional, default is "~"
         Pod priority
    privileged : bool, optional, default is True
        If set to false, deploys an unprivileged / less privileged setup.
    probes : ValuesProbes, optional
        Prometheus Operator Probes
    processors : ValuesProcessors, optional
        Processors to apply to the data before delivering it to its destination.
    profileProcessingRules : str, optional, default is ""
        Rule blocks to be added to the pyroscope.relabel component for received profiles.
        These relabeling rules are applied to profiles received by this feature.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/pyroscope/pyroscope.relabel/#rule))
    profiles : ValuesProfiles, optional
    profilesReceiver : ValuesProfilesReceiver, optional
        Profiles Receiver enables receiving profiles from applications.
        Requires a destination that supports profiles.
        To see the valid options, please see the [Profiles Receiver feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-profiles-receiver).
    profiling : ValuesProfiling, optional
        Profiling enables gathering profiles from applications.
        Requires a destination that supports profiles.
        To see the valid options, please see the [Profiling feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-profiling).
    prometheus : ValuesPrometheus, optional
    prometheusOperatorObjects : ValuesPrometheusOperatorObjects, optional
        Prometheus Operator Objects enables the gathering of metrics from objects like Probes, PodMonitors, and
        ServiceMonitors. Requires a destination that supports metrics.
        To see the valid options, please see the [Prometheus Operator Objects feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-prometheus-operator-objects).
    prometheusScrape : bool, optional, default is True
        Default values for kube-state-metrics.
    $protocol : str, optional
        The protocol for the OTLP destination.
        Options are "grpc" (default), "http".
    proxyConnectHeader : ValuesProxyConnectHeader, optional
        Specifies headers to send to proxies during CONNECT requests.
    proxyFromEnvironment : bool, optional
        Use the proxy URL indicated by environment variables.
    proxyURL : str, optional
        HTTP proxy to send requests through.
    queueConfig : ValuesQueueConfig, optional
    rbac : ValuesRbac, optional
        Create cluster role policies
    readBufferSize : str, optional
        Size of the read buffer the gRPC client to use for reading server responses.
    readinessProbe : ValuesReadinessProbe, optional
        # Readiness probe
        #
    receivers : ValuesReceivers, optional
    redfish : ValuesRedfish, optional
    releaseLabel : bool, optional, default is False
        # set to true to add the release label so scraping of the servicemonitor with kube-prometheus-stack works out of the box
    releaseNamespace : bool, optional, default is False
        Enable only the release namespace for collecting resources. By default all namespaces are collected.
        If releaseNamespace and namespaces are both set a merged list will be collected.
    remoteConfig : ValuesRemoteConfig, optional
        Remote configuration from a remote config server.
    replicaCount : int, optional, default is 1
        How many replicas to use for the Alloy Operator Deployment.
    replicas : int, optional, default is 1
    resources : ValuesResources, optional
        CPU/MEM resources
    restartPolicy : any, optional, default is "null"
        Specify the container restart policy passed to the Node Export container
        Possible Values: Always (default)|OnFailure|Never
    retryOnFailure : ValuesRetryOnFailure, optional
    revisionHistoryLimit : int, optional, default is 10
        Number of old history to retain to allow rollback
        Default Kubernetes value is set to 10
    scrapeInterval : str, optional, default is ""
        How frequently to scrape metrics from discovered pods and services. Only used if the `k8s.grafana.com/metrics.scrapeInterval` annotation is not set.
        Overrides global.scrapeInterval
    scrapeTimeout : str, optional, default is ""
        The scrape timeout for discovered pods and services. Only used if the `k8s.grafana.com/metrics.scrapeTimeout` annotation is not set.
        Overrides global.scrapeTimeout
    secret : ValuesSecret, optional
    secretAnnotations : ValuesSecretAnnotations, optional
         Annotations to add to the Secret
    secretFilter : ValuesSecretFilter, optional
        Check logs for secrets and mask them.
    secrets : [any], optional
        - name: <configMapName>
          mountPath: <mountPath>
    securityContext : ValuesSecurityContext, optional
        Privileges and access control settings for a container
    selectorOverride : ValuesSelectorOverride, optional
        # Override selector labels
    selfMonitor : ValuesSelfMonitor, optional
        Enable self metrics configuration for service and Service Monitor
        Default values for telemetry configuration can be overridden
        If you set telemetryNodePort, you must also set service.type to NodePort
    selfReporting : ValuesSelfReporting, optional
        Self-reporting creates a single metric and log that reports anonymized information about how this Helm chart was
        configured. It reports features enabled, destinations types used, and alloy instances enabled. It does not report any
        actual telemetry data, credentials or configuration, or send any data to any destination other than the ones
        configured above.
    sendNativeHistograms : bool, optional
        Whether native histograms should be sent.
    service : ValuesService, optional
        # Service configuration
    serviceAccount : ValuesServiceAccount, optional
        Service Account settings
    serviceMonitor : ValuesServiceMonitor, optional
        Enable creation of ServiceMonitor for scraping of prometheus HTTP endpoint
    serviceMonitors : ValuesServiceMonitors, optional
        Prometheus Operator ServiceMonitors
    services : ValuesServices, optional
    sidecarHostVolumeMounts : [any], optional
        # Additional mounts from the host to sidecar containers
        #
    sidecarVolumeMount : [any], optional
        # Volume for sidecar containers
        #
    sidecars : [any], optional
        # Additional containers for export metrics to text file
        #
    startupProbe : ValuesStartupProbe, optional
        # Startup probe can optionally be enabled.
        #
    staticLabels : ValuesStaticLabels, optional
        Log labels to set with static values.
    staticLabelsFrom : ValuesStaticLabelsFrom, optional
        Log labels to set with static values, not quoted so it can reference config components.
    structuredMetadata : ValuesStructuredMetadata, optional
        The structured metadata mappings to set.
        Format: `<key>: <extracted_key>`.
        Example:
        structuredMetadata:
          component: component
          kind: kind
          name: name
    tempo : ValuesTempo, optional
        Scrape metrics/logs from Tempo
    tenantId : str, optional
        The tenant ID for the Pyroscope destination.
    tenantIdFrom : str, optional
        Raw config for accessing the tenant ID.
    tenantIdKey : str, optional
        The key for storing the tenant ID in the secret.
    terminationGracePeriodSeconds : any, optional, default is "null"
        Specify grace period for graceful termination of pods. Defaults to 30 if null or not specified
    terminationMessageParams : ValuesTerminationMessageParams, optional
        Enable or disable container termination message settings
        https://kubernetes.io/docs/tasks/debug/debug-application/determine-reason-pod-failure/
    tls : ValuesTls, optional
    tlsSecret : ValuesTlsSecret, optional
        # tlsSecret refers to an existing secret holding TLS items: client CA certificate, private key and certificate.
        # secretName and volumeName can be templated.
        # If enabled, volume volumeName gets created on secret secretName.
        # The volume's resources will be used by kube-rbac-proxy if kubeRBACProxy.tls.enabled is set.
    tolerations : [ValuesTolerationsItems0], optional
        # Tolerations for pod assignment
        # Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    topologySpreadConstraints : [any], optional
        # Topology spread constraints for pod assignment
        # Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/
    traces : ValuesTraces, optional
    updateStrategy : ValuesUpdateStrategy, optional
        # Customize the updateStrategy if set
    url : str, optional
        The URL for the Pyroscope destination.
    urlFrom : str, optional
        Raw config for accessing the URL.
    version : str, optional, default is ""
        Override version of app, required if image.tag is defined and does not follow semver
    verticalPodAutoscaler : ValuesVerticalPodAutoscaler, optional
        Enable vertical pod autoscaler support for prometheus-node-exporter
    volumeGatherSettings : ValuesVolumeGatherSettings, optional
        Settings specific for gathering Pod logs using the "volumes" gather method.
    volumeMounts : [any], optional
        volumeMounts are used to add custom volume mounts to deployment.
        See example below
    volumes : [any], optional
        volumes are used to add custom volumes to deployment
        See example below
    "windows-exporter" : ValuesWindowsExporter, optional
        Windows Exporter metrics gathers hardware information about Windows nodes.
    writeAheadLog : ValuesWriteAheadLog, optional
        Write-Ahead Log (WAL) settings. Only applies when protocol is "remote_write"
    writeBufferSize : str, optional
        Size of the write buffer the gRPC client to use for writing requests.
    """
    [...str]: any
    affinity?: ValuesAffinity
    alloy?: ValuesAlloy
    "alloy-logs"?: ValuesAlloyLogs
    "alloy-metrics"?: ValuesAlloyMetrics
    "alloy-operator"?: ValuesAlloyOperator
    "alloy-profiles"?: ValuesAlloyProfiles
    "alloy-receiver"?: ValuesAlloyReceiver
    "alloy-singleton"?: ValuesAlloySingleton
    annotationAutodiscovery?: ValuesAnnotationAutodiscovery
    annotations?: [any | ValuesAnnotations]
    apiServer?: ValuesApiServer
    applicationObservability?: ValuesApplicationObservability
    auth?: ValuesAuth
    autoInstrumentation?: ValuesAutoInstrumentation
    automountServiceAccountToken?: bool
    autosharding?: ValuesAutosharding
    batchSize?: str
    batchWait?: str
    bearerToken?: ValuesBearerToken
    beyla?: ValuesBeyla
    cadvisor?: ValuesCadvisor
    canMount?: ValuesCanMount
    "cert-manager"?: ValuesCertManager
    cluster?: ValuesCluster
    clusterEvents?: ValuesClusterEvents
    clusterLabels?: [str]
    clusterMetrics?: ValuesClusterMetrics
    clusterName?: str
    collectorCommon?: ValuesCollectorCommon
    collectors?: [str]
    commonLabels?: ValuesCommonLabels
    config?: str | ValuesConfig
    configReloader?: ValuesConfigReloader
    configmaps?: [any]
    connectors?: ValuesConnectors
    containerSecurityContext?: ValuesContainerSecurityContext
    containers?: [any]
    contextPropagation?: ValuesContextPropagation
    controlPlane?: ValuesControlPlane
    controller?: ValuesController
    crds?: ValuesCrds
    customLabels?: ValuesCustomLabels
    customResourceState?: ValuesCustomResourceState
    daemonsetAnnotations?: ValuesDaemonsetAnnotations
    "dcgm-exporter"?: ValuesDcgmExporter
    deployAsConfigMap?: bool
    destinations?: [any]
    destinationsMap?: ValuesDestinationsMap
    dnsConfig?: ValuesDnsConfig
    dnsPolicy?: str
    ebpf?: ValuesEbpf
    ecosystem?: str
    enabled?: bool
    endpoints?: [any]
    env?: any | ValuesEnv
    envValueFrom?: ValuesEnvValueFrom
    etcd?: ValuesEtcd
    excludeLevels?: [any]
    excludeNamespaces?: [any]
    excludeReasons?: [any]
    exporter?: ValuesExporter
    extraArgs?: [any]
    extraCapabilities?: [any]
    extraConfig?: str
    extraDiscoveryRules?: str
    extraEnvVars?: ValuesExtraEnvVars
    extraHeaders?: ValuesExtraHeaders
    extraHeadersFrom?: ValuesExtraHeadersFrom
    extraHostVolumeMounts?: [any]
    extraInitContainers?: [any]
    extraLabels?: ValuesExtraLabels
    extraLabelsFrom?: ValuesExtraLabelsFrom
    extraLogProcessingStages?: str
    extraManifests?: [any]
    extraMetricProcessingRules?: str
    extraObjects?: [any]
    extraVolumeMounts?: [any]
    extraVolumes?: [any]
    fieldSelectors?: [any]
    filelogGatherSettings?: ValuesFilelogGatherSettings
    fullnameOverride?: any
    gatherMethod?: str
    global?: ValuesGlobal
    grafana?: ValuesGrafana
    hostIPC?: bool
    hostNetwork?: bool
    hostPID?: bool
    hostProcFsMount?: ValuesHostProcFsMount
    hostRootFsMount?: ValuesHostRootFsMount
    hostSysFsMount?: ValuesHostSysFsMount
    image?: ValuesImage
    imagePullSecrets?: [any]
    includeDestinations?: [any]
    includeLevels?: [any]
    includeReasons?: [any]
    ingress?: ValuesIngress
    initContainers?: [any]
    integrations?: ValuesIntegrations
    java?: ValuesJava
    jobLabel?: str
    journal?: ValuesJournal
    k8sCache?: ValuesK8SCache
    kepler?: ValuesKepler
    "kube-state-metrics"?: ValuesKubeStateMetrics
    kubeControllerManager?: ValuesKubeControllerManager
    kubeDNS?: ValuesKubeDns
    kubeProxy?: ValuesKubeProxy
    kubeRBACProxy?: ValuesKubeRbacproxy
    kubeScheduler?: ValuesKubeScheduler
    kubeconfig?: ValuesKubeconfig
    kubelet?: ValuesKubelet
    kubeletProbes?: ValuesKubeletProbes
    kubeletResource?: ValuesKubeletResource
    labelSelectors?: ValuesLabelSelectors
    labels?: [any | ValuesLabels]
    labelsToKeep?: [str]
    leaderElection?: ValuesLeaderElection
    liveDebugging?: ValuesLiveDebugging
    livenessProbe?: ValuesLivenessProbe
    logFormat?: str
    logProcessingRules?: str
    logProcessingStages?: str
    logging?: ValuesLogging
    loglevel?: str
    logs?: ValuesLogs
    loki?: ValuesLoki
    maxBackoffPeriod?: str
    maxBackoffRetries?: int
    maxCacheSize?: any
    metricAllowlist?: [any]
    metricAnnotationsAllowList?: [any]
    metricDenylist?: [any]
    metricLabelsAllowlist?: [any]
    metricProcessingRules?: str
    metrics?: ValuesMetrics
    metricsTuning?: ValuesMetricsTuning
    mimir?: ValuesMimir
    minBackoffPeriod?: str
    modelServer?: ValuesModelServer
    mysql?: ValuesMysql
    name?: str
    nameOverride?: any
    namespaceAnnotations?: ValuesNamespaceAnnotations
    namespaceLabels?: ValuesNamespaceLabels
    namespaceOverride?: any
    namespaces?: [any]
    namespacesDenylist?: str
    networkPolicies?: ValuesNetworkPolicies
    networkPolicy?: ValuesNetworkPolicy
    noProxy?: str
    "node-exporter"?: ValuesNodeExporter
    nodeAnnotations?: ValuesNodeAnnotations
    nodeLabels?: ValuesNodeLabels
    nodeLogs?: ValuesNodeLogs
    nodeSelector?: ValuesNodeSelector
    nodeSelectors?: ValuesNodeSelectors
    openTelemetryConversion?: ValuesOpenTelemetryConversion
    opencost?: ValuesOpencost
    ownNamespaceOnly?: bool
    pdb?: ValuesPdb
    plugins?: ValuesPlugins
    podAnnotations?: ValuesPodAnnotations
    podAutomountServiceAccountToken?: bool
    podDisruptionBudget?: ValuesPodDisruptionBudget
    podLabels?: ValuesPodLabels
    podLogs?: ValuesPodLogs
    podLogsViaKubernetesApi?: ValuesPodLogsViaKubernetesApi
    podMonitors?: ValuesPodMonitors
    podSecurityContext?: ValuesPodSecurityContext
    pods?: ValuesPods
    port?: int
    pprof?: ValuesPprof
    preset?: str
    priorityClassName?: any
    privileged?: bool
    probes?: ValuesProbes
    processors?: ValuesProcessors
    profileProcessingRules?: str
    profiles?: ValuesProfiles
    profilesReceiver?: ValuesProfilesReceiver
    profiling?: ValuesProfiling
    prometheus?: ValuesPrometheus
    prometheusOperatorObjects?: ValuesPrometheusOperatorObjects
    prometheusScrape?: bool
    $protocol?: str
    proxyConnectHeader?: ValuesProxyConnectHeader
    proxyFromEnvironment?: bool
    proxyURL?: str
    queueConfig?: ValuesQueueConfig
    rbac?: ValuesRbac
    readBufferSize?: str
    readinessProbe?: ValuesReadinessProbe
    receivers?: ValuesReceivers
    redfish?: ValuesRedfish
    releaseLabel?: bool
    releaseNamespace?: bool
    remoteConfig?: ValuesRemoteConfig
    replicaCount?: int
    replicas?: int
    resources?: ValuesResources
    restartPolicy?: any
    retryOnFailure?: ValuesRetryOnFailure
    revisionHistoryLimit?: int
    scrapeInterval?: str
    scrapeTimeout?: str
    secret?: ValuesSecret
    secretAnnotations?: ValuesSecretAnnotations
    secretFilter?: ValuesSecretFilter
    secrets?: [any]
    securityContext?: ValuesSecurityContext
    selectorOverride?: ValuesSelectorOverride
    selfMonitor?: ValuesSelfMonitor
    selfReporting?: ValuesSelfReporting
    sendNativeHistograms?: bool
    service?: ValuesService
    serviceAccount?: ValuesServiceAccount
    serviceMonitor?: ValuesServiceMonitor
    serviceMonitors?: ValuesServiceMonitors
    services?: ValuesServices
    sidecarHostVolumeMounts?: [any]
    sidecarVolumeMount?: [any]
    sidecars?: [any]
    startupProbe?: ValuesStartupProbe
    staticLabels?: ValuesStaticLabels
    staticLabelsFrom?: ValuesStaticLabelsFrom
    structuredMetadata?: ValuesStructuredMetadata
    tempo?: ValuesTempo
    tenantId?: str
    tenantIdFrom?: str
    tenantIdKey?: str
    terminationGracePeriodSeconds?: any
    terminationMessageParams?: ValuesTerminationMessageParams
    tls?: ValuesTls
    tlsSecret?: ValuesTlsSecret
    tolerations?: [ValuesTolerationsItems0]
    topologySpreadConstraints?: [any]
    traces?: ValuesTraces
    updateStrategy?: ValuesUpdateStrategy
    url?: str
    urlFrom?: str
    version?: str
    verticalPodAutoscaler?: ValuesVerticalPodAutoscaler
    volumeGatherSettings?: ValuesVolumeGatherSettings
    volumeMounts?: [any]
    volumes?: [any]
    "windows-exporter"?: ValuesWindowsExporter
    writeAheadLog?: ValuesWriteAheadLog
    writeBufferSize?: str

schema ValuesAffinity:
    r"""
    # Assign a group of affinity scheduling rules
    #
    """
    [...str]: any

schema ValuesAlloy:
    r"""
    # Various Alloy settings. For backwards compatibility with the grafana-agent
    # chart, this field may also be called "agent". Naming this field "agent" is
    # deprecated and will be removed in a future release.

    Attributes
    ----------
    clustering : ValuesAlloyClustering, optional
    configMap : ValuesAlloyConfigMap, optional
    enableHttpServerPort : bool, optional
        Enables Grafana Alloy container's http server port.
    enableReporting : bool, optional
        Enables sending Grafana Labs anonymous usage stats to help improve Grafana
        Alloy.
    envFrom : [any], optional
        Maps all the keys on a ConfigMap or Secret as environment variables. https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#envfromsource-v1-core
    extraArgs : [any], optional
        Extra args to pass to `alloy run`: https://grafana.com/docs/alloy/latest/reference/cli/run/
    extraEnv : [any], optional
        Extra environment variables to pass to the Alloy container.
    extraPorts : [any], optional
        Extra ports to expose on the Alloy container.
    hostAliases : [any], optional
        Host aliases to add to the Alloy container.
    initialDelaySeconds : int, optional
        Initial delay for readiness probe.
    instances : [any], optional
    lifecycle : ValuesAlloyLifecycle, optional
        Set lifecycle hooks for the Grafana Alloy container.
    listenAddr : str, optional
        Address to listen for traffic on. 0.0.0.0 exposes the UI to other
        containers.
    listenPort : int, optional
        Port to listen for traffic on.
    listenScheme : str, optional
        Scheme is needed for readiness probes. If enabling tls in your configs, set to "HTTPS"
    livenessProbe : ValuesAlloyLivenessProbe, optional
        Set livenessProbe for the Grafana Alloy container.
    mounts : ValuesAlloyMounts, optional
    resources : ValuesAlloyResources, optional
        Resource requests and limits to apply to the Grafana Alloy container.
    securityContext : ValuesAlloySecurityContext, optional
        Security context to apply to the Grafana Alloy container.
    stabilityLevel : str, optional
        Minimum stability level of components and behavior to enable. Must be
        one of "experimental", "public-preview", or "generally-available".
    storagePath : str, optional
        Path to where Grafana Alloy stores data (for example, the Write-Ahead Log).
        By default, data is lost between reboots.
    timeoutSeconds : int, optional
        Timeout for readiness probe.
    uiPathPrefix : str, optional
         Base path where the UI is exposed.
    """
    [...str]: any
    clustering?: ValuesAlloyClustering
    configMap?: ValuesAlloyConfigMap
    enableHttpServerPort?: bool
    enableReporting?: bool
    envFrom?: [any]
    extraArgs?: [any]
    extraEnv?: [any]
    extraPorts?: [any]
    hostAliases?: [any]
    initialDelaySeconds?: int
    instances?: [any]
    lifecycle?: ValuesAlloyLifecycle
    listenAddr?: str
    listenPort?: int
    listenScheme?: str
    livenessProbe?: ValuesAlloyLivenessProbe
    mounts?: ValuesAlloyMounts
    resources?: ValuesAlloyResources
    securityContext?: ValuesAlloySecurityContext
    stabilityLevel?: str
    storagePath?: str
    timeoutSeconds?: int
    uiPathPrefix?: str

schema ValuesAlloyClustering:
    r"""
    ValuesAlloyClustering

    Attributes
    ----------
    enabled : bool, optional
        Deploy Alloy in a cluster to allow for load distribution.
    name : str, optional
        Name for the Alloy cluster. Used for differentiating between clusters.
    portName : str, optional
        Name for the port used for clustering, useful if running inside an Istio Mesh
    """
    [...str]: any
    enabled?: bool
    name?: str
    portName?: str

schema ValuesAlloyConfigMap:
    r"""
    ValuesAlloyConfigMap

    Attributes
    ----------
    content : str, optional
        Content to assign to the new ConfigMap.  This is passed into `tpl` allowing for templating from values.
    create : bool, optional
        Create a new ConfigMap for the config file.
    key : any, optional
        Key in ConfigMap to get config from.
    name : any, optional
        Name of existing ConfigMap to use. Used when create is false.
    """
    [...str]: any
    content?: str
    create?: bool
    key?: any
    name?: any

schema ValuesAlloyLifecycle:
    r"""
    Set lifecycle hooks for the Grafana Alloy container.
    """
    [...str]: any

schema ValuesAlloyLivenessProbe:
    r"""
    Set livenessProbe for the Grafana Alloy container.
    """
    [...str]: any

schema ValuesAlloyLogs:
    r"""
    An Alloy instance for collecting log data.
    To see all valid settings, please see the [Alloy Collector documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/collectors/alloy.md).

    Attributes
    ----------
    enabled : bool, optional, default is False
        Deploy the Alloy instance for collecting log data.
    """
    [...str]: any
    enabled?: bool

schema ValuesAlloyMetrics:
    r"""
    An Alloy instance for collecting metrics.
    To see all valid settings, please see the [Alloy Collector documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/collectors/alloy.md).

    Attributes
    ----------
    enabled : bool, optional, default is False
        Deploy the Alloy instance for collecting metrics.
    """
    [...str]: any
    enabled?: bool

schema ValuesAlloyMounts:
    r"""
    ValuesAlloyMounts

    Attributes
    ----------
    dockercontainers : bool, optional
        Mount /var/lib/docker/containers from the host into the container for log
        collection.
    extra : [any], optional
        Extra volume mounts to add into the Grafana Alloy container. Does not
        affect the watch container.
    varlog : bool, optional
        Mount /var/log from the host into the container for log collection.
    """
    [...str]: any
    dockercontainers?: bool
    extra?: [any]
    varlog?: bool

schema ValuesAlloyOperator:
    r"""
    The Alloy Operator is a Kubernetes Operator that manages Alloy instances and their lifecycle.
    To see all valid settings, please see the [Alloy Operator documentation](https://github.com/grafana/alloy-operator/tree/main/charts/alloy-operator).

    Attributes
    ----------
    deploy : bool, optional, default is True
        Deploy the Alloy Operator.
    waitForAlloyRemoval : ValuesAlloyOperatorWaitForAlloyRemoval, optional
    """
    [...str]: any
    deploy?: bool
    waitForAlloyRemoval?: ValuesAlloyOperatorWaitForAlloyRemoval

schema ValuesAlloyOperatorWaitForAlloyRemoval:
    r"""
    ValuesAlloyOperatorWaitForAlloyRemoval

    Attributes
    ----------
    enabled : bool, optional, default is True
        Utilize a Helm Hook to wait for all Alloy instances to be removed before uninstalling the Alloy Operator.
        This ensures that all Alloy instances are properly cleaned up before the operator is removed.
    image : ValuesAlloyOperatorWaitForAlloyRemovalImage, optional
        The image to use for the Helm Hook that ensures that Alloy instances are removed during uninstall.
    nodeSelector : ValuesAlloyOperatorWaitForAlloyRemovalNodeSelector, optional
        Node selector to use for the Helm Hook that ensures that Alloy instances are removed during uninstall.
    podAnnotations : ValuesAlloyOperatorWaitForAlloyRemovalPodAnnotations, optional
        Annotations to apply to the Pod for the Helm Hook to wait for all Alloy instances to be removed before
        uninstalling the Alloy Operator
    podLabels : ValuesAlloyOperatorWaitForAlloyRemovalPodLabels, optional
        Labels to apply to the Pod for the Helm Hook to wait for all Alloy instances to be removed before uninstalling
        the Alloy Operator
    tolerations : [any], optional
        Tolerations to apply to the Helm Hook that ensures that Alloy instances are removed during uninstall.
    """
    [...str]: any
    enabled?: bool
    image?: ValuesAlloyOperatorWaitForAlloyRemovalImage
    nodeSelector?: ValuesAlloyOperatorWaitForAlloyRemovalNodeSelector
    podAnnotations?: ValuesAlloyOperatorWaitForAlloyRemovalPodAnnotations
    podLabels?: ValuesAlloyOperatorWaitForAlloyRemovalPodLabels
    tolerations?: [any]

schema ValuesAlloyOperatorWaitForAlloyRemovalImage:
    r"""
    The image to use for the Helm Hook that ensures that Alloy instances are removed during uninstall.

    Attributes
    ----------
    digest : str, optional, default is ""
    pullPolicy : str, optional, default is "IfNotPresent"
    pullSecrets : [any], optional
    registry : str, optional, default is "ghcr.io"
    repository : str, optional, default is "grafana/helm-chart-toolbox-kubectl"
    tag : str, optional, default is "0.1.1"
    """
    [...str]: any
    digest?: str
    pullPolicy?: str
    pullSecrets?: [any]
    registry?: str
    repository?: str
    tag?: str

schema ValuesAlloyOperatorWaitForAlloyRemovalNodeSelector:
    r"""
    Node selector to use for the Helm Hook that ensures that Alloy instances are removed during uninstall.

    Attributes
    ----------
    "kubernetes.io/os" : str, optional, default is "linux"
    """
    [...str]: any
    "kubernetes.io/os"?: str

schema ValuesAlloyOperatorWaitForAlloyRemovalPodAnnotations:
    r"""
    Annotations to apply to the Pod for the Helm Hook to wait for all Alloy instances to be removed before
    uninstalling the Alloy Operator
    """
    [...str]: any

schema ValuesAlloyOperatorWaitForAlloyRemovalPodLabels:
    r"""
    Labels to apply to the Pod for the Helm Hook to wait for all Alloy instances to be removed before uninstalling
    the Alloy Operator

    Attributes
    ----------
    "linkerd.io/inject" : str, optional, default is "disabled"
    "sidecar.istio.io/inject" : str, optional, default is "false"
    """
    [...str]: any
    "linkerd.io/inject"?: str
    "sidecar.istio.io/inject"?: str

schema ValuesAlloyProfiles:
    r"""
    An Alloy instance for gathering profiles.
    To see all valid settings, please see the [Alloy Collector documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/collectors/alloy.md).

    Attributes
    ----------
    enabled : bool, optional, default is False
        Deploy the Alloy instance for gathering profiles.
    """
    [...str]: any
    enabled?: bool

schema ValuesAlloyReceiver:
    r"""
    An Alloy instance for opening receivers to collect application data.
    To see all valid settings, please see the [Alloy Collector documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/collectors/alloy.md).

    Attributes
    ----------
    alloy : ValuesAlloyReceiverAlloy, optional
    enabled : bool, optional, default is False
        Deploy the Alloy instance for opening receivers to collect application data.
    extraService : ValuesAlloyReceiverExtraService, optional
    """
    [...str]: any
    alloy?: ValuesAlloyReceiverAlloy
    enabled?: bool
    extraService?: ValuesAlloyReceiverExtraService

schema ValuesAlloyReceiverAlloy:
    r"""
    ValuesAlloyReceiverAlloy

    Attributes
    ----------
    extraPorts : [any], optional
        The ports to expose for the Alloy receiver.
    """
    [...str]: any
    extraPorts?: [any]

schema ValuesAlloyReceiverExtraService:
    r"""
    ValuesAlloyReceiverExtraService

    Attributes
    ----------
    enabled : bool, optional, default is False
        Create an extra service for the Alloy receiver. This service will mirror the alloy-receiver service, but its
        name can be customized to match existing application settings.
    fullname : str, optional, default is ""
        If set, the full name of the extra service to create. This will result in the format `<fullname>`.
    name : str, optional, default is "alloy"
        The name of the extra service to create. This will result in the format `<release-name>-<name>`.
    """
    [...str]: any
    enabled?: bool
    fullname?: str
    name?: str

schema ValuesAlloyResources:
    r"""
    Resource requests and limits to apply to the Grafana Alloy container.
    """
    [...str]: any

schema ValuesAlloySecurityContext:
    r"""
    Security context to apply to the Grafana Alloy container.

    Attributes
    ----------
    allowPrivilegeEscalation : bool, optional
    capabilities : ValuesAlloySecurityContextCapabilities, optional
    seccompProfile : ValuesAlloySecurityContextSeccompProfile, optional
    """
    [...str]: any
    allowPrivilegeEscalation?: bool
    capabilities?: ValuesAlloySecurityContextCapabilities
    seccompProfile?: ValuesAlloySecurityContextSeccompProfile

schema ValuesAlloySecurityContextCapabilities:
    r"""
    ValuesAlloySecurityContextCapabilities

    Attributes
    ----------
    add : [str], optional
    drop : [str], optional
    """
    [...str]: any
    add?: [str]
    drop?: [str]

schema ValuesAlloySecurityContextSeccompProfile:
    r"""
    ValuesAlloySecurityContextSeccompProfile

    Attributes
    ----------
    $type : str, optional
    """
    [...str]: any
    $type?: str

schema ValuesAlloySingleton:
    r"""
    An Alloy instance for data sources required to be deployed on a single replica.
    To see all valid settings, please see the [Alloy Collector documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/collectors/alloy.md).

    Attributes
    ----------
    enabled : bool, optional, default is False
        Deploy the Alloy instance for data sources required to be deployed on a single replica.
    """
    [...str]: any
    enabled?: bool

schema ValuesAnnotationAutodiscovery:
    r"""
    Annotation Autodiscovery enables gathering metrics from Kubernetes Pods and Services discovered by special annotations.
    Requires a destination that supports metrics.
    To see the valid options, please see the [Annotation Autodiscovery feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-annotation-autodiscovery).

    Attributes
    ----------
    collector : str, optional, default is "alloy-metrics"
        Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    destinations : [any], optional
        The destinations where cluster metrics will be sent. If empty, all metrics-capable destinations will be used.
    enabled : bool, optional, default is False
        Enable gathering metrics from Kubernetes Pods and Services discovered by special annotations.
    """
    [...str]: any
    collector?: str
    destinations?: [any]
    enabled?: bool

schema ValuesAnnotations:
    r"""
    Annotations to add to the Alloy Custom Resource. These annotations are not added to the workload or Pod.

    Attributes
    ----------
    instance : str, optional, default is "k8s.grafana.com/instance"
        Annotation for overriding the instance label
    job : str, optional, default is "k8s.grafana.com/logs.job"
        Annotation for overriding the job label
    metricsContainer : str, optional, default is "k8s.grafana.com/metrics.container"
        Annotation for selecting the specific container to scrape.
    metricsParam : str, optional, default is "k8s.grafana.com/metrics.param"
        Annotation for setting `__param_<key>` parameters when scraping.
        Example: `k8s.grafana.com/metrics.param_key: "value"`.
    metricsPath : str, optional, default is "k8s.grafana.com/metrics.path"
        Annotation for setting or overriding the metrics path. If not set, it defaults to /metrics
    metricsPortName : str, optional, default is "k8s.grafana.com/metrics.portName"
        Annotation for setting the metrics port by name.
    metricsPortNumber : str, optional, default is "k8s.grafana.com/metrics.portNumber"
        Annotation for setting the metrics port by number.
    metricsScheme : str, optional, default is "k8s.grafana.com/metrics.scheme"
        Annotation for setting the metrics scheme, default: http.
    metricsScrapeInterval : str, optional, default is "k8s.grafana.com/metrics.scrapeInterval"
        Annotation for overriding the scrape interval for this service or pod. Value should be a duration like "15s, 1m".
        Overrides metrics.autoDiscover.scrapeInterval
    metricsScrapeTimeout : str, optional, default is "k8s.grafana.com/metrics.scrapeTimeout"
        Annotation for overriding the scrape timeout for this service or pod. Value should be a duration like "15s, 1m".
        Overrides metrics.autoDiscover.scrapeTimeout
    prefix : str, optional, default is "profiles.grafana.com"
        The prefix for all annotations.
    scrape : str, optional, default is "k8s.grafana.com/scrape"
        Annotation for enabling scraping for this service or pod. Value should be either "true" or "false"
    """
    [...str]: any
    instance?: str
    job?: str
    metricsContainer?: str
    metricsParam?: str
    metricsPath?: str
    metricsPortName?: str
    metricsPortNumber?: str
    metricsScheme?: str
    metricsScrapeInterval?: str
    metricsScrapeTimeout?: str
    prefix?: str
    scrape?: str

schema ValuesApiServer:
    r"""
    API Server metrics gather information about the Kubernetes API Server.

    Attributes
    ----------
    enabled : any, optional, default is ""
        (bool) Scrape metrics from the API Server.
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for the API Server.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with `__` (i.e. `__meta_kubernetes*`) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for the API Server.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    jobLabel : str, optional, default is "integrations/kubernetes/kube-apiserver"
        The value for the job label.
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for the API Server prometheus.relabel component.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides metrics.maxCacheSize
    metricsTuning : ValuesApiServerMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    scrapeInterval : str, optional, default is ""
        How frequently to scrape metrics from the API Server
        Overrides metrics.scrapeInterval
    scrapeTimeout : str, optional, default is ""
        The timeout for scraping API Server metrics.
    """
    [...str]: any
    enabled?: any
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    jobLabel?: str
    maxCacheSize?: any
    metricsTuning?: ValuesApiServerMetricsTuning
    scrapeInterval?: str
    scrapeTimeout?: str

schema ValuesApiServerMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions. An empty list means keep all.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]

schema ValuesApplicationObservability:
    r"""
    Application Observability.
    Requires destinations that supports metrics, logs, and traces.
    To see the valid options, please see the [Application Observability feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-application-observability).

    Attributes
    ----------
    collector : str, optional, default is "alloy-receiver"
        Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    destinations : [any], optional
        The destinations where application data will be sent. If empty, all capable destinations will be used.
    enabled : bool, optional, default is False
        Enable receiving Application Observability.
    receivers : ValuesApplicationObservabilityReceivers, optional
        The receivers used for receiving application data.
    """
    [...str]: any
    collector?: str
    destinations?: [any]
    enabled?: bool
    receivers?: ValuesApplicationObservabilityReceivers

schema ValuesApplicationObservabilityReceivers:
    r"""
    The receivers used for receiving application data.
    """
    [...str]: any

schema ValuesAuth:
    r"""
    ValuesAuth

    Attributes
    ----------
    bearerToken : str, optional
        The bearer token for bearer token authentication.
    bearerTokenFile : str, optional
        Path to a file that containers the bearer token.
    bearerTokenFrom : str, optional
        Raw config for accessing the bearer token.
    bearerTokenKey : str, optional
        The key for storing the bearer token in the secret.
    oauth2 : ValuesAuthOauth2, optional
        Authenticate to Pyroscope using OAuth2
    password : str, optional
        The password for basic authentication.
    passwordFrom : str, optional
        Raw config for accessing the password.
    passwordKey : str, optional
        The key for storing the password in the secret.
    sigv4 : ValuesAuthSigv4, optional
        Authentication using AWS Signature Version 4
    $type : str, optional
        The type of authentication to do.
        Options are "none" (default), "basic", "bearerToken".
    username : str, optional
        The username for basic authentication.
    usernameFrom : str, optional
        Raw config for accessing the username.
    usernameKey : str, optional
        The key for storing the username in the secret.
    """
    [...str]: any
    bearerToken?: str
    bearerTokenFile?: str
    bearerTokenFrom?: str
    bearerTokenKey?: str
    oauth2?: ValuesAuthOauth2
    password?: str
    passwordFrom?: str
    passwordKey?: str
    sigv4?: ValuesAuthSigv4
    $type?: str
    username?: str
    usernameFrom?: str
    usernameKey?: str

schema ValuesAuthOauth2:
    r"""
    Authenticate to Pyroscope using OAuth2

    Attributes
    ----------
    clientId : str, optional
        OAuth2 client ID
    clientIdFrom : str, optional
        Raw config for accessing the client ID
    clientIdKey : str, optional
        The key for the client ID property in the secret
    clientSecret : str, optional
        OAuth2 client secret
    clientSecretFile : str, optional
        File containing the OAuth2 client secret.
    clientSecretFrom : str, optional
        Raw config for accessing the client secret
    clientSecretKey : str, optional
        The key for the client secret property in the secret
    endpointParams : ValuesAuthOauth2EndpointParams, optional
        OAuth2 endpoint parameters
    noProxy : str, optional
        Comma-separated list of IP addresses, CIDR notations, and domain names to exclude from proxying.
    proxyConnectHeader : ValuesAuthOauth2ProxyConnectHeader, optional
        Specifies headers to send to proxies during CONNECT requests.
    proxyFromEnvironment : bool, optional
        Use the proxy URL indicated by environment variables.
    proxyURL : str, optional
        HTTP proxy to send requests through.
    scopes : [any], optional
        List of scopes to authenticate with.
    tokenURL : str, optional
        URL to fetch the token from.
    """
    [...str]: any
    clientId?: str
    clientIdFrom?: str
    clientIdKey?: str
    clientSecret?: str
    clientSecretFile?: str
    clientSecretFrom?: str
    clientSecretKey?: str
    endpointParams?: ValuesAuthOauth2EndpointParams
    noProxy?: str
    proxyConnectHeader?: ValuesAuthOauth2ProxyConnectHeader
    proxyFromEnvironment?: bool
    proxyURL?: str
    scopes?: [any]
    tokenURL?: str

schema ValuesAuthOauth2EndpointParams:
    r"""
    OAuth2 endpoint parameters
    """
    [...str]: any

schema ValuesAuthOauth2ProxyConnectHeader:
    r"""
    Specifies headers to send to proxies during CONNECT requests.
    """
    [...str]: any

schema ValuesAuthSigv4:
    r"""
    Authentication using AWS Signature Version 4

    Attributes
    ----------
    accessKey : str, optional
        The access key for sigv4 authentication.
    accessKeyFrom : str, optional
        Raw config for accessing the access key.
    accessKeyKey : str, optional
        The key for storing the access key in the secret.
    profile : str, optional
        The named AWS profile for sigv4 authentication.
    region : str, optional
        The AWS region for sigv4 authentication.
    roleArn : str, optional
        The Role ARN for sigv4 authentication.
    secretKey : str, optional
        The secret key for sigv4 authentication.
    secretKeyFrom : str, optional
        Raw config for accessing the secret key.
    secretKeyKey : str, optional
        The key for storing the secret key in the secret.
    """
    [...str]: any
    accessKey?: str
    accessKeyFrom?: str
    accessKeyKey?: str
    profile?: str
    region?: str
    roleArn?: str
    secretKey?: str
    secretKeyFrom?: str
    secretKeyKey?: str

schema ValuesAutoInstrumentation:
    r"""
    Auto-Instrumentation.
    Requires destinations that supports metrics, logs, and traces.
    To see the valid options, please see the [Auto-Instrumentation feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-auto-instrumentation).

    Attributes
    ----------
    collector : str, optional, default is "alloy-metrics"
        Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    destinations : [any], optional
        The destinations where application data will be sent. If empty, all capable destinations will be used.
    enabled : bool, optional, default is False
        Enable automatic instrumentation for applications.
    """
    [...str]: any
    collector?: str
    destinations?: [any]
    enabled?: bool

schema ValuesAutosharding:
    r"""
    If set to true, this will deploy kube-state-metrics as a StatefulSet and the data
    will be automatically sharded across <.Values.replicas> pods using the built-in
    autodiscovery feature: https://github.com/kubernetes/kube-state-metrics#automated-sharding
    This is an experimental feature and there are no stability guarantees.

    Attributes
    ----------
    enabled : bool, optional, default is False
    """
    [...str]: any
    enabled?: bool

schema ValuesBearerToken:
    r"""
    Sets bearer_token_file line in the prometheus.scrape annotation_autodiscovery.

    Attributes
    ----------
    enabled : bool, optional, default is True
    token : str, optional, default is "/var/run/secrets/kubernetes.io/serviceaccount/token"
    """
    [...str]: any
    enabled?: bool
    token?: str

schema ValuesBeyla:
    r"""
    ValuesBeyla

    Attributes
    ----------
    config : ValuesBeylaConfig, optional
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for Beyla.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with __ (i.e. __meta_kubernetes*) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for Beyla. ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus.relabel/#rule-block))
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no __meta* labels are present.
    labelMatchers : ValuesBeylaLabelMatchers, optional
        Label matchers used to select the Beyla pods for scraping metrics.
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for the prometheus.relabel component for Beyla.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus.relabel/#arguments))
        Overrides metrics.maxCacheSize
    metricsTuning : ValuesBeylaMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    nodeSelector : ValuesBeylaNodeSelector, optional
    podAnnotations : ValuesBeylaPodAnnotations, optional
    preset : str, optional, default is "application"
        The configuration preset to use. Valid options are "application" or "network".
    scrapeInterval : str, optional, default is ""
        How frequently to scrape metrics from Beyla.
        Overrides metrics.scrapeInterval
    service : ValuesBeylaService, optional
        The port number for the Beyla service.
    tolerations : [ValuesBeylaTolerationsItems0], optional
    """
    [...str]: any
    config?: ValuesBeylaConfig
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    labelMatchers?: ValuesBeylaLabelMatchers
    maxCacheSize?: any
    metricsTuning?: ValuesBeylaMetricsTuning
    nodeSelector?: ValuesBeylaNodeSelector
    podAnnotations?: ValuesBeylaPodAnnotations
    preset?: str
    scrapeInterval?: str
    service?: ValuesBeylaService
    tolerations?: [ValuesBeylaTolerationsItems0]

schema ValuesBeylaConfig:
    r"""
    ValuesBeylaConfig

    Attributes
    ----------
    create : bool, optional, default is False
    data : ValuesBeylaConfigData, optional
        The configuration for Grafana Beyla
        Some sections will be set automatically, such as the cluster name.
        Others will be modified depending on the value of beyla.preset.
    skipConfigMapCheck : bool, optional, default is True
    """
    [...str]: any
    create?: bool
    data?: ValuesBeylaConfigData
    skipConfigMapCheck?: bool

schema ValuesBeylaConfigData:
    r"""
    The configuration for Grafana Beyla
    Some sections will be set automatically, such as the cluster name.
    Others will be modified depending on the value of beyla.preset.

    Attributes
    ----------
    attributes : ValuesBeylaConfigDataAttributes, optional
    internal_metrics : ValuesBeylaConfigDataInternalMetrics, optional
    prometheus_export : ValuesBeylaConfigDataPrometheusExport, optional
    """
    [...str]: any
    attributes?: ValuesBeylaConfigDataAttributes
    internal_metrics?: ValuesBeylaConfigDataInternalMetrics
    prometheus_export?: ValuesBeylaConfigDataPrometheusExport

schema ValuesBeylaConfigDataAttributes:
    r"""
    ValuesBeylaConfigDataAttributes

    Attributes
    ----------
    kubernetes : ValuesBeylaConfigDataAttributesKubernetes, optional
    """
    [...str]: any
    kubernetes?: ValuesBeylaConfigDataAttributesKubernetes

schema ValuesBeylaConfigDataAttributesKubernetes:
    r"""
    ValuesBeylaConfigDataAttributesKubernetes

    Attributes
    ----------
    enable : bool, optional, default is True
    """
    [...str]: any
    enable?: bool

schema ValuesBeylaConfigDataInternalMetrics:
    r"""
    ValuesBeylaConfigDataInternalMetrics

    Attributes
    ----------
    prometheus : ValuesBeylaConfigDataInternalMetricsPrometheus, optional
    """
    [...str]: any
    prometheus?: ValuesBeylaConfigDataInternalMetricsPrometheus

schema ValuesBeylaConfigDataInternalMetricsPrometheus:
    r"""
    ValuesBeylaConfigDataInternalMetricsPrometheus

    Attributes
    ----------
    path : str, optional, default is "/internal/metrics"
    port : int, optional, default is 9090
    """
    [...str]: any
    path?: str
    port?: int

schema ValuesBeylaConfigDataPrometheusExport:
    r"""
    ValuesBeylaConfigDataPrometheusExport

    Attributes
    ----------
    features : [str], optional
    path : str, optional, default is "/metrics"
    port : int, optional, default is 9090
    """
    [...str]: any
    features?: [str]
    path?: str
    port?: int

schema ValuesBeylaLabelMatchers:
    r"""
    Label matchers used to select the Beyla pods for scraping metrics.

    Attributes
    ----------
    "app.kubernetes.io/name" : str, optional, default is "beyla"
    """
    [...str]: any
    "app.kubernetes.io/name"?: str

schema ValuesBeylaMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]

schema ValuesBeylaNodeSelector:
    r"""
    ValuesBeylaNodeSelector

    Attributes
    ----------
    "kubernetes.io/os" : str, optional, default is "linux"
    """
    [...str]: any
    "kubernetes.io/os"?: str

schema ValuesBeylaPodAnnotations:
    r"""
    ValuesBeylaPodAnnotations

    Attributes
    ----------
    "k8s.grafana.com/job" : str, optional, default is "default/beyla"
    "k8s.grafana.com/logs.job" : str, optional, default is "integrations/beyla"
    """
    [...str]: any
    "k8s.grafana.com/job"?: str
    "k8s.grafana.com/logs.job"?: str

schema ValuesBeylaService:
    r"""
    The port number for the Beyla service.

    Attributes
    ----------
    targetPort : int, optional, default is 9090
    """
    [...str]: any
    targetPort?: int

schema ValuesBeylaTolerationsItems0:
    r"""
    ValuesBeylaTolerationsItems0

    Attributes
    ----------
    effect : str, optional, default is "NoSchedule"
    operator : str, optional, default is "Exists"
    """
    [...str]: any
    effect?: str
    operator?: str

schema ValuesCadvisor:
    r"""
    cAdvisor metrics gather information about containers on each node.

    Attributes
    ----------
    enabled : bool, optional, default is True
        Scrape metrics from cAdvisor.
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for cAdvisor.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with `__` (i.e. `__meta_kubernetes*`) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for cAdvisor metrics.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    jobLabel : str, optional, default is "integrations/kubernetes/cadvisor"
        The value for the job label.
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for the cAdvisor prometheus.relabel component.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides global.maxCacheSize
    metricsTuning : ValuesCadvisorMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    nodeAddressFormat : str, optional, default is "direct"
        How to access cAdvisor to get metrics, either "direct" (use node IP) or "proxy" (uses API Server)
    scrapeInterval : str, optional, default is ""
        How frequently to scrape cAdvisor metrics.
    scrapeTimeout : str, optional, default is ""
        The timeout for scraping cAdvisor metrics.
    """
    [...str]: any
    enabled?: bool
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    jobLabel?: str
    maxCacheSize?: any
    metricsTuning?: ValuesCadvisorMetricsTuning
    nodeAddressFormat?: str
    scrapeInterval?: str
    scrapeTimeout?: str

schema ValuesCadvisorMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    dropEmptyContainerLabels : bool, optional, default is True
        Drop metrics that have an empty container label
    dropEmptyImageLabels : bool, optional, default is True
        Drop metrics that have an empty image label
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    excludeNamespaces : [any], optional
        For metrics with a `namespace` label, drop those that are in this list.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions.
    includeNamespaces : [any], optional
        For metrics with a `namespace` label, only keep those that are in this list.
    keepPhysicalFilesystemDevices : [str], optional
        Only keep filesystem metrics that use the following physical devices
    keepPhysicalNetworkDevices : [str], optional
        Only keep network metrics that use the following physical devices
    normalizeUnnecessaryLabels : [ValuesCadvisorMetricsTuningNormalizeUnnecessaryLabelsItems0], optional
        Normalize labels to the same value for the given metric and label pairs
    useDefaultAllowList : bool, optional, default is True
        Filter the list of metrics from cAdvisor to the minimal set required for Kubernetes Monitoring.
    """
    [...str]: any
    dropEmptyContainerLabels?: bool
    dropEmptyImageLabels?: bool
    excludeMetrics?: [any]
    excludeNamespaces?: [any]
    includeMetrics?: [any]
    includeNamespaces?: [any]
    keepPhysicalFilesystemDevices?: [str]
    keepPhysicalNetworkDevices?: [str]
    normalizeUnnecessaryLabels?: [ValuesCadvisorMetricsTuningNormalizeUnnecessaryLabelsItems0]
    useDefaultAllowList?: bool

schema ValuesCadvisorMetricsTuningNormalizeUnnecessaryLabelsItems0:
    r"""
    ValuesCadvisorMetricsTuningNormalizeUnnecessaryLabelsItems0

    Attributes
    ----------
    labels : [str], optional
    metric : str, optional, default is "machine_memory_bytes"
    """
    [...str]: any
    labels?: [str]
    metric?: str

schema ValuesCanMount:
    r"""
    ValuesCanMount

    Attributes
    ----------
    usrSrc : bool, optional, default is True
    """
    [...str]: any
    usrSrc?: bool

schema ValuesCertManager:
    r"""
    Scrape metrics/logs from cert-manager

    Attributes
    ----------
    instances : [any], optional
    """
    [...str]: any
    instances?: [any]

schema ValuesCluster:
    r"""
    yamllint disable rule:line-length rule:comments-indentation

    Attributes
    ----------
    name : str, optional, default is ""
        The name for this cluster.
    """
    [...str]: any
    name?: str

schema ValuesClusterEvents:
    r"""
    Cluster events.
    Requires a destination that supports logs.
    To see the valid options, please see the [Cluster Events feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-cluster-events).

    Attributes
    ----------
    collector : str, optional, default is "alloy-singleton"
        Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    destinations : [any], optional
        The destinations where cluster events will be sent. If empty, all logs-capable destinations will be used.
    enabled : bool, optional, default is False
        Enable gathering Kubernetes Cluster events.
    """
    [...str]: any
    collector?: str
    destinations?: [any]
    enabled?: bool

schema ValuesClusterMetrics:
    r"""
    Cluster Monitoring enables observability and monitoring for your Kubernetes Cluster itself.
    Requires a destination that supports metrics.
    To see the valid options, please see the [Cluster Monitoring feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-cluster-metrics).

    Attributes
    ----------
    collector : str, optional, default is "alloy-metrics"
        Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    destinations : [any], optional
        The destinations where cluster metrics will be sent. If empty, all metrics-capable destinations will be used.
    enabled : bool, optional, default is False
        Enable gathering Kubernetes Cluster metrics.
    """
    [...str]: any
    collector?: str
    destinations?: [any]
    enabled?: bool

schema ValuesCollectorCommon:
    r"""
    ValuesCollectorCommon

    Attributes
    ----------
    alloy : ValuesCollectorCommonAlloy, optional
        Settings to apply to all Alloy instances created by this Helm chart. This includes Alloy instances created by
        enabling Tail Sampling or Service Graph Metrics.
    """
    [...str]: any
    alloy?: ValuesCollectorCommonAlloy

schema ValuesCollectorCommonAlloy:
    r"""
    Settings to apply to all Alloy instances created by this Helm chart. This includes Alloy instances created by
    enabling Tail Sampling or Service Graph Metrics.
    """
    [...str]: any

schema ValuesCommonLabels:
    r"""
    # Extra labels to attach to all resources (can be templated)
    """
    [...str]: any

schema ValuesConfig:
    r"""
    The configuration for this destination.
    @ section -- General

    Attributes
    ----------
    create : bool, optional, default is True
        set to true, to use the below default configurations
    data : ValuesConfigData, optional
        default value of beyla configuration
    name : str, optional, default is ""
        # -- Provide the name of the external configmap containing the beyla configuration.
        # To create configmap from configuration file, user can use the below command. Note: The name 'beyla-config.yaml' is important.
        # `kubectl create cm --from-file=beyla-config.yaml=<name-of-config-file> -n <namespace>`
        # If empty, default configuration below is used.
    skipConfigMapCheck : bool, optional, default is False
        set to true, to skip the check around the ConfigMap creation
    """
    [...str]: any
    create?: bool
    data?: ValuesConfigData
    name?: str
    skipConfigMapCheck?: bool

schema ValuesConfigData:
    r"""
    default value of beyla configuration

    Attributes
    ----------
    attributes : ValuesConfigDataAttributes, optional
        profile_port: 6060
        open_port: 8443
        routes:
          unmatched: heuristic
        log_level: info
        otel_traces_export:
          endpoint: http://grafana-agent:4318
        # or alternatively use
        grafana:
          otlp:
            cloud_zone: prod-eu-west-0
            cloud_instance_id: 123456
            cloud_api_key:
    $filter : ValuesConfigDataFilter, optional
    prometheus_export : ValuesConfigDataPrometheusExport, optional
        # to enable network metrics
        network:
          enable: true
    """
    [...str]: any
    attributes?: ValuesConfigDataAttributes
    $filter?: ValuesConfigDataFilter
    prometheus_export?: ValuesConfigDataPrometheusExport

schema ValuesConfigDataAttributes:
    r"""
    profile_port: 6060
    open_port: 8443
    routes:
      unmatched: heuristic
    log_level: info
    otel_traces_export:
      endpoint: http://grafana-agent:4318
    # or alternatively use
    grafana:
      otlp:
        cloud_zone: prod-eu-west-0
        cloud_instance_id: 123456
        cloud_api_key:

    Attributes
    ----------
    kubernetes : ValuesConfigDataAttributesKubernetes, optional
    """
    [...str]: any
    kubernetes?: ValuesConfigDataAttributesKubernetes

schema ValuesConfigDataAttributesKubernetes:
    r"""
    ValuesConfigDataAttributesKubernetes

    Attributes
    ----------
    enable : bool, optional, default is True
    """
    [...str]: any
    enable?: bool

schema ValuesConfigDataFilter:
    r"""
    ValuesConfigDataFilter

    Attributes
    ----------
    network : ValuesConfigDataFilterNetwork, optional
    """
    [...str]: any
    network?: ValuesConfigDataFilterNetwork

schema ValuesConfigDataFilterNetwork:
    r"""
    ValuesConfigDataFilterNetwork

    Attributes
    ----------
    k8s_dst_owner_name : ValuesConfigDataFilterNetworkK8SDstOwnerName, optional
    k8s_src_owner_name : ValuesConfigDataFilterNetworkK8SSrcOwnerName, optional
    """
    [...str]: any
    k8s_dst_owner_name?: ValuesConfigDataFilterNetworkK8SDstOwnerName
    k8s_src_owner_name?: ValuesConfigDataFilterNetworkK8SSrcOwnerName

schema ValuesConfigDataFilterNetworkK8SDstOwnerName:
    r"""
    ValuesConfigDataFilterNetworkK8SDstOwnerName

    Attributes
    ----------
    not_match : str, optional, default is "{kube*,*jaeger-agent*,*prometheus*,*promtail*,*grafana-agent*}"
    """
    [...str]: any
    not_match?: str

schema ValuesConfigDataFilterNetworkK8SSrcOwnerName:
    r"""
    ValuesConfigDataFilterNetworkK8SSrcOwnerName

    Attributes
    ----------
    not_match : str, optional, default is "{kube*,*jaeger-agent*,*prometheus*,*promtail*,*grafana-agent*}"
    """
    [...str]: any
    not_match?: str

schema ValuesConfigDataPrometheusExport:
    r"""
    # to enable network metrics
    network:
      enable: true

    Attributes
    ----------
    path : str, optional, default is "/metrics"
    port : int, optional, default is 9090
    """
    [...str]: any
    path?: str
    port?: int

schema ValuesConfigReloader:
    r"""
    Options for the extra controller used for config reloading.

    Attributes
    ----------
    customArgs : [any], optional
        Override the args passed to the container.
    enabled : bool, optional
        Enables automatically reloading when the Alloy config changes.
    image : ValuesConfigReloaderImage, optional
    resources : ValuesConfigReloaderResources, optional
        Resource requests and limits to apply to the config reloader container.
    securityContext : ValuesConfigReloaderSecurityContext, optional
        Security context to apply to the Grafana configReloader container.
    """
    [...str]: any
    customArgs?: [any]
    enabled?: bool
    image?: ValuesConfigReloaderImage
    resources?: ValuesConfigReloaderResources
    securityContext?: ValuesConfigReloaderSecurityContext

schema ValuesConfigReloaderImage:
    r"""
    ValuesConfigReloaderImage

    Attributes
    ----------
    digest : str, optional
        SHA256 digest of image to use for config reloading (either in format "sha256:XYZ" or "XYZ"). When set, will override `configReloader.image.tag`
    registry : str, optional
        Config reloader image registry (defaults to docker.io)
    repository : str, optional
        Repository to get config reloader image from.
    tag : str, optional
        Tag of image to use for config reloading.
    """
    [...str]: any
    digest?: str
    registry?: str
    repository?: str
    tag?: str

schema ValuesConfigReloaderResources:
    r"""
    Resource requests and limits to apply to the config reloader container.

    Attributes
    ----------
    requests : ValuesConfigReloaderResourcesRequests, optional
    """
    [...str]: any
    requests?: ValuesConfigReloaderResourcesRequests

schema ValuesConfigReloaderResourcesRequests:
    r"""
    ValuesConfigReloaderResourcesRequests

    Attributes
    ----------
    cpu : str, optional
    memory : str, optional
    """
    [...str]: any
    cpu?: str
    memory?: str

schema ValuesConfigReloaderSecurityContext:
    r"""
    Security context to apply to the Grafana configReloader container.
    """
    [...str]: any

schema ValuesConnectors:
    r"""
    Connectors are components that create new telemetry data from existing telemetry data.

    Attributes
    ----------
    grafanaCloudMetrics : ValuesConnectorsGrafanaCloudMetrics, optional
    spanLogs : ValuesConnectorsSpanLogs, optional
        Span Logs connector settings.
    spanMetrics : ValuesConnectorsSpanMetrics, optional
        Span Metrics connector settings.
    """
    [...str]: any
    grafanaCloudMetrics?: ValuesConnectorsGrafanaCloudMetrics
    spanLogs?: ValuesConnectorsSpanLogs
    spanMetrics?: ValuesConnectorsSpanMetrics

schema ValuesConnectorsGrafanaCloudMetrics:
    r"""
    ValuesConnectorsGrafanaCloudMetrics

    Attributes
    ----------
    enabled : bool, optional, default is True
        Generate host info metrics from telemetry data. These metrics are required for using Application Observability
        in Grafana Cloud. Note: Enabling this may incur additional costs.
        See [Application Observability Pricing](https://grafana.com/docs/grafana-cloud/monitor-applications/application-observability/pricing/)
    """
    [...str]: any
    enabled?: bool

schema ValuesConnectorsSpanLogs:
    r"""
    Span Logs connector settings.

    Attributes
    ----------
    enabled : bool, optional, default is False
        Use a span logs connector which creates logs from spans.
    labels : [any], optional
        A list of keys that will be logged as labels.
    process : bool, optional, default is False
        Log one line for every process.
    processAttributes : [any], optional
        Additional process attributes to log.
    roots : bool, optional, default is False
        Log one line for every root span of a trace.
    spanAttributes : [any], optional
        Additional span attributes to log.
    spans : bool, optional, default is False
        Create a log line for each span. This can lead to a large number of logs.
    """
    [...str]: any
    enabled?: bool
    labels?: [any]
    process?: bool
    processAttributes?: [any]
    roots?: bool
    spanAttributes?: [any]
    spans?: bool

schema ValuesConnectorsSpanMetrics:
    r"""
    Span Metrics connector settings.

    Attributes
    ----------
    aggregationCardinalityLimit : int, optional, default is 1000
        How many unique combinations of dimensions that will be tracked for metrics aggregation
    dimensions : [any], optional
        Define dimensions to be added.
        Some are set internally by default: [service.name, span.name, span.kind, status.code]
        Example:
        - name: "http.status_code"
        - name: "http.method"
          default: "GET"
    dimensionsCacheSize : int, optional, default is 1000
        How many dimensions to cache. DEPRECATED, please use aggregationCardinalityLimit instead.
    enabled : bool, optional, default is False
        Use a span metrics connector which creates metrics from spans.
    events : ValuesConnectorsSpanMetricsEvents, optional
    excludeDimensions : [any], optional
        List of dimensions to be excluded from the default set of dimensions.
    exemplars : ValuesConnectorsSpanMetricsExemplars, optional
    histogram : ValuesConnectorsSpanMetricsHistogram, optional
    namespace : str, optional, default is "traces.span.metrics"
        The Metric namespace.
    skipBeyla : bool, optional, default is True
        Skip Beyla traces when `span.metrics.skip` resource attribute is present.
    skipInternal : bool, optional, default is True
        Skip span if span kind is internal.
    transforms : ValuesConnectorsSpanMetricsTransforms, optional
        Apply transformations to span metrics after they are generated.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.transform/))
    """
    [...str]: any
    aggregationCardinalityLimit?: int
    dimensions?: [any]
    dimensionsCacheSize?: int
    enabled?: bool
    events?: ValuesConnectorsSpanMetricsEvents
    excludeDimensions?: [any]
    exemplars?: ValuesConnectorsSpanMetricsExemplars
    histogram?: ValuesConnectorsSpanMetricsHistogram
    namespace?: str
    skipBeyla?: bool
    skipInternal?: bool
    transforms?: ValuesConnectorsSpanMetricsTransforms

schema ValuesConnectorsSpanMetricsEvents:
    r"""
    ValuesConnectorsSpanMetricsEvents

    Attributes
    ----------
    enabled : bool, optional, default is False
        Capture events metrics, which track span events.
    """
    [...str]: any
    enabled?: bool

schema ValuesConnectorsSpanMetricsExemplars:
    r"""
    ValuesConnectorsSpanMetricsExemplars

    Attributes
    ----------
    enabled : bool, optional, default is False
        Attach exemplars to histograms.
    maxPerDataPoint : any, optional, default is ""
        (number) Limits the number of exemplars that can be added to a unique dimension set.
    """
    [...str]: any
    enabled?: bool
    maxPerDataPoint?: any

schema ValuesConnectorsSpanMetricsHistogram:
    r"""
    ValuesConnectorsSpanMetricsHistogram

    Attributes
    ----------
    enabled : bool, optional, default is True
        Capture histogram metrics, derived from spans’ durations.
    explicit : ValuesConnectorsSpanMetricsHistogramExplicit, optional
        Settings for explicit histograms.
    exponential : ValuesConnectorsSpanMetricsHistogramExponential, optional
        Settings for exponential histograms.
    $type : str, optional, default is "explicit"
        Type of histograms to create. Must be either "explicit" or "exponential".
    unit : str, optional, default is "s"
        The histogram unit.
    """
    [...str]: any
    enabled?: bool
    explicit?: ValuesConnectorsSpanMetricsHistogramExplicit
    exponential?: ValuesConnectorsSpanMetricsHistogramExponential
    $type?: str
    unit?: str

schema ValuesConnectorsSpanMetricsHistogramExplicit:
    r"""
    Settings for explicit histograms.

    Attributes
    ----------
    buckets : [str], optional
        The histogram buckets to use.
    """
    [...str]: any
    buckets?: [str]

schema ValuesConnectorsSpanMetricsHistogramExponential:
    r"""
    Settings for exponential histograms.

    Attributes
    ----------
    maxSize : int, optional, default is 160
        Maximum number of buckets per positive or negative number range.
    """
    [...str]: any
    maxSize?: int

schema ValuesConnectorsSpanMetricsTransforms:
    r"""
    Apply transformations to span metrics after they are generated.
    ([docs](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.transform/))

    Attributes
    ----------
    datapoint : [any], optional
    metric : [any], optional
    resource : [any], optional
    """
    [...str]: any
    datapoint?: [any]
    metric?: [any]
    resource?: [any]

schema ValuesContainerSecurityContext:
    r"""
    # Specify security settings for a Container
    # Allows overrides and additional options compared to (Pod) securityContext
    # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container

    Attributes
    ----------
    allowPrivilegeEscalation : bool, optional, default is False
    capabilities : ValuesContainerSecurityContextCapabilities, optional
    readOnlyRootFilesystem : bool, optional, default is True
    """
    [...str]: any
    allowPrivilegeEscalation?: bool
    capabilities?: ValuesContainerSecurityContextCapabilities
    readOnlyRootFilesystem?: bool

schema ValuesContainerSecurityContextCapabilities:
    r"""
    ValuesContainerSecurityContextCapabilities

    Attributes
    ----------
    drop : [str], optional
    """
    [...str]: any
    drop?: [str]

schema ValuesContextPropagation:
    r"""
    Enables context propagation support.

    Attributes
    ----------
    enabled : bool, optional, default is True
    """
    [...str]: any
    enabled?: bool

schema ValuesControlPlane:
    r"""
    ValuesControlPlane

    Attributes
    ----------
    enabled : bool, optional, default is False
        enable all Kubernetes Control Plane metrics sources. This includes api-server, kube-scheduler,
        kube-controller-manager, and KubeDNS.
    """
    [...str]: any
    enabled?: bool

schema ValuesController:
    r"""
    ValuesController

    Attributes
    ----------
    affinity : ValuesControllerAffinity, optional
        Affinity configuration for pods.
    autoscaling : ValuesControllerAutoscaling, optional
    dnsPolicy : str, optional
        Configures the DNS policy for the pod. https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy
    enableStatefulSetAutoDeletePVC : bool, optional
        Whether to enable automatic deletion of stale PVCs due to a scale down operation, when controller.type is 'statefulset'.
    extraAnnotations : ValuesControllerExtraAnnotations, optional
        Annotations to add to controller.
    extraContainers : [any], optional
        Additional containers to run alongside the Alloy container and initContainers.
    extraLabels : ValuesControllerExtraLabels, optional
        Extra labels to add to the controller.
    hostNetwork : bool, optional
        Configures Pods to use the host network. When set to true, the ports that will be used must be specified.
    hostPID : bool, optional
        Configures Pods to use the host PID namespace.
    initContainers : [any], optional
        # -- Additional init containers to run.
        # ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
        #
    minReadySeconds : int, optional
        How many additional seconds to wait before considering a pod ready.
    nodeSelector : ValuesControllerNodeSelector, optional
        nodeSelector to apply to Grafana Alloy pods.
    parallelRollout : bool, optional
        Whether to deploy pods in parallel. Only used when controller.type is
        'statefulset'.
    podAnnotations : ValuesControllerPodAnnotations, optional
        Extra pod annotations to add.
    podDisruptionBudget : ValuesControllerPodDisruptionBudget, optional
        PodDisruptionBudget configuration.
    podLabels : ValuesControllerPodLabels, optional
        Extra pod labels to add.
    priorityClassName : str, optional
        priorityClassName to apply to Grafana Alloy pods.
    replicas : int, optional
        Number of pods to deploy. Ignored when controller.type is 'daemonset'.
    terminationGracePeriodSeconds : any, optional
        Termination grace period in seconds for the Grafana Alloy pods.
        The default value used by Kubernetes if unspecifed is 30 seconds.
    tolerations : [any], optional
        Tolerations to apply to Grafana Alloy pods.
    topologySpreadConstraints : [any], optional
        Topology Spread Constraints to apply to Grafana Alloy pods.
    $type : str, optional
        Type of controller to use for deploying Grafana Alloy in the cluster.
        Must be one of 'daemonset', 'deployment', or 'statefulset'.
    updateStrategy : ValuesControllerUpdateStrategy, optional
        Update strategy for updating deployed Pods.
    volumeClaimTemplates : [any], optional
        volumeClaimTemplates to add when controller.type is 'statefulset'.
    volumes : ValuesControllerVolumes, optional
    """
    [...str]: any
    affinity?: ValuesControllerAffinity
    autoscaling?: ValuesControllerAutoscaling
    dnsPolicy?: str
    enableStatefulSetAutoDeletePVC?: bool
    extraAnnotations?: ValuesControllerExtraAnnotations
    extraContainers?: [any]
    extraLabels?: ValuesControllerExtraLabels
    hostNetwork?: bool
    hostPID?: bool
    initContainers?: [any]
    minReadySeconds?: int
    nodeSelector?: ValuesControllerNodeSelector
    parallelRollout?: bool
    podAnnotations?: ValuesControllerPodAnnotations
    podDisruptionBudget?: ValuesControllerPodDisruptionBudget
    podLabels?: ValuesControllerPodLabels
    priorityClassName?: str
    replicas?: int
    terminationGracePeriodSeconds?: any
    tolerations?: [any]
    topologySpreadConstraints?: [any]
    $type?: str
    updateStrategy?: ValuesControllerUpdateStrategy
    volumeClaimTemplates?: [any]
    volumes?: ValuesControllerVolumes

schema ValuesControllerAffinity:
    r"""
    Affinity configuration for pods.
    """
    [...str]: any

schema ValuesControllerAutoscaling:
    r"""
    ValuesControllerAutoscaling

    Attributes
    ----------
    enabled : bool, optional
        Creates a HorizontalPodAutoscaler for controller type deployment.
        Deprecated: Please use controller.autoscaling.horizontal instead
    horizontal : ValuesControllerAutoscalingHorizontal, optional
        Configures the Horizontal Pod Autoscaler for the controller.
    maxReplicas : int, optional
        The upper limit for the number of replicas to which the autoscaler can scale up.
    minReplicas : int, optional
        The lower limit for the number of replicas to which the autoscaler can scale down.
    scaleDown : ValuesControllerAutoscalingScaleDown, optional
    scaleUp : ValuesControllerAutoscalingScaleUp, optional
    targetCPUUtilizationPercentage : int, optional
        Average CPU utilization across all relevant pods, a percentage of the requested value of the resource for the pods. Setting `targetCPUUtilizationPercentage` to 0 will disable CPU scaling.
    targetMemoryUtilizationPercentage : int, optional
        Average Memory utilization across all relevant pods, a percentage of the requested value of the resource for the pods. Setting `targetMemoryUtilizationPercentage` to 0 will disable Memory scaling.
    vertical : ValuesControllerAutoscalingVertical, optional
        Configures the Vertical Pod Autoscaler for the controller.
    """
    [...str]: any
    enabled?: bool
    horizontal?: ValuesControllerAutoscalingHorizontal
    maxReplicas?: int
    minReplicas?: int
    scaleDown?: ValuesControllerAutoscalingScaleDown
    scaleUp?: ValuesControllerAutoscalingScaleUp
    targetCPUUtilizationPercentage?: int
    targetMemoryUtilizationPercentage?: int
    vertical?: ValuesControllerAutoscalingVertical

schema ValuesControllerAutoscalingHorizontal:
    r"""
    Configures the Horizontal Pod Autoscaler for the controller.

    Attributes
    ----------
    enabled : bool, optional
        Enables the Horizontal Pod Autoscaler for the controller.
    maxReplicas : int, optional
        The upper limit for the number of replicas to which the autoscaler can scale up.
    minReplicas : int, optional
        The lower limit for the number of replicas to which the autoscaler can scale down.
    scaleDown : ValuesControllerAutoscalingHorizontalScaleDown, optional
    scaleUp : ValuesControllerAutoscalingHorizontalScaleUp, optional
    targetCPUUtilizationPercentage : int, optional
        Average CPU utilization across all relevant pods, a percentage of the requested value of the resource for the pods. Setting `targetCPUUtilizationPercentage` to 0 will disable CPU scaling.
    targetMemoryUtilizationPercentage : int, optional
        Average Memory utilization across all relevant pods, a percentage of the requested value of the resource for the pods. Setting `targetMemoryUtilizationPercentage` to 0 will disable Memory scaling.
    """
    [...str]: any
    enabled?: bool
    maxReplicas?: int
    minReplicas?: int
    scaleDown?: ValuesControllerAutoscalingHorizontalScaleDown
    scaleUp?: ValuesControllerAutoscalingHorizontalScaleUp
    targetCPUUtilizationPercentage?: int
    targetMemoryUtilizationPercentage?: int

schema ValuesControllerAutoscalingHorizontalScaleDown:
    r"""
    ValuesControllerAutoscalingHorizontalScaleDown

    Attributes
    ----------
    policies : [any], optional
        List of policies to determine the scale-down behavior.
    selectPolicy : str, optional
        - type: Pods
          value: 4
          periodSeconds: 60
        Determines which of the provided scaling-down policies to apply if multiple are specified.
    stabilizationWindowSeconds : int, optional
        The duration that the autoscaling mechanism should look back on to make decisions about scaling down.
    """
    [...str]: any
    policies?: [any]
    selectPolicy?: str
    stabilizationWindowSeconds?: int

schema ValuesControllerAutoscalingHorizontalScaleUp:
    r"""
    ValuesControllerAutoscalingHorizontalScaleUp

    Attributes
    ----------
    policies : [any], optional
        List of policies to determine the scale-up behavior.
    selectPolicy : str, optional
        - type: Pods
          value: 4
          periodSeconds: 60
        Determines which of the provided scaling-up policies to apply if multiple are specified.
    stabilizationWindowSeconds : int, optional
        The duration that the autoscaling mechanism should look back on to make decisions about scaling up.
    """
    [...str]: any
    policies?: [any]
    selectPolicy?: str
    stabilizationWindowSeconds?: int

schema ValuesControllerAutoscalingScaleDown:
    r"""
    ValuesControllerAutoscalingScaleDown

    Attributes
    ----------
    policies : [any], optional
        List of policies to determine the scale-down behavior.
    selectPolicy : str, optional
        - type: Pods
          value: 4
          periodSeconds: 60
        Determines which of the provided scaling-down policies to apply if multiple are specified.
    stabilizationWindowSeconds : int, optional
        The duration that the autoscaling mechanism should look back on to make decisions about scaling down.
    """
    [...str]: any
    policies?: [any]
    selectPolicy?: str
    stabilizationWindowSeconds?: int

schema ValuesControllerAutoscalingScaleUp:
    r"""
    ValuesControllerAutoscalingScaleUp

    Attributes
    ----------
    policies : [any], optional
        List of policies to determine the scale-up behavior.
    selectPolicy : str, optional
        - type: Pods
          value: 4
          periodSeconds: 60
        Determines which of the provided scaling-up policies to apply if multiple are specified.
    stabilizationWindowSeconds : int, optional
        The duration that the autoscaling mechanism should look back on to make decisions about scaling up.
    """
    [...str]: any
    policies?: [any]
    selectPolicy?: str
    stabilizationWindowSeconds?: int

schema ValuesControllerAutoscalingVertical:
    r"""
    Configures the Vertical Pod Autoscaler for the controller.

    Attributes
    ----------
    enabled : bool, optional
        Enables the Vertical Pod Autoscaler for the controller.
    recommenders : [any], optional
        List of recommenders to use for the Vertical Pod Autoscaler.
        Recommenders are responsible for generating recommendation for the object.
        List should be empty (then the default recommender will generate the recommendation)
        or contain exactly one recommender.
    resourcePolicy : ValuesControllerAutoscalingVerticalResourcePolicy, optional
        Configures the resource policy for the Vertical Pod Autoscaler.
    updatePolicy : any, optional
        Configures the update policy for the Vertical Pod Autoscaler.
    """
    [...str]: any
    enabled?: bool
    recommenders?: [any]
    resourcePolicy?: ValuesControllerAutoscalingVerticalResourcePolicy
    updatePolicy?: any

schema ValuesControllerAutoscalingVerticalResourcePolicy:
    r"""
    Configures the resource policy for the Vertical Pod Autoscaler.

    Attributes
    ----------
    containerPolicies : [ValuesControllerAutoscalingVerticalResourcePolicyContainerPoliciesItems0], optional
        Configures the container policies for the Vertical Pod Autoscaler.
    """
    [...str]: any
    containerPolicies?: [ValuesControllerAutoscalingVerticalResourcePolicyContainerPoliciesItems0]

schema ValuesControllerAutoscalingVerticalResourcePolicyContainerPoliciesItems0:
    r"""
    ValuesControllerAutoscalingVerticalResourcePolicyContainerPoliciesItems0

    Attributes
    ----------
    containerName : str, optional
    controlledResources : [str], optional
        The controlled resources for the Vertical Pod Autoscaler.
    controlledValues : str, optional
        The controlled values for the Vertical Pod Autoscaler. Needs to be either RequestsOnly or RequestsAndLimits.
    maxAllowed : ValuesControllerAutoscalingVerticalResourcePolicyContainerPoliciesItems0MaxAllowed, optional
        The maximum allowed values for the pods.
    minAllowed : ValuesControllerAutoscalingVerticalResourcePolicyContainerPoliciesItems0MinAllowed, optional
        cpu: 200m
        memory: 100Mi
        Defines the min allowed resources for the pod
    """
    [...str]: any
    containerName?: str
    controlledResources?: [str]
    controlledValues?: str
    maxAllowed?: ValuesControllerAutoscalingVerticalResourcePolicyContainerPoliciesItems0MaxAllowed
    minAllowed?: ValuesControllerAutoscalingVerticalResourcePolicyContainerPoliciesItems0MinAllowed

schema ValuesControllerAutoscalingVerticalResourcePolicyContainerPoliciesItems0MaxAllowed:
    r"""
    The maximum allowed values for the pods.
    """
    [...str]: any

schema ValuesControllerAutoscalingVerticalResourcePolicyContainerPoliciesItems0MinAllowed:
    r"""
    cpu: 200m
    memory: 100Mi
    Defines the min allowed resources for the pod
    """
    [...str]: any

schema ValuesControllerExtraAnnotations:
    r"""
    Annotations to add to controller.
    """
    [...str]: any

schema ValuesControllerExtraLabels:
    r"""
    Extra labels to add to the controller.
    """
    [...str]: any

schema ValuesControllerNodeSelector:
    r"""
    nodeSelector to apply to Grafana Alloy pods.

    Attributes
    ----------
    "kubernetes.io/os" : str, optional
    """
    [...str]: any
    "kubernetes.io/os"?: str

schema ValuesControllerPodAnnotations:
    r"""
    Extra pod annotations to add.

    Attributes
    ----------
    "k8s.grafana.com/logs.job" : str, optional
    """
    [...str]: any
    "k8s.grafana.com/logs.job"?: str

schema ValuesControllerPodDisruptionBudget:
    r"""
    PodDisruptionBudget configuration.

    Attributes
    ----------
    enabled : bool, optional
        Whether to create a PodDisruptionBudget for the controller.
    maxUnavailable : any, optional
        Maximum number of pods that can be unavailable during a disruption.
        Note: Only one of minAvailable or maxUnavailable should be set.
    minAvailable : any, optional
        Minimum number of pods that must be available during a disruption.
        Note: Only one of minAvailable or maxUnavailable should be set.
    """
    [...str]: any
    enabled?: bool
    maxUnavailable?: any
    minAvailable?: any

schema ValuesControllerPodLabels:
    r"""
    Extra pod labels to add.
    """
    [...str]: any

schema ValuesControllerUpdateStrategy:
    r"""
    Update strategy for updating deployed Pods.
    """
    [...str]: any

schema ValuesControllerVolumes:
    r"""
    ValuesControllerVolumes

    Attributes
    ----------
    extra : [any], optional
        Extra volumes to add to the Grafana Alloy pod.
    """
    [...str]: any
    extra?: [any]

schema ValuesCrds:
    r"""
    Skip installation of the Grafana Alloy CRDs, since we don't use them in this chart

    Attributes
    ----------
    alertmanagerconfigs : ValuesCrdsAlertmanagerconfigs, optional
        # alertmanagerconfigs configures the AlertManagerConfig CRD
    alertmanagers : ValuesCrdsAlertmanagers, optional
        # alertmanagers configures the AlertManager CRD
    annotations : ValuesCrdsAnnotations, optional
        # annotations add additional annotations to all CRDs
    create : bool, optional
    deploy : bool, optional, default is False
        Deploy the Prometheus Operator CRDs.
    deployAlloyCRD : bool, optional, default is True
        Should this chart deploy the Alloy CRD?
    deployPodLogsCRD : bool, optional, default is False
        Should this chart deploy the PodLogs CRD?
    podmonitors : ValuesCrdsPodmonitors, optional
        # podmonitors configures the PodMonitor CRD
    probes : ValuesCrdsProbes, optional
        # probes configures the Probe CRD
    prometheusagents : ValuesCrdsPrometheusagents, optional
        # prometheusagents configures the PrometheusAgent CRD
    prometheuses : ValuesCrdsPrometheuses, optional
        # prometheuses configures the Prometheus CRD
    prometheusrules : ValuesCrdsPrometheusrules, optional
        # prometheusrules configures the PrometheusRule CRD
    scrapeconfigs : ValuesCrdsScrapeconfigs, optional
        # prometheusrules configures the PrometheusRule CRD
    servicemonitors : ValuesCrdsServicemonitors, optional
        # servicemonitors configures the ServiceMonitor CRD
    thanosrulers : ValuesCrdsThanosrulers, optional
        # thanosrulers configures the ThanosRuler CRD
    """
    [...str]: any
    alertmanagerconfigs?: ValuesCrdsAlertmanagerconfigs
    alertmanagers?: ValuesCrdsAlertmanagers
    annotations?: ValuesCrdsAnnotations
    create?: bool
    deploy?: bool
    deployAlloyCRD?: bool
    deployPodLogsCRD?: bool
    podmonitors?: ValuesCrdsPodmonitors
    probes?: ValuesCrdsProbes
    prometheusagents?: ValuesCrdsPrometheusagents
    prometheuses?: ValuesCrdsPrometheuses
    prometheusrules?: ValuesCrdsPrometheusrules
    scrapeconfigs?: ValuesCrdsScrapeconfigs
    servicemonitors?: ValuesCrdsServicemonitors
    thanosrulers?: ValuesCrdsThanosrulers

schema ValuesCrdsAlertmanagerconfigs:
    r"""
    # alertmanagerconfigs configures the AlertManagerConfig CRD

    Attributes
    ----------
    enabled : bool, optional, default is True
        # enabled defines if the CRD should be installed
    """
    [...str]: any
    enabled?: bool

schema ValuesCrdsAlertmanagers:
    r"""
    # alertmanagers configures the AlertManager CRD

    Attributes
    ----------
    enabled : bool, optional, default is True
        # enabled defines if the CRD should be installed
    """
    [...str]: any
    enabled?: bool

schema ValuesCrdsAnnotations:
    r"""
    # annotations add additional annotations to all CRDs
    """
    [...str]: any

schema ValuesCrdsPodmonitors:
    r"""
    # podmonitors configures the PodMonitor CRD

    Attributes
    ----------
    enabled : bool, optional, default is True
        # enabled defines if the CRD should be installed
    """
    [...str]: any
    enabled?: bool

schema ValuesCrdsProbes:
    r"""
    # probes configures the Probe CRD

    Attributes
    ----------
    enabled : bool, optional, default is True
        # enabled defines if the CRD should be installed
    """
    [...str]: any
    enabled?: bool

schema ValuesCrdsPrometheusagents:
    r"""
    # prometheusagents configures the PrometheusAgent CRD

    Attributes
    ----------
    enabled : bool, optional, default is True
        # enabled defines if the CRD should be installed
    """
    [...str]: any
    enabled?: bool

schema ValuesCrdsPrometheuses:
    r"""
    # prometheuses configures the Prometheus CRD

    Attributes
    ----------
    enabled : bool, optional, default is True
        # enabled defines if the CRD should be installed
    """
    [...str]: any
    enabled?: bool

schema ValuesCrdsPrometheusrules:
    r"""
    # prometheusrules configures the PrometheusRule CRD

    Attributes
    ----------
    enabled : bool, optional, default is True
        # enabled defines if the CRD should be installed
    """
    [...str]: any
    enabled?: bool

schema ValuesCrdsScrapeconfigs:
    r"""
    # prometheusrules configures the PrometheusRule CRD

    Attributes
    ----------
    enabled : bool, optional, default is True
        # enabled defines if the CRD should be installed
    """
    [...str]: any
    enabled?: bool

schema ValuesCrdsServicemonitors:
    r"""
    # servicemonitors configures the ServiceMonitor CRD

    Attributes
    ----------
    enabled : bool, optional, default is True
        # enabled defines if the CRD should be installed
    """
    [...str]: any
    enabled?: bool

schema ValuesCrdsThanosrulers:
    r"""
    # thanosrulers configures the ThanosRuler CRD

    Attributes
    ----------
    enabled : bool, optional, default is True
        # enabled defines if the CRD should be installed
    """
    [...str]: any
    enabled?: bool

schema ValuesCustomLabels:
    r"""
    # Additional labels to add to all resources
    """
    [...str]: any

schema ValuesCustomResourceState:
    r"""
    Enabling support for customResourceState, will create a configMap including your config that will be read from kube-state-metrics

    Attributes
    ----------
    config : ValuesCustomResourceStateConfig, optional
        Definition of the CustomResourceStateMetrics. Add (Cluster)Role permissions to list/watch the resources defined in the config to rbac.extraRules.
    create : bool, optional, default is True
        Whether to create the ConfigMap that holds the config.
    enabled : bool, optional, default is False
        Whether to enable support for CustomResourceStateMetrics.
    key : str, optional, default is "config.yaml"
        ConfigMap key that holds the config.
    name : str, optional, default is ""
        Name of the ConfigMap that holds the config. If empty, name will be generated based on the release name.
    """
    [...str]: any
    config?: ValuesCustomResourceStateConfig
    create?: bool
    enabled?: bool
    key?: str
    name?: str

schema ValuesCustomResourceStateConfig:
    r"""
    Definition of the CustomResourceStateMetrics. Add (Cluster)Role permissions to list/watch the resources defined in the config to rbac.extraRules.
    """
    [...str]: any

schema ValuesDaemonsetAnnotations:
    r"""
    Annotations to be added to windows exporter daemonset
    """
    [...str]: any

schema ValuesDcgmExporter:
    r"""
    Scrape metrics/logs from DCGM Exporter

    Attributes
    ----------
    instances : [any], optional
    """
    [...str]: any
    instances?: [any]

schema ValuesDestinationsMap:
    r"""
    A map of destinations where telemetry data will be sent. Keys will be used as the destination name.
    See the [destinations documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/destinations/README.md) for more information.
    """
    [...str]: any

schema ValuesDnsConfig:
    r"""
    Custom DNS configuration to be added to prometheus-windows-exporter pods
    """
    [...str]: any

schema ValuesEbpf:
    r"""
    Settings for gathering profiles using eBPF

    Attributes
    ----------
    annotationSelectors : ValuesEbpfAnnotationSelectors, optional
        Select pods to profile based on pod annotations.
        Example: `color: "green"` will select pods with the annotation `color="green"`.
        Example with multiple values: `color: ["blue", "green"]` will select pods with the annotation `color="blue"` or
        `color="green"`.
    annotations : ValuesEbpfAnnotations, optional
        Configure the annotations that will control how the targets are discovered and how profiles are collected.
        All annotations will be `<prefix>/cpu.ebpf.<action>`, for example, to "enable" collecting profiles using eBPF, set
        the annotation `profiles.grafana.com/cpu.ebpf.scrape: "true"` on the pod.
    demangle : str, optional, default is "none"
        C++ demangle mode. Available options are: none, simplified, templates, full
    enabled : bool, optional, default is True
        Gather profiles using eBPF
    excludeNamespaces : [any], optional
        Which namespaces to exclude looking for pods.
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for eBPF profile sources.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with `__` (i.e. `__meta_kubernetes*`) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    labelSelectors : ValuesEbpfLabelSelectors, optional
        Select pods to profile based on pod labels.
        Example: `app.kubernetes.io/name: myapp` will select pods with the label `app.kubernetes.io/name=myapp`.
        Example with multiple values: `app.kubernetes.io/name: [myapp, myapp2]` will select pods with the label
        `app.kubernetes.io/name=myapp` or `app.kubernetes.io/name=myapp2`.
    namespaces : [any], optional
        Select pods to profile based on their namespaces.
    targetingScheme : str, optional, default is "annotation"
        How to target pods for collecting profiles with eBPF. Options are `all` and `annotation`. If using `all`, all
        Kubernetes pods will be targeted for collecting profiles, and you can exclude certain pods by setting the
        `profiles.grafana.com/cpu.ebpf.enabled="false"` annotation on that pod. If using `annotation`, only pods with the
        `profiles.grafana.com/cpu.ebpf.enabled="true"` annotation will have profiles collected with eBPF.
    """
    [...str]: any
    annotationSelectors?: ValuesEbpfAnnotationSelectors
    annotations?: ValuesEbpfAnnotations
    demangle?: str
    enabled?: bool
    excludeNamespaces?: [any]
    extraDiscoveryRules?: str
    labelSelectors?: ValuesEbpfLabelSelectors
    namespaces?: [any]
    targetingScheme?: str

schema ValuesEbpfAnnotationSelectors:
    r"""
    Select pods to profile based on pod annotations.
    Example: `color: "green"` will select pods with the annotation `color="green"`.
    Example with multiple values: `color: ["blue", "green"]` will select pods with the annotation `color="blue"` or
    `color="green"`.
    """
    [...str]: any

schema ValuesEbpfAnnotations:
    r"""
    Configure the annotations that will control how the targets are discovered and how profiles are collected.
    All annotations will be `<prefix>/cpu.ebpf.<action>`, for example, to "enable" collecting profiles using eBPF, set
    the annotation `profiles.grafana.com/cpu.ebpf.scrape: "true"` on the pod.

    Attributes
    ----------
    enable : str, optional, default is "enabled"
        The annotation action for enabling or disabling collecting of profiles with eBPF.
    """
    [...str]: any
    enable?: str

schema ValuesEbpfLabelSelectors:
    r"""
    Select pods to profile based on pod labels.
    Example: `app.kubernetes.io/name: myapp` will select pods with the label `app.kubernetes.io/name=myapp`.
    Example with multiple values: `app.kubernetes.io/name: [myapp, myapp2]` will select pods with the label
    `app.kubernetes.io/name=myapp` or `app.kubernetes.io/name=myapp2`.
    """
    [...str]: any

schema ValuesEnv:
    r"""
    Additional environment variables that will be passed to the daemonset
    """
    [...str]: any

schema ValuesEnvValueFrom:
    r"""
    extra environment variables to be set from resources such as k8s configMaps/secrets
    """
    [...str]: any

schema ValuesEtcd:
    r"""
    Scrape metrics/logs from etcd

    Attributes
    ----------
    instances : [any], optional
    """
    [...str]: any
    instances?: [any]

schema ValuesExporter:
    r"""
    Settings for the Alloy embedded MySQL Exporter

    Attributes
    ----------
    collectors : [str], optional
        The list of collectors to enable for the MySQL Exporter ([Documentation](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.exporter.mysql/#supported-collectors)).
    dataSource : ValuesExporterDataSource, optional
        The data source to use for the MySQL Exporter.
    dataSourceName : str, optional
        The data source string to use for the MySQL Exporter.
    """
    [...str]: any
    collectors?: [str]
    dataSource?: ValuesExporterDataSource
    dataSourceName?: str

schema ValuesExporterDataSource:
    r"""
    The data source to use for the MySQL Exporter.

    Attributes
    ----------
    auth : ValuesExporterDataSourceAuth, optional
    host : str, optional
        The MySQL host to connect to.
    port : int, optional
        The MySQL port to connect to.
    $protocol : str, optional
        The MySQL protocol type.
    """
    [...str]: any
    auth?: ValuesExporterDataSourceAuth
    host?: str
    port?: int
    $protocol?: str

schema ValuesExporterDataSourceAuth:
    r"""
    ValuesExporterDataSourceAuth

    Attributes
    ----------
    password : str, optional
        The password to use for the MySQL connection.
    passwordFrom : str, optional
        Raw config for accessing the password.
    passwordKey : str, optional
        The key for storing the password in the secret.
    username : str, optional
        The username to use for the MySQL connection.
    usernameFrom : str, optional
        Raw config for accessing the username.
    usernameKey : str, optional
        The key for storing the username in the secret.
    """
    [...str]: any
    password?: str
    passwordFrom?: str
    passwordKey?: str
    username?: str
    usernameFrom?: str
    usernameKey?: str

schema ValuesExtraEnvVars:
    r"""
    Extra environment variables

    Attributes
    ----------
    CGROUP_METRICS : str, optional, default is "*"
    CPU_ARCH_OVERRIDE : str, optional, default is ""
    ENABLE_EBPF_CGROUPID : str, optional, default is "true"
    ENABLE_GPU : str, optional, default is "true"
        METRIC_PATH: "/metrics"
        BIND_ADDRESS: "0.0.0.0:9102"
    ENABLE_PROCESS_METRICS : str, optional, default is "false"
    ENABLE_QAT : str, optional, default is "false"
    EXPOSE_CGROUP_METRICS : str, optional, default is "false"
    EXPOSE_HW_COUNTER_METRICS : str, optional, default is "true"
    EXPOSE_IRQ_COUNTER_METRICS : str, optional, default is "true"
    KEPLER_LOG_LEVEL : str, optional, default is "1"
    """
    [...str]: any
    CGROUP_METRICS?: str
    CPU_ARCH_OVERRIDE?: str
    ENABLE_EBPF_CGROUPID?: str
    ENABLE_GPU?: str
    ENABLE_PROCESS_METRICS?: str
    ENABLE_QAT?: str
    EXPOSE_CGROUP_METRICS?: str
    EXPOSE_HW_COUNTER_METRICS?: str
    EXPOSE_IRQ_COUNTER_METRICS?: str
    KEPLER_LOG_LEVEL?: str

schema ValuesExtraHeaders:
    r"""
    Extra headers to be set when sending data.
    All values are treated as strings and automatically quoted.
    """
    [...str]: any

schema ValuesExtraHeadersFrom:
    r"""
    Extra headers to be set when sending data through a dynamic reference.
    All values are treated as raw strings and not quoted.
    """
    [...str]: any

schema ValuesExtraLabels:
    r"""
    Extra labels to be added to all profiles before delivering to the destination.
    All values are treated as strings and automatically quoted.
    """
    [...str]: any

schema ValuesExtraLabelsFrom:
    r"""
    Extra labels to be added to all profiles using a dynamic reference before delivering to the destination.
    All values are treated as raw strings and not quoted.
    """
    [...str]: any

schema ValuesFilelogGatherSettings:
    r"""
    ValuesFilelogGatherSettings

    Attributes
    ----------
    onlyGatherNewLogLines : bool, optional, default is False
        Only gather new log lines since this was deployed. Do not gather historical log lines.
    """
    [...str]: any
    onlyGatherNewLogLines?: bool

schema ValuesGlobal:
    r"""

    Global settings


    Attributes
    ----------
    image : ValuesGlobalImage, optional
    imagePullSecrets : [any], optional
        To help compatibility with other charts which use global.imagePullSecrets.
        Allow either an array of {name: pullSecret} maps (k8s-style), or an array of strings (more common helm-style).
        global:
          imagePullSecrets:
          - name: pullSecret1
          - name: pullSecret2
        or
        global:
          imagePullSecrets:
          - pullSecret1
          - pullSecret2
    imageRegistry : str, optional, default is ""

        Allow parent charts to override registry hostname
    kubernetesAPIService : str, optional, default is ""
        The Kubernetes service. Change this if your cluster DNS is configured differently than the default.
    maxCacheSize : int, optional, default is 100000
        Sets the max_cache_size for every prometheus.relabel component. ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        This should be at least 2x-5x your largest scrape target or samples appended rate.
    platform : str, optional, default is ""
        The specific platform for this cluster. Will enable compatibility for some platforms. Supported options: (empty) or "openshift".
    podSecurityContext : ValuesGlobalPodSecurityContext, optional
        Security context to apply to the Grafana Alloy pod.
    scrapeClassicHistograms : bool, optional, default is False
        Whether to scrape a classic histogram that’s also exposed as a native histogram.
    scrapeInterval : str, optional, default is "60s"
        How frequently to scrape metrics.
    scrapeProtocols : [str], optional
        The protocols to negotiate during a Prometheus metrics scrape, in order of preference.
    scrapeTimeout : str, optional, default is "10s"
        The timeout for scraping metrics.
    """
    [...str]: any
    image?: ValuesGlobalImage
    imagePullSecrets?: [any]
    imageRegistry?: str
    kubernetesAPIService?: str
    maxCacheSize?: int
    platform?: str
    podSecurityContext?: ValuesGlobalPodSecurityContext
    scrapeClassicHistograms?: bool
    scrapeInterval?: str
    scrapeProtocols?: [str]
    scrapeTimeout?: str

schema ValuesGlobalImage:
    r"""
    ValuesGlobalImage

    Attributes
    ----------
    pullSecrets : [any], optional
        Optional set of global image pull secrets.
    registry : str, optional, default is ""
        Global image registry to use if it needs to be overridden for some specific use cases (e.g local registries, custom images, ...)
    """
    [...str]: any
    pullSecrets?: [any]
    registry?: str

schema ValuesGlobalPodSecurityContext:
    r"""
    Security context to apply to the Grafana Alloy pod.
    """
    [...str]: any

schema ValuesGrafana:
    r"""
    Scrape metrics/logs from Grafana

    Attributes
    ----------
    instances : [any], optional
    """
    [...str]: any
    instances?: [any]

schema ValuesHostProcFsMount:
    r"""
    Mount the node's proc file system (/proc) at /host/proc in the container

    Attributes
    ----------
    mountPropagation : str, optional, default is ""
        Possible values are None, HostToContainer, and Bidirectional
    """
    [...str]: any
    mountPropagation?: str

schema ValuesHostRootFsMount:
    r"""
    Mount the node's root file system (/) at /host/root in the container

    Attributes
    ----------
    enabled : bool, optional, default is True
    mountPropagation : str, optional, default is "HostToContainer"
        Defines how new mounts in existing mounts on the node or in the container
        are propagated to the container or node, respectively. Possible values are
        None, HostToContainer, and Bidirectional. If this field is omitted, then
        None is used. More information on:
        https://kubernetes.io/docs/concepts/storage/volumes/#mount-propagation
    """
    [...str]: any
    enabled?: bool
    mountPropagation?: str

schema ValuesHostSysFsMount:
    r"""
    Mount the node's sys file system (/sys) at /host/sys in the container

    Attributes
    ----------
    mountPropagation : str, optional, default is ""
        Possible values are None, HostToContainer, and Bidirectional
    """
    [...str]: any
    mountPropagation?: str

schema ValuesImage:
    r"""
    Default values for prometheus-node-exporter.
    This is a YAML-formatted file.
    Declare variables to be passed into your templates.

    Attributes
    ----------
    digest : any, optional, default is ""
        Grafana Alloy image's SHA256 digest (either in format "sha256:XYZ" or "XYZ"). When set, will override `image.tag`.
    pullPolicy : str, optional, default is "IfNotPresent"
        Grafana Alloy image pull policy.
    pullSecrets : [any], optional
        Optional set of image pull secrets.
    registry : str, optional, default is "ghcr.io"
        Grafana Alloy image registry (defaults to docker.io)
    repository : str, optional, default is "prometheus-community/windows-exporter"
        Grafana Alloy image repository.
    sha : str, optional, default is ""
    tag : any, optional, default is ""
        (string) Grafana Alloy image tag. When empty, the Chart's appVersion is
        used.
    """
    [...str]: any
    digest?: any
    pullPolicy?: str
    pullSecrets?: [any]
    registry?: str
    repository?: str
    sha?: str
    tag?: any

schema ValuesIngress:
    r"""
    ValuesIngress

    Attributes
    ----------
    annotations : ValuesIngressAnnotations, optional
        For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
        See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
        ingressClassName: nginx
        Values can be templated
    enabled : bool, optional
        Enables ingress for Alloy (Faro port)
    extraPaths : [any], optional
        # Extra paths to prepend to every host configuration. This is useful when working with annotation based services.
    faroPort : int, optional
    hosts : [str], optional
    labels : ValuesIngressLabels, optional
        kubernetes.io/ingress.class: nginx
        kubernetes.io/tls-acme: "true"
    path : str, optional
    pathType : str, optional
        pathType is only for k8s >= 1.1=
    tls : [any], optional
    """
    [...str]: any
    annotations?: ValuesIngressAnnotations
    enabled?: bool
    extraPaths?: [any]
    faroPort?: int
    hosts?: [str]
    labels?: ValuesIngressLabels
    path?: str
    pathType?: str
    tls?: [any]

schema ValuesIngressAnnotations:
    r"""
    For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
    See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
    ingressClassName: nginx
    Values can be templated
    """
    [...str]: any

schema ValuesIngressLabels:
    r"""
    kubernetes.io/ingress.class: nginx
    kubernetes.io/tls-acme: "true"
    """
    [...str]: any

schema ValuesIntegrations:
    r"""
    Service Integrations enables gathering telemetry data for common services and applications deployed to Kubernetes.
    To see the valid options, please see the [Service Integrations documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-integrations).

    Attributes
    ----------
    collector : str, optional, default is "alloy-metrics"
        Which collectors to assign this feature to. Do not change this unless you are sure of what you are doing.
    destinations : [any], optional
        The destinations where integration metrics will be sent. If empty, all metrics-capable destinations will be used.
    """
    [...str]: any
    collector?: str
    destinations?: [any]

schema ValuesJava:
    r"""
    ValuesJava

    Attributes
    ----------
    annotationSelectors : ValuesJavaAnnotationSelectors, optional
        Select pods to profile based on pod annotations.
        Example: `color: "green"` will select pods with the annotation `color="green"`.
        Example with multiple values: `color: ["blue", "green"]` will select pods with the annotation `color="blue"` or
        `color="green"`.
    annotations : ValuesJavaAnnotations, optional
        Configure the annotations that will control how the Java targets are discovered and how profiles are collected.
        All annotations will be `<prefix>/java.<action>`, for example, to "enable" scraping of Java profiles, set the
        annotation `profiles.grafana.com/java.enabled: "true"` on the pod.
    enabled : bool, optional, default is True
        Gather profiles by attaching async-profiler to the Java runtime.
    excludeNamespaces : [any], optional
        Which namespaces to exclude looking for pods.
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for Java profile sources.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    labelSelectors : ValuesJavaLabelSelectors, optional
        Select pods to profile based on pod labels.
        Example: `app.kubernetes.io/name: myapp` will select pods with the label `app.kubernetes.io/name=myapp`.
        Example with multiple values: `app.kubernetes.io/name: [myapp, myapp2]` will select pods with the label
        `app.kubernetes.io/name=myapp` or `app.kubernetes.io/name=myapp2`.
    namespaces : [any], optional
        Select pods to profile based on their namespaces.
    profilingConfig : ValuesJavaProfilingConfig, optional
        Configuration for the async-profiler
    targetingScheme : str, optional, default is "annotation"
        How to target pods for finding Java profiles. Options are `all` and `annotation`. If using `all`, all Kubernetes
        pods will be targeted for Java profiles, and you can exclude certain pods by setting the
        `profiles.grafana.com/java.enabled="false"` annotation on that pod. If using `annotation`, only pods with the
        `profiles.grafana.com/java.enabled="true"` annotation will collecting Java profiles.
    """
    [...str]: any
    annotationSelectors?: ValuesJavaAnnotationSelectors
    annotations?: ValuesJavaAnnotations
    enabled?: bool
    excludeNamespaces?: [any]
    extraDiscoveryRules?: str
    labelSelectors?: ValuesJavaLabelSelectors
    namespaces?: [any]
    profilingConfig?: ValuesJavaProfilingConfig
    targetingScheme?: str

schema ValuesJavaAnnotationSelectors:
    r"""
    Select pods to profile based on pod annotations.
    Example: `color: "green"` will select pods with the annotation `color="green"`.
    Example with multiple values: `color: ["blue", "green"]` will select pods with the annotation `color="blue"` or
    `color="green"`.
    """
    [...str]: any

schema ValuesJavaAnnotations:
    r"""
    Configure the annotations that will control how the Java targets are discovered and how profiles are collected.
    All annotations will be `<prefix>/java.<action>`, for example, to "enable" scraping of Java profiles, set the
    annotation `profiles.grafana.com/java.enabled: "true"` on the pod.

    Attributes
    ----------
    enable : str, optional, default is "enabled"
        The annotation action for enabling or disabling of Java profile collection.
    """
    [...str]: any
    enable?: str

schema ValuesJavaLabelSelectors:
    r"""
    Select pods to profile based on pod labels.
    Example: `app.kubernetes.io/name: myapp` will select pods with the label `app.kubernetes.io/name=myapp`.
    Example with multiple values: `app.kubernetes.io/name: [myapp, myapp2]` will select pods with the label
    `app.kubernetes.io/name=myapp` or `app.kubernetes.io/name=myapp2`.
    """
    [...str]: any

schema ValuesJavaProfilingConfig:
    r"""
    Configuration for the async-profiler

    Attributes
    ----------
    alloc : str, optional, default is "512k"
    cpu : bool, optional, default is True
    interval : str, optional, default is "60s"
    lock : str, optional, default is "10ms"
    sampleRate : int, optional, default is 100
    """
    [...str]: any
    alloc?: str
    cpu?: bool
    interval?: str
    lock?: str
    sampleRate?: int

schema ValuesJournal:
    r"""
    ValuesJournal

    Attributes
    ----------
    formatAsJson : bool, optional, default is False
        Whether to forward the original journal entry as JSON.
    jobLabel : str, optional, default is "integrations/kubernetes/journal"
        The value for the job label for journal logs.
    maxAge : str, optional, default is "8h"
        The path to the journal logs on the worker node.
    path : str, optional, default is "/var/log/journal"
        The path to the journal logs on the worker node.
    units : [any], optional
        The list of systemd units to keep scraped logs from, this can be a valid RE2 regular expression. If empty, all
        units are scraped.
    """
    [...str]: any
    formatAsJson?: bool
    jobLabel?: str
    maxAge?: str
    path?: str
    units?: [any]

schema ValuesK8SCache:
    r"""
    Options to deploy the Kubernetes metadata cache as a separate service

    Attributes
    ----------
    annotations : ValuesK8SCacheAnnotations, optional
        Deployment annotations.
    env : ValuesK8SCacheEnv, optional
        # Env variables that will override configmap values
        # For example:
        #   BEYLA_K8S_CACHE_LOG_LEVEL: "debug"
        extra environment variables
    envValueFrom : ValuesK8SCacheEnvValueFrom, optional
        extra environment variables to be set from resources such as k8s configMaps/secrets
    image : ValuesK8SCacheImage, optional
        We usually recommend not to specify default resources and to leave this as a conscious
        choice for the user. This also increases chances charts run on environments with little
        resources, such as Minikube. If you do want to specify resources, uncomment the following
        lines, adjust them as necessary, and remove the curly braces after 'resources:'.
        limits:
          cpu: 100m
          memory: 128Mi
        requests:
          cpu: 100m
          memory: 128Mi
    internalMetrics : ValuesK8SCacheInternalMetrics, optional
    podAnnotations : ValuesK8SCachePodAnnotations, optional
        Adds custom annotations to the Beyla Kube Cache Pods.
    podLabels : ValuesK8SCachePodLabels, optional
        Adds custom labels to the Beyla Kube Cache Pods.
    profilePort : int, optional, default is 0
        Enables the profile port for the Beyla cache
    replicas : int, optional, default is 0
        Number of replicas for the Kubernetes metadata cache service. 0 disables the service.
    resources : ValuesK8SCacheResources, optional
         ENV_NAME:
           secretKeyRef:
             name: secret-name
             key: value_key
    service : ValuesK8SCacheService, optional
    """
    [...str]: any
    annotations?: ValuesK8SCacheAnnotations
    env?: ValuesK8SCacheEnv
    envValueFrom?: ValuesK8SCacheEnvValueFrom
    image?: ValuesK8SCacheImage
    internalMetrics?: ValuesK8SCacheInternalMetrics
    podAnnotations?: ValuesK8SCachePodAnnotations
    podLabels?: ValuesK8SCachePodLabels
    profilePort?: int
    replicas?: int
    resources?: ValuesK8SCacheResources
    service?: ValuesK8SCacheService

schema ValuesK8SCacheAnnotations:
    r"""
    Deployment annotations.
    """
    [...str]: any

schema ValuesK8SCacheEnv:
    r"""
    # Env variables that will override configmap values
    # For example:
    #   BEYLA_K8S_CACHE_LOG_LEVEL: "debug"
    extra environment variables
    """
    [...str]: any

schema ValuesK8SCacheEnvValueFrom:
    r"""
    extra environment variables to be set from resources such as k8s configMaps/secrets
    """
    [...str]: any

schema ValuesK8SCacheImage:
    r"""
    We usually recommend not to specify default resources and to leave this as a conscious
    choice for the user. This also increases chances charts run on environments with little
    resources, such as Minikube. If you do want to specify resources, uncomment the following
    lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi

    Attributes
    ----------
    digest : any, optional, default is "null"
        K8s Cache image's SHA256 digest (either in format "sha256:XYZ" or "XYZ"). When set, will override `image.tag`.
    pullPolicy : str, optional, default is "IfNotPresent"
        K8s Cache image pull policy.
    pullSecrets : [any], optional
        Optional set of image pull secrets.
    registry : str, optional, default is "docker.io"
        K8s Cache image registry (defaults to docker.io)
    repository : str, optional, default is "grafana/beyla-k8s-cache"
        K8s Cache image repository.
    tag : any, optional, default is "null"
        (string) K8s Cache image tag. When empty, the Chart's appVersion is used.
    """
    [...str]: any
    digest?: any
    pullPolicy?: str
    pullSecrets?: [any]
    registry?: str
    repository?: str
    tag?: any

schema ValuesK8SCacheInternalMetrics:
    r"""
    ValuesK8SCacheInternalMetrics

    Attributes
    ----------
    path : str, optional, default is "/metrics"
    port : int, optional, default is 0
        0: disabled by default
    portName : str, optional, default is "metrics"
    """
    [...str]: any
    path?: str
    port?: int
    portName?: str

schema ValuesK8SCachePodAnnotations:
    r"""
    Adds custom annotations to the Beyla Kube Cache Pods.
    """
    [...str]: any

schema ValuesK8SCachePodLabels:
    r"""
    Adds custom labels to the Beyla Kube Cache Pods.
    """
    [...str]: any

schema ValuesK8SCacheResources:
    r"""
     ENV_NAME:
       secretKeyRef:
         name: secret-name
         key: value_key
    """
    [...str]: any

schema ValuesK8SCacheService:
    r"""
    ValuesK8SCacheService

    Attributes
    ----------
    annotations : ValuesK8SCacheServiceAnnotations, optional
        Service annotations.
    labels : ValuesK8SCacheServiceLabels, optional
        Service labels.
    name : str, optional, default is "beyla-k8s-cache"
        Name of both the Service and Deployment
    port : int, optional, default is 50055
        Port of the Kubernetes metadata cache service.
    """
    [...str]: any
    annotations?: ValuesK8SCacheServiceAnnotations
    labels?: ValuesK8SCacheServiceLabels
    name?: str
    port?: int

schema ValuesK8SCacheServiceAnnotations:
    r"""
    Service annotations.
    """
    [...str]: any

schema ValuesK8SCacheServiceLabels:
    r"""
    Service labels.
    """
    [...str]: any

schema ValuesKepler:
    r"""
    Kepler gathers energy metrics for the Kubernetes Cluster and the objects running inside.

    Attributes
    ----------
    affinity : ValuesKeplerAffinity, optional
    canMount : ValuesKeplerCanMount, optional
    enabled : bool, optional, default is False
        Deploy and scrape Kepler metrics.
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for Kepler.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with __ (i.e. __meta_kubernetes*) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraEnvVars : ValuesKeplerExtraEnvVars, optional
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for Kepler. ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no __meta* labels are present.
    jobLabel : str, optional, default is "integrations/kepler"
        The value for the job label.
    labelMatchers : ValuesKeplerLabelMatchers, optional
        Label matchers used to select the Kepler pods
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for the prometheus.relabel component for Kepler.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides global.maxCacheSize
    metricsTuning : ValuesKeplerMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    podAnnotations : ValuesKeplerPodAnnotations, optional
    scrapeInterval : str, optional, default is ""
        How frequently to scrape metrics from Kepler.
        Overrides global.scrapeInterval.
    scrapeTimeout : str, optional, default is ""
        The timeout for scraping Kepler metrics.
    """
    [...str]: any
    affinity?: ValuesKeplerAffinity
    canMount?: ValuesKeplerCanMount
    enabled?: bool
    extraDiscoveryRules?: str
    extraEnvVars?: ValuesKeplerExtraEnvVars
    extraMetricProcessingRules?: str
    jobLabel?: str
    labelMatchers?: ValuesKeplerLabelMatchers
    maxCacheSize?: any
    metricsTuning?: ValuesKeplerMetricsTuning
    podAnnotations?: ValuesKeplerPodAnnotations
    scrapeInterval?: str
    scrapeTimeout?: str

schema ValuesKeplerAffinity:
    r"""
    ValuesKeplerAffinity

    Attributes
    ----------
    nodeAffinity : ValuesKeplerAffinityNodeAffinity, optional
    """
    [...str]: any
    nodeAffinity?: ValuesKeplerAffinityNodeAffinity

schema ValuesKeplerAffinityNodeAffinity:
    r"""
    ValuesKeplerAffinityNodeAffinity

    Attributes
    ----------
    requiredDuringSchedulingIgnoredDuringExecution : ValuesKeplerAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution, optional
    """
    [...str]: any
    requiredDuringSchedulingIgnoredDuringExecution?: ValuesKeplerAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution

schema ValuesKeplerAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution:
    r"""
    ValuesKeplerAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution

    Attributes
    ----------
    nodeSelectorTerms : [ValuesKeplerAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0], optional
    """
    [...str]: any
    nodeSelectorTerms?: [ValuesKeplerAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0]

schema ValuesKeplerAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0:
    r"""
    ValuesKeplerAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0

    Attributes
    ----------
    matchExpressions : [ValuesKeplerAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0MatchExpressionsItems0], optional
    """
    [...str]: any
    matchExpressions?: [ValuesKeplerAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0MatchExpressionsItems0]

schema ValuesKeplerAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0MatchExpressionsItems0:
    r"""
    ValuesKeplerAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0MatchExpressionsItems0

    Attributes
    ----------
    key : str, optional, default is "eks.amazonaws.com/compute-type"
    operator : str, optional, default is "NotIn"
    values : [str], optional
    """
    [...str]: any
    key?: str
    operator?: str
    values?: [str]

schema ValuesKeplerCanMount:
    r"""
    ValuesKeplerCanMount

    Attributes
    ----------
    usrSrc : bool, optional, default is False
    """
    [...str]: any
    usrSrc?: bool

schema ValuesKeplerExtraEnvVars:
    r"""
    ValuesKeplerExtraEnvVars

    Attributes
    ----------
    EXPOSE_ESTIMATED_IDLE_POWER_METRICS : str, optional, default is "true"
    """
    [...str]: any
    EXPOSE_ESTIMATED_IDLE_POWER_METRICS?: str

schema ValuesKeplerLabelMatchers:
    r"""
    Label matchers used to select the Kepler pods

    Attributes
    ----------
    "app.kubernetes.io/name" : str, optional, default is "kepler"
    """
    [...str]: any
    "app.kubernetes.io/name"?: str

schema ValuesKeplerMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions.
    useDefaultAllowList : bool, optional, default is True
        Filter the list of metrics from Kepler to the minimal set required for Kubernetes Monitoring.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]
    useDefaultAllowList?: bool

schema ValuesKeplerPodAnnotations:
    r"""
    ValuesKeplerPodAnnotations

    Attributes
    ----------
    "k8s.grafana.com/logs.job" : str, optional, default is "integrations/kepler"
    """
    [...str]: any
    "k8s.grafana.com/logs.job"?: str

schema ValuesKubeControllerManager:
    r"""
    Metrics from the Kube Controller Manager

    Attributes
    ----------
    enabled : any, optional, default is ""
        (bool) Scrape metrics from the Kube Controller Manager
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for the Kube Controller Manager.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with `__` (i.e. `__meta_kubernetes*`) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for the Kube Controller Manager.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    jobLabel : str, optional, default is "kube-controller-manager"
        The value for the job label.
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for the Kube Controller Manager prometheus.relabel component.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides metrics.maxCacheSize
    metricsTuning : ValuesKubeControllerManagerMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    port : int, optional, default is 10257
        Port number used by the Kube Controller Manager, set by `--secure-port.`
    scrapeInterval : str, optional, default is ""
        How frequently to scrape metrics from the Kube Controller Manager
        Overrides metrics.scrapeInterval
    selectorLabel : str, optional, default is "component=kube-controller-manager"
        Selector label.
    """
    [...str]: any
    enabled?: any
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    jobLabel?: str
    maxCacheSize?: any
    metricsTuning?: ValuesKubeControllerManagerMetricsTuning
    port?: int
    scrapeInterval?: str
    selectorLabel?: str

schema ValuesKubeControllerManagerMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions. An empty list means keep all.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]

schema ValuesKubeDns:
    r"""
    Metrics from the KubeDNS

    Attributes
    ----------
    enabled : any, optional, default is ""
        (bool) Scrape metrics from KubeDNS
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for KubeDNS.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with `__` (i.e. `__meta_kubernetes*`) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for KubeDNS.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    jobLabel : str, optional, default is "integrations/kubernetes/kube-dns"
        The value for the job label.
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for the KubeDNS prometheus.relabel component.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides metrics.maxCacheSize
    metricsTuning : ValuesKubeDnsMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    scrapeInterval : str, optional, default is ""
        How frequently to scrape metrics from KubeDNS
        Overrides metrics.scrapeInterval
    scrapeTimeout : str, optional, default is ""
        The timeout for scraping KubeDNS metrics.
    """
    [...str]: any
    enabled?: any
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    jobLabel?: str
    maxCacheSize?: any
    metricsTuning?: ValuesKubeDnsMetricsTuning
    scrapeInterval?: str
    scrapeTimeout?: str

schema ValuesKubeDnsMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions. An empty list means keep all.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]

schema ValuesKubeProxy:
    r"""
    Metrics from the Kube Proxy

    Attributes
    ----------
    enabled : any, optional, default is ""
        (bool) Scrape metrics from the Kube Proxy
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for the Kube Proxy.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with `__` (i.e. `__meta_kubernetes*`) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for the Kube Proxy.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    jobLabel : str, optional, default is "integrations/kubernetes/kube-proxy"
        The value for the job label.
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for the Kube Proxy prometheus.relabel component.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides metrics.maxCacheSize
    metricsTuning : ValuesKubeProxyMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    port : int, optional, default is 10249
        Port number used by the Kube Proxy, set in `--metrics-bind-address`.
    scrapeInterval : str, optional, default is ""
        How frequently to scrape metrics from the Kube Proxy
        Overrides metrics.scrapeInterval
    scrapeTimeout : str, optional, default is ""
        The timeout for scraping Kube Proxy metrics.
    selectorLabel : str, optional, default is "k8s-app=kube-proxy"
        Selector label.
    """
    [...str]: any
    enabled?: any
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    jobLabel?: str
    maxCacheSize?: any
    metricsTuning?: ValuesKubeProxyMetricsTuning
    port?: int
    scrapeInterval?: str
    scrapeTimeout?: str
    selectorLabel?: str

schema ValuesKubeProxyMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions. An empty list means keep all.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]

schema ValuesKubeRbacproxy:
    r"""
    Configure kube-rbac-proxy. When enabled, creates a kube-rbac-proxy to protect the node-exporter http endpoint.
    The requests are served through the same service but requests are HTTPS.

    Attributes
    ----------
    containerSecurityContext : ValuesKubeRbacproxyContainerSecurityContext, optional
        # Specify security settings for a Container
        # Allows overrides and additional options compared to (Pod) securityContext
        # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
    enableHostPort : bool, optional, default is False
        Configure a hostPort. If true, hostPort will be enabled in the container and set to service.port.
    enableProxyEndpointsHostPort : bool, optional, default is False
        Configure a hostPort. If true, hostPort will be enabled in the container and set to proxyEndpointsPort.
    enabled : bool, optional, default is False
    env : ValuesKubeRbacproxyEnv, optional
        # Set environment variables as name/value pairs
    extraArgs : [any], optional
        List of additional cli arguments to configure kube-rbac-proxy
        for example: --tls-cipher-suites, --log-file, etc.
        all the possible args can be found here: https://github.com/brancz/kube-rbac-proxy#usage
    extraVolumeMounts : [any], optional
        # Additional volume mounts in the kube-rbac-proxy container
        # See extraVolumes below
    ignoreProbePaths : bool, optional, default is True
        This set --ignore-paths=/livez,/readyz to kubeRBACProxy container args
        to allow the pod probes working properly with kubeRBACProxy enabled.
    image : ValuesKubeRbacproxyImage, optional
        VARIABLE: value
    port : int, optional, default is 8100
        Specify the port used for the Node exporter container (upstream port)
    portName : str, optional, default is "http"
        Specify the name of the container port
    proxyEndpointsPort : int, optional, default is 8888
        Configure Proxy Endpoints Port
        This is the port being probed for readiness
    resources : ValuesKubeRbacproxyResources, optional
    tls : ValuesKubeRbacproxyTls, optional
        # tls enables using TLS resources from a volume on secret referred to in tlsSecret below.
        # When enabling tlsClientAuth, client CA certificate must be set in tlsSecret.caItem.
        # Ref. https://github.com/brancz/kube-rbac-proxy/issues/187
    volumeMounts : [any], optional
        # volumeMounts enables mounting custom volumes in rbac-proxy containers
        # Useful for TLS certificates and keys
    """
    [...str]: any
    containerSecurityContext?: ValuesKubeRbacproxyContainerSecurityContext
    enableHostPort?: bool
    enableProxyEndpointsHostPort?: bool
    enabled?: bool
    env?: ValuesKubeRbacproxyEnv
    extraArgs?: [any]
    extraVolumeMounts?: [any]
    ignoreProbePaths?: bool
    image?: ValuesKubeRbacproxyImage
    port?: int
    portName?: str
    proxyEndpointsPort?: int
    resources?: ValuesKubeRbacproxyResources
    tls?: ValuesKubeRbacproxyTls
    volumeMounts?: [any]

schema ValuesKubeRbacproxyContainerSecurityContext:
    r"""
    # Specify security settings for a Container
    # Allows overrides and additional options compared to (Pod) securityContext
    # Ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container

    Attributes
    ----------
    allowPrivilegeEscalation : bool, optional, default is False
    capabilities : ValuesKubeRbacproxyContainerSecurityContextCapabilities, optional
    readOnlyRootFilesystem : bool, optional, default is True
    """
    [...str]: any
    allowPrivilegeEscalation?: bool
    capabilities?: ValuesKubeRbacproxyContainerSecurityContextCapabilities
    readOnlyRootFilesystem?: bool

schema ValuesKubeRbacproxyContainerSecurityContextCapabilities:
    r"""
    ValuesKubeRbacproxyContainerSecurityContextCapabilities

    Attributes
    ----------
    drop : [str], optional
    """
    [...str]: any
    drop?: [str]

schema ValuesKubeRbacproxyEnv:
    r"""
    # Set environment variables as name/value pairs
    """
    [...str]: any

schema ValuesKubeRbacproxyImage:
    r"""
    VARIABLE: value

    Attributes
    ----------
    pullPolicy : str, optional, default is "IfNotPresent"
    registry : str, optional, default is "quay.io"
    repository : str, optional, default is "brancz/kube-rbac-proxy"
    sha : str, optional, default is ""
    tag : str, optional, default is "v0.20.0"
    """
    [...str]: any
    pullPolicy?: str
    registry?: str
    repository?: str
    sha?: str
    tag?: str

schema ValuesKubeRbacproxyResources:
    r"""
    ValuesKubeRbacproxyResources
    """
    [...str]: any

schema ValuesKubeRbacproxyTls:
    r"""
    # tls enables using TLS resources from a volume on secret referred to in tlsSecret below.
    # When enabling tlsClientAuth, client CA certificate must be set in tlsSecret.caItem.
    # Ref. https://github.com/brancz/kube-rbac-proxy/issues/187

    Attributes
    ----------
    enabled : bool, optional, default is False
    tlsClientAuth : bool, optional, default is False
    """
    [...str]: any
    enabled?: bool
    tlsClientAuth?: bool

schema ValuesKubeScheduler:
    r"""
    Metrics from the Kube Scheduler

    Attributes
    ----------
    enabled : any, optional, default is ""
        (bool) Scrape metrics from the Kube Scheduler
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for the Kube Scheduler.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with `__` (i.e. `__meta_kubernetes*`) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for the Kube Scheduler.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    jobLabel : str, optional, default is "kube-scheduler"
        The value for the job label.
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for the Kube Scheduler prometheus.relabel component.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides metrics.maxCacheSize
    metricsTuning : ValuesKubeSchedulerMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    port : int, optional, default is 10259
        Port number used by the Kube Scheduler, set by `--secure-port`.
    scrapeInterval : str, optional, default is ""
        How frequently to scrape metrics from the Kube Scheduler
        Overrides metrics.scrapeInterval
    scrapeTimeout : str, optional, default is ""
        The timeout for scraping Kube Scheduler metrics.
    selectorLabel : str, optional, default is "component=kube-scheduler"
        Selector label.
    """
    [...str]: any
    enabled?: any
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    jobLabel?: str
    maxCacheSize?: any
    metricsTuning?: ValuesKubeSchedulerMetricsTuning
    port?: int
    scrapeInterval?: str
    scrapeTimeout?: str
    selectorLabel?: str

schema ValuesKubeSchedulerMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions. An empty list means keep all.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]

schema ValuesKubeStateMetrics:
    r"""
    kube-state-metrics metrics gather information about Kubernetes resources.

    Attributes
    ----------
    autosharding : ValuesKubeStateMetricsAutosharding, optional
    bearerTokenFile : str, optional, default is ""
        The bearer token file to use when scraping metrics from kube-state-metrics.
    deploy : bool, optional, default is True
        Deploy kube-state-metrics. Set to false if your cluster already has kube-state-metrics deployed.
    discoveryType : str, optional, default is "endpoints"
        How to discover the kube-state-metrics service. Either `endpoints`, `pod`, or `service`.
        Use `service` if you know there is a single kube-state-metrics replica, or are using HA. Use `endpoints` or `pod` if
        you have multiple replicas with auto-sharding.
    enabled : bool, optional, default is True
        Scrape metrics from kube-state-metrics.
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for kube-state-metrics.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with __ (i.e. __meta_kubernetes*) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for kube-state-metrics metrics.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    jobLabel : str, optional, default is "integrations/kubernetes/kube-state-metrics"
        The value for the job label.
    labelMatchers : ValuesKubeStateMetricsLabelMatchers, optional
        Labels used to select the kube-state-metrics service.
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for the kube-state-metrics prometheus.relabel component.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides global.maxCacheSize
    metricLabelsAllowlist : [str], optional
        `kube_<resource>_labels` metrics to generate.
        The default is to include a useful set for Node labels.
    metricsTuning : ValuesKubeStateMetricsMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    namespace : str, optional, default is ""
        Namespace to locate kube-state-metrics pods. If `deploy` is set to `true`, this will automatically be set to the
        namespace where this Helm chart is deployed.
    namespaces : [any], optional
        List (or comma-separated string) of namespaces to be enabled for collecting resources. By default, all namespaces
        are collected. Requires kube-state-metrics to be deployed by this chart.
    namespacesDenylist : [any], optional
        List (or comma-separated string) of namespaces to be excluded from collecting resources. If namespaces and
        namespaces denylist are both set, only namespaces that are excluded in namespaces denylist will be used.
        Requires kube-state-metrics to be deployed by this chart.
    nodeSelector : ValuesKubeStateMetricsNodeSelector, optional
    podAnnotations : ValuesKubeStateMetricsPodAnnotations, optional
    prometheusScrape : bool, optional, default is False
    releaseLabel : bool, optional, default is True
    scrapeInterval : str, optional, default is ""
        How frequently to scrape kube-state-metrics metrics.
    scrapeTimeout : str, optional, default is ""
        The timeout for scraping kube-state-metrics metrics.
    service : ValuesKubeStateMetricsService, optional
        kube-state-metrics service settings
    updateStrategy : str, optional, default is "Recreate"
    """
    [...str]: any
    autosharding?: ValuesKubeStateMetricsAutosharding
    bearerTokenFile?: str
    deploy?: bool
    discoveryType?: str
    enabled?: bool
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    jobLabel?: str
    labelMatchers?: ValuesKubeStateMetricsLabelMatchers
    maxCacheSize?: any
    metricLabelsAllowlist?: [str]
    metricsTuning?: ValuesKubeStateMetricsMetricsTuning
    namespace?: str
    namespaces?: [any]
    namespacesDenylist?: [any]
    nodeSelector?: ValuesKubeStateMetricsNodeSelector
    podAnnotations?: ValuesKubeStateMetricsPodAnnotations
    prometheusScrape?: bool
    releaseLabel?: bool
    scrapeInterval?: str
    scrapeTimeout?: str
    service?: ValuesKubeStateMetricsService
    updateStrategy?: str

schema ValuesKubeStateMetricsAutosharding:
    r"""
    ValuesKubeStateMetricsAutosharding

    Attributes
    ----------
    enabled : bool, optional, default is False
    """
    [...str]: any
    enabled?: bool

schema ValuesKubeStateMetricsLabelMatchers:
    r"""
    Labels used to select the kube-state-metrics service.

    Attributes
    ----------
    "app.kubernetes.io/name" : str, optional, default is "kube-state-metrics"
    """
    [...str]: any
    "app.kubernetes.io/name"?: str

schema ValuesKubeStateMetricsMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions.
    useDefaultAllowList : bool, optional, default is True
        Filter the list of metrics from Kube State Metrics to a useful, minimal set.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]
    useDefaultAllowList?: bool

schema ValuesKubeStateMetricsNodeSelector:
    r"""
    ValuesKubeStateMetricsNodeSelector

    Attributes
    ----------
    "kubernetes.io/os" : str, optional, default is "linux"
    """
    [...str]: any
    "kubernetes.io/os"?: str

schema ValuesKubeStateMetricsPodAnnotations:
    r"""
    ValuesKubeStateMetricsPodAnnotations

    Attributes
    ----------
    "k8s.grafana.com/logs.job" : str, optional, default is "integrations/kubernetes/kube-state-metrics"
    """
    [...str]: any
    "k8s.grafana.com/logs.job"?: str

schema ValuesKubeStateMetricsService:
    r"""
    kube-state-metrics service settings

    Attributes
    ----------
    portName : str, optional, default is "http"
        The port name used by kube-state-metrics.
    scheme : str, optional, default is "http"
        The scrape scheme used by kube-state-metrics.
    """
    [...str]: any
    portName?: str
    scheme?: str

schema ValuesKubeconfig:
    r"""
    Enabling kubeconfig will pass the --kubeconfig argument to the container

    Attributes
    ----------
    enabled : bool, optional, default is False
    secret : any, optional, default is ""
        base64 encoded kube-config file
    """
    [...str]: any
    enabled?: bool
    secret?: any

schema ValuesKubelet:
    r"""
    Kubelet metrics gather information about Kubernetes information on each node.

    Attributes
    ----------
    enabled : bool, optional, default is True
        Scrape metrics from kubelet.
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for the Kubelet.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with `__` (i.e. `__meta_kubernetes*`) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for Kubelet metrics.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    jobLabel : str, optional, default is "integrations/kubernetes/kubelet"
        The value for the job label.
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for the Kubelet prometheus.relabel component.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides global.maxCacheSize
    metricsTuning : ValuesKubeletMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    nodeAddressFormat : str, optional, default is "direct"
        How to access the Kubelet to get metrics, either "direct" (use node IP) or "proxy" (uses API Server)
    scrapeInterval : str, optional, default is ""
        How frequently to scrape Kubelet metrics.
    scrapeTimeout : str, optional, default is ""
        The timeout for scraping Kubelet metrics.
    """
    [...str]: any
    enabled?: bool
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    jobLabel?: str
    maxCacheSize?: any
    metricsTuning?: ValuesKubeletMetricsTuning
    nodeAddressFormat?: str
    scrapeInterval?: str
    scrapeTimeout?: str

schema ValuesKubeletMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions.
    useDefaultAllowList : bool, optional, default is True
        Filter the list of metrics from the Kubelet to the minimal set required for Kubernetes Monitoring.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]
    useDefaultAllowList?: bool

schema ValuesKubeletProbes:
    r"""
    Kubelet Probe metrics gather information about liveness and readiness probe information.

    Attributes
    ----------
    enabled : bool, optional, default is False
        Scrape probe metrics from the Kubelet.
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for Kubelet probes.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with `__` (i.e. `__meta_kubernetes*`) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for Kubelet probe metrics.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    jobLabel : str, optional, default is "integrations/kubernetes/probes"
        The value for the job label.
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for prometheus.relabel components.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides global.maxCacheSize
    metricsTuning : ValuesKubeletProbesMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    nodeAddressFormat : str, optional, default is "direct"
        How to access the Kubelet to get probe metrics, either "direct" (use node IP) or "proxy" (uses API Server)
    scrapeInterval : str, optional, default is ""
        How frequently to scrape Kubelet probe metrics.
    scrapeTimeout : str, optional, default is ""
        The timeout for scraping Kubelet probe metrics.
    """
    [...str]: any
    enabled?: bool
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    jobLabel?: str
    maxCacheSize?: any
    metricsTuning?: ValuesKubeletProbesMetricsTuning
    nodeAddressFormat?: str
    scrapeInterval?: str
    scrapeTimeout?: str

schema ValuesKubeletProbesMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions.
    useDefaultAllowList : bool, optional, default is True
        Filter the list of probe metrics from the Kubelet to the minimal set required for Kubernetes Monitoring.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]
    useDefaultAllowList?: bool

schema ValuesKubeletResource:
    r"""
    Kubelet Resource metrics gather information about resource information on each node.

    Attributes
    ----------
    enabled : bool, optional, default is True
        Scrape resource metrics from the Kubelet.
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for Kubelet resources.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with `__` (i.e. `__meta_kubernetes*`) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for Kubelet resource metrics.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    jobLabel : str, optional, default is "integrations/kubernetes/resources"
        The value for the job label.
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for prometheus.relabel components.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides global.maxCacheSize
    metricsTuning : ValuesKubeletResourceMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    nodeAddressFormat : str, optional, default is "direct"
        How to access the Kubelet to get resource metrics, either "direct" (use node IP) or "proxy" (uses API Server)
    scrapeInterval : str, optional, default is ""
        How frequently to scrape Kubelet resource metrics.
    scrapeTimeout : str, optional, default is ""
        The timeout for scraping Kubelet resource metrics.
    """
    [...str]: any
    enabled?: bool
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    jobLabel?: str
    maxCacheSize?: any
    metricsTuning?: ValuesKubeletResourceMetricsTuning
    nodeAddressFormat?: str
    scrapeInterval?: str
    scrapeTimeout?: str

schema ValuesKubeletResourceMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions.
    useDefaultAllowList : bool, optional, default is True
        Filter the list of resource metrics from the Kubelet to the minimal set required for Kubernetes Monitoring.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]
    useDefaultAllowList?: bool

schema ValuesLabelSelectors:
    r"""
    Filter the list of discovered pods and services by labels. Only for the "volumes" gather method.
    Example: `labelSelectors: { 'app': 'myapp' }` will only discover pods with the label `app=myapp`.
    Example: `labelSelectors: { 'app': ['myapp', 'myotherapp'] }` will only discover pods with the label `app=myapp` or `app=myotherapp`.

    Attributes
    ----------
    "app.kubernetes.io/name" : [str], optional
    """
    [...str]: any
    "app.kubernetes.io/name"?: [str]

schema ValuesLabels:
    r"""
    Labels to add to the Alloy Custom Resource. These labels are not added to the workload or Pod.

    Attributes
    ----------
    app_kubernetes_io_name : str, optional, default is "app.kubernetes.io/name"
    """
    [...str]: any
    app_kubernetes_io_name?: str

schema ValuesLeaderElection:
    r"""
    Leader election settings.

    Attributes
    ----------
    enabled : bool, optional, default is True
        Whether to enable leader election for the Alloy Operator. This is important when using multiple replicas or
        when rolling updates. If set to false, you risk having split-brain scenarios where multiple instances of the
        Alloy Operator try to manage the same Alloy instances.
    """
    [...str]: any
    enabled?: bool

schema ValuesLiveDebugging:
    r"""
    ValuesLiveDebugging

    Attributes
    ----------
    enabled : bool, optional
        Enable live debugging for the Alloy instance.
        Requires stability level to be set to "experimental".
    """
    [...str]: any
    enabled?: bool

schema ValuesLivenessProbe:
    r"""
    # Liveness probe
    #

    Attributes
    ----------
    failureThreshold : int, optional, default is 3
    httpGet : ValuesLivenessProbeHttpGet, optional
    initialDelaySeconds : int, optional, default is 0
    periodSeconds : int, optional, default is 10
    successThreshold : int, optional, default is 1
    timeoutSeconds : int, optional, default is 1
    """
    [...str]: any
    failureThreshold?: int
    httpGet?: ValuesLivenessProbeHttpGet
    initialDelaySeconds?: int
    periodSeconds?: int
    successThreshold?: int
    timeoutSeconds?: int

schema ValuesLivenessProbeHttpGet:
    r"""
    ValuesLivenessProbeHttpGet

    Attributes
    ----------
    httpHeaders : [any], optional
    path : str, optional, default is "/health"
    scheme : str, optional, default is "http"
    """
    [...str]: any
    httpHeaders?: [any]
    path?: str
    scheme?: str

schema ValuesLogging:
    r"""
    ValuesLogging

    Attributes
    ----------
    format : str, optional
        Format to use for writing Alloy log lines.
    level : str, optional
        Level at which Alloy log lines should be written.
    """
    [...str]: any
    format?: str
    level?: str

schema ValuesLogs:
    r"""
    Settings for log gathering using the Pod Logs feature

    Attributes
    ----------
    enabled : bool, optional, default is True
        Whether to send logs to the OTLP destination.
    filters : ValuesLogsFilters, optional
        Apply a filter to logs received via receivers.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.filter/))
    labelSelectors : ValuesLogsLabelSelectors, optional
        Discover MySQL instances based on label selectors. At least one is required.
    namespaces : [any], optional
        The namespaces to look for MySQL instances in.
        Will automatically look for MySQL instances in all namespaces unless specified here
    target : str, optional
        The Alloy component reference for sending logs.
        @ section -- Logs
    transforms : ValuesLogsTransforms, optional
        Apply a transformation to logs received via the OTLP or OTLP HTTP receivers.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.transform/))
    tuning : ValuesLogsTuning, optional
        Adjustments to the scraped logs to filter the amount of data sent to storage.
    """
    [...str]: any
    enabled?: bool
    filters?: ValuesLogsFilters
    labelSelectors?: ValuesLogsLabelSelectors
    namespaces?: [any]
    target?: str
    transforms?: ValuesLogsTransforms
    tuning?: ValuesLogsTuning

schema ValuesLogsFilters:
    r"""
    Apply a filter to logs received via receivers.
    ([docs](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.filter/))

    Attributes
    ----------
    log_record : [any], optional
    """
    [...str]: any
    log_record?: [any]

schema ValuesLogsLabelSelectors:
    r"""
    Discover MySQL instances based on label selectors. At least one is required.
    """
    [...str]: any

schema ValuesLogsTransforms:
    r"""
    Apply a transformation to logs received via the OTLP or OTLP HTTP receivers.
    ([docs](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.transform/))

    Attributes
    ----------
    labels : [str], optional
        The list of labels to set in the log stream.
    log : [any], optional
        Log transformation rules.
    resource : [any], optional
        Resource transformation rules.
    """
    [...str]: any
    labels?: [str]
    log?: [any]
    resource?: [any]

schema ValuesLogsTuning:
    r"""
    Adjustments to the scraped logs to filter the amount of data sent to storage.

    Attributes
    ----------
    dropLogLevels : [str], optional
        The log levels to drop.
        Will automatically keep all log levels unless specified here.
    excludeLines : [any], optional
        Line patterns (valid RE2 regular expression)to exclude from the logs.
    scrubTimestamp : bool, optional
        Whether the timestamp should be scrubbed from the log line
    structuredMetadata : ValuesLogsTuningStructuredMetadata, optional
        The structured metadata mappings to set.
        To not set any structured metadata, set this to an empty object (e.g. `{}`)
    timestampFormat : str, optional
        The timestamp format to use for the log line, if not set the default timestamp which is the collection
        will be used for the log line
    """
    [...str]: any
    dropLogLevels?: [str]
    excludeLines?: [any]
    scrubTimestamp?: bool
    structuredMetadata?: ValuesLogsTuningStructuredMetadata
    timestampFormat?: str

schema ValuesLogsTuningStructuredMetadata:
    r"""
    The structured metadata mappings to set.
    To not set any structured metadata, set this to an empty object (e.g. `{}`)
    """
    [...str]: any

schema ValuesLoki:
    r"""
    Scrape metrics/logs from Loki

    Attributes
    ----------
    instances : [any], optional
    """
    [...str]: any
    instances?: [any]

schema ValuesMetrics:
    r"""
    Settings for metrics collection

    Attributes
    ----------
    enabled : bool, optional, default is True
        Whether to send metrics to the OTLP destination.
    extraMetricProcessingRules : str, optional
        Rule blocks to be added to the prometheus.relabel component for MySQL metrics.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    filters : ValuesMetricsFilters, optional
        Apply a filter to metrics received via the OTLP or OTLP HTTP receivers.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.filter/))
    maxCacheSize : any, optional
        Sets the max_cache_size for prometheus.relabel component.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus.relabel/#arguments))
        Overrides global.maxCacheSize
    port : int, optional
        The etcd metrics port number to scrape metrics from. Defined on the etcd pod with:
        `--listen-metrics-urls=http://127.0.0.1:2381`
    portName : str, optional
        Name of the port to scrape metrics from.
    scrapeInterval : any, optional
        How frequently to scrape metrics from Tempo.
    scrapeTimeout : str, optional
        The timeout for scraping metrics from Tempo.
    target : str, optional
        The Alloy component reference for sending metrics.
        @ section -- Metrics
    transforms : ValuesMetricsTransforms, optional
        Apply a transformation to metrics received via the OTLP or OTLP HTTP receivers.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.transform/))
    tuning : ValuesMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    """
    [...str]: any
    enabled?: bool
    extraMetricProcessingRules?: str
    filters?: ValuesMetricsFilters
    maxCacheSize?: any
    port?: int
    portName?: str
    scrapeInterval?: any
    scrapeTimeout?: str
    target?: str
    transforms?: ValuesMetricsTransforms
    tuning?: ValuesMetricsTuning

schema ValuesMetricsFilters:
    r"""
    Apply a filter to metrics received via the OTLP or OTLP HTTP receivers.
    ([docs](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.filter/))

    Attributes
    ----------
    datapoint : [any], optional
    metric : [any], optional
    """
    [...str]: any
    datapoint?: [any]
    metric?: [any]

schema ValuesMetricsTransforms:
    r"""
    Apply a transformation to metrics received via the OTLP or OTLP HTTP receivers.
    ([docs](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.transform/))

    Attributes
    ----------
    datapoint : [any], optional
    metric : [any], optional
    resource : [any], optional
    """
    [...str]: any
    datapoint?: [any]
    metric?: [any]
    resource?: [any]

schema ValuesMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of metrics sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]

schema ValuesMimir:
    r"""
    Scrape metrics/logs from Mimir

    Attributes
    ----------
    instances : [any], optional
    """
    [...str]: any
    instances?: [any]

schema ValuesModelServer:
    r"""
    Configure kepler [model-server](https://sustainable-computing.io/kepler_model_server/get_started/)

    Attributes
    ----------
    affinity : ValuesModelServerAffinity, optional
    annotations : ValuesModelServerAnnotations, optional
        additional annotions for the model server Deployment
    enabled : bool, optional, default is False
        whether model-server and estimator sidecar should be deployed
    fullNameOverride : str, optional, default is ""
    image : ValuesModelServerImage, optional
    modelConfig : str, optional, default is "NODE_COMPONENTS_ESTIMATOR=true\n"
    nameOverride : str, optional, default is ""
    nodeSelector : ValuesModelServerNodeSelector, optional
    podAnnotations : ValuesModelServerPodAnnotations, optional
        additional annotions for the model server Pods
    podLabels : ValuesModelServerPodLabels, optional
        additional labels for the model server Pods
    podSecurityContext : ValuesModelServerPodSecurityContext, optional
    replicas : int, optional, default is 1
        replicas of the model-server Deployment
    resources : ValuesModelServerResources, optional
        resources for the model-server containers in the model-server Deployment
    securityContext : ValuesModelServerSecurityContext, optional
        security context for the model-server container in the model-server Deployment
    service : ValuesModelServerService, optional
    sidecarResources : ValuesModelServerSidecarResources, optional
        resources for the estimator sidecar deployed in the kepler DaemonSet
    """
    [...str]: any
    affinity?: ValuesModelServerAffinity
    annotations?: ValuesModelServerAnnotations
    enabled?: bool
    fullNameOverride?: str
    image?: ValuesModelServerImage
    modelConfig?: str
    nameOverride?: str
    nodeSelector?: ValuesModelServerNodeSelector
    podAnnotations?: ValuesModelServerPodAnnotations
    podLabels?: ValuesModelServerPodLabels
    podSecurityContext?: ValuesModelServerPodSecurityContext
    replicas?: int
    resources?: ValuesModelServerResources
    securityContext?: ValuesModelServerSecurityContext
    service?: ValuesModelServerService
    sidecarResources?: ValuesModelServerSidecarResources

schema ValuesModelServerAffinity:
    r"""
    ValuesModelServerAffinity
    """
    [...str]: any

schema ValuesModelServerAnnotations:
    r"""
    additional annotions for the model server Deployment
    """
    [...str]: any

schema ValuesModelServerImage:
    r"""
    ValuesModelServerImage

    Attributes
    ----------
    digest : str, optional, default is ""
        if empty, it will use the tag
    pullPolicy : str, optional, default is "Always"
    repository : str, optional, default is "quay.io/sustainable_computing_io/kepler_model_server"
    tag : str, optional, default is "v0.7.12"
    """
    [...str]: any
    digest?: str
    pullPolicy?: str
    repository?: str
    tag?: str

schema ValuesModelServerNodeSelector:
    r"""
    ValuesModelServerNodeSelector

    Attributes
    ----------
    "kubernetes.io/os" : str, optional, default is "linux"
    """
    [...str]: any
    "kubernetes.io/os"?: str

schema ValuesModelServerPodAnnotations:
    r"""
    additional annotions for the model server Pods
    """
    [...str]: any

schema ValuesModelServerPodLabels:
    r"""
    additional labels for the model server Pods
    """
    [...str]: any

schema ValuesModelServerPodSecurityContext:
    r"""
    ValuesModelServerPodSecurityContext
    """
    [...str]: any

schema ValuesModelServerResources:
    r"""
    resources for the model-server containers in the model-server Deployment
    """
    [...str]: any

schema ValuesModelServerSecurityContext:
    r"""
    security context for the model-server container in the model-server Deployment
    """
    [...str]: any

schema ValuesModelServerService:
    r"""
    ValuesModelServerService

    Attributes
    ----------
    annotations : ValuesModelServerServiceAnnotations, optional
    port : int, optional, default is 8100
    $type : str, optional, default is "ClusterIP"
    """
    [...str]: any
    annotations?: ValuesModelServerServiceAnnotations
    port?: int
    $type?: str

schema ValuesModelServerServiceAnnotations:
    r"""
    ValuesModelServerServiceAnnotations
    """
    [...str]: any

schema ValuesModelServerSidecarResources:
    r"""
    resources for the estimator sidecar deployed in the kepler DaemonSet
    """
    [...str]: any

schema ValuesMysql:
    r"""
    Scrape metrics/logs from MySQL

    Attributes
    ----------
    instances : [any], optional
    """
    [...str]: any
    instances?: [any]

schema ValuesNamespaceAnnotations:
    r"""
    Log labels to set with values copied from the Kubernetes Namespace annotations.
    Only used for "filelog" gather method.
    Format: `<log_label>: <kubernetes_namespace_annotation>`.
    """
    [...str]: any

schema ValuesNamespaceLabels:
    r"""
    Log labels to set with values copied from the Kubernetes Namespace labels.
    Only used for "filelog" gather method.
    Format: `<log_label>: <kubernetes_namespace_label>`.
    """
    [...str]: any

schema ValuesNetworkPolicies:
    r"""
    NetworkPolicies for ingress

    Attributes
    ----------
    enabled : bool, optional, default is False
        Specifies whether networkpolicies should be created
    extraEgress : [any], optional
        Extra egress rule
    prometheus : ValuesNetworkPoliciesPrometheus, optional
        Internal Prometheus settings related to NetworkPolicies
    """
    [...str]: any
    enabled?: bool
    extraEgress?: [any]
    prometheus?: ValuesNetworkPoliciesPrometheus

schema ValuesNetworkPoliciesPrometheus:
    r"""
    Internal Prometheus settings related to NetworkPolicies

    Attributes
    ----------
    labels : ValuesNetworkPoliciesPrometheusLabels, optional
        Labels applied to the Prometheus server pod(s)
    namespace : str, optional, default is "prometheus-system"
        Namespace where internal Prometheus is installed
    port : int, optional, default is 9090
        Pod port of in-cluster Prometheus
    """
    [...str]: any
    labels?: ValuesNetworkPoliciesPrometheusLabels
    namespace?: str
    port?: int

schema ValuesNetworkPoliciesPrometheusLabels:
    r"""
    Labels applied to the Prometheus server pod(s)

    Attributes
    ----------
    "app.kubernetes.io/name" : str, optional, default is "prometheus"
    """
    [...str]: any
    "app.kubernetes.io/name"?: str

schema ValuesNetworkPolicy:
    r"""
    Set a NetworkPolicy with:
    ingress only on service.port or custom policy
    no egress permitted

    Attributes
    ----------
    egress : ValuesNetworkPolicyEgressItems0 | ValuesNetworkPolicyEgress, optional
        If you enable a networkPolicy, you must add any redfish IP/Ports you list
        egress:
          - to:
            - ipBlock:
                cidr: 10.0.0.0/24
            ports:
              - protocol: TCP
                port: 443
    enabled : bool, optional, default is False
    flavor : str, optional, default is "kubernetes"
        networkPolicy.flavor -- Flavor of the network policy to use.
        Can be:
        * kubernetes for networking.k8s.io/v1/NetworkPolicy
        * cilium     for cilium.io/v2/CiliumNetworkPolicy
    ingress : [ValuesNetworkPolicyIngressItems0], optional
        Default allow all traffic because Alloy is so configurable
        It is recommended to change this before deploying to production
        To disable each policyType, set value to `null`
    policyTypes : [str], optional
    """
    [...str]: any
    egress?: ValuesNetworkPolicyEgressItems0 | ValuesNetworkPolicyEgress
    enabled?: bool
    flavor?: str
    ingress?: [ValuesNetworkPolicyIngressItems0]
    policyTypes?: [str]

schema ValuesNetworkPolicyEgress:
    r"""
    If you enable a networkPolicy, you must add any redfish IP/Ports you list
    egress:
      - to:
        - ipBlock:
            cidr: 10.0.0.0/24
        ports:
          - protocol: TCP
            port: 443
    """
    [...str]: any

schema ValuesNetworkPolicyEgressItems0:
    r"""
    ValuesNetworkPolicyEgressItems0
    """
    [...str]: any

schema ValuesNetworkPolicyIngressItems0:
    r"""
    ValuesNetworkPolicyIngressItems0

    Attributes
    ----------
    ports : [ValuesNetworkPolicyIngressItems0PortsItems0], optional
    """
    [...str]: any
    ports?: [ValuesNetworkPolicyIngressItems0PortsItems0]

schema ValuesNetworkPolicyIngressItems0PortsItems0:
    r"""
    ValuesNetworkPolicyIngressItems0PortsItems0

    Attributes
    ----------
    port : int, optional, default is 9102
    $protocol : str, optional, default is "TCP"
    """
    [...str]: any
    port?: int
    $protocol?: str

schema ValuesNodeAnnotations:
    r"""
    Log labels to set with values copied from the Kubernetes Node annotations.
    Only used for "filelog" gather method.
    Format: `<log_label>: <kubernetes_node_annotation>`.
    """
    [...str]: any

schema ValuesNodeExporter:
    r"""
    Node Exporter metrics gathers hardware information about Linux nodes.

    Attributes
    ----------
    affinity : ValuesNodeExporterAffinity, optional
    bearerTokenFile : str, optional, default is ""
        The bearer token file to use when scraping metrics from Node Exporter.
    deploy : bool, optional, default is True
        Deploy Node Exporter. Set to false if your cluster already has Node Exporter deployed.
    enabled : bool, optional, default is True
        Scrape metrics from Node Exporter.
    extraArgs : [str], optional
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for Node Exporter.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with __ (i.e. __meta_kubernetes*) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for Node Exporter metrics.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    jobLabel : str, optional, default is "integrations/node_exporter"
        The value for the job label.
    labelMatchers : ValuesNodeExporterLabelMatchers, optional
        Labels used to select the Node Exporter pods.
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for the Node Exporter prometheus.relabel component.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides global.maxCacheSize
    metricsTuning : ValuesNodeExporterMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    namespace : str, optional, default is ""
        Namespace to locate Node Exporter pods. If `deploy` is set to `true`, this will automatically be set to the
        namespace where this Helm chart is deployed.
    nodeSelector : ValuesNodeExporterNodeSelector, optional
    podAnnotations : ValuesNodeExporterPodAnnotations, optional
    releaseLabel : bool, optional, default is True
    scrapeInterval : str, optional, default is ""
        How frequently to scrape Node Exporter metrics.
    scrapeTimeout : str, optional, default is ""
        The timeout for scraping Node Exporter metrics.
    service : ValuesNodeExporterService, optional
        Node Exporter service settings
    """
    [...str]: any
    affinity?: ValuesNodeExporterAffinity
    bearerTokenFile?: str
    deploy?: bool
    enabled?: bool
    extraArgs?: [str]
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    jobLabel?: str
    labelMatchers?: ValuesNodeExporterLabelMatchers
    maxCacheSize?: any
    metricsTuning?: ValuesNodeExporterMetricsTuning
    namespace?: str
    nodeSelector?: ValuesNodeExporterNodeSelector
    podAnnotations?: ValuesNodeExporterPodAnnotations
    releaseLabel?: bool
    scrapeInterval?: str
    scrapeTimeout?: str
    service?: ValuesNodeExporterService

schema ValuesNodeExporterAffinity:
    r"""
    ValuesNodeExporterAffinity

    Attributes
    ----------
    nodeAffinity : ValuesNodeExporterAffinityNodeAffinity, optional
    """
    [...str]: any
    nodeAffinity?: ValuesNodeExporterAffinityNodeAffinity

schema ValuesNodeExporterAffinityNodeAffinity:
    r"""
    ValuesNodeExporterAffinityNodeAffinity

    Attributes
    ----------
    requiredDuringSchedulingIgnoredDuringExecution : ValuesNodeExporterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution, optional
    """
    [...str]: any
    requiredDuringSchedulingIgnoredDuringExecution?: ValuesNodeExporterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution

schema ValuesNodeExporterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution:
    r"""
    ValuesNodeExporterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution

    Attributes
    ----------
    nodeSelectorTerms : [ValuesNodeExporterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0], optional
    """
    [...str]: any
    nodeSelectorTerms?: [ValuesNodeExporterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0]

schema ValuesNodeExporterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0:
    r"""
    ValuesNodeExporterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0

    Attributes
    ----------
    matchExpressions : [ValuesNodeExporterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0MatchExpressionsItems0], optional
    """
    [...str]: any
    matchExpressions?: [ValuesNodeExporterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0MatchExpressionsItems0]

schema ValuesNodeExporterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0MatchExpressionsItems0:
    r"""
    ValuesNodeExporterAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsItems0MatchExpressionsItems0

    Attributes
    ----------
    key : str, optional, default is "eks.amazonaws.com/compute-type"
    operator : str, optional, default is "NotIn"
    values : [str], optional
    """
    [...str]: any
    key?: str
    operator?: str
    values?: [str]

schema ValuesNodeExporterLabelMatchers:
    r"""
    Labels used to select the Node Exporter pods.

    Attributes
    ----------
    "app.kubernetes.io/name" : str, optional, default is "node-exporter"
    """
    [...str]: any
    "app.kubernetes.io/name"?: str

schema ValuesNodeExporterMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    dropMetricsForFilesystem : [str], optional
        Drop metrics for the given filesystem types
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions.
    useDefaultAllowList : bool, optional, default is True
        Filter the list of metrics from Node Exporter to the minimal set required for Kubernetes Monitoring.
    useIntegrationAllowList : bool, optional, default is False
        Filter the list of metrics from Node Exporter to the minimal set required for Kubernetes Monitoring as well as the Node Exporter integration.
    """
    [...str]: any
    dropMetricsForFilesystem?: [str]
    excludeMetrics?: [any]
    includeMetrics?: [any]
    useDefaultAllowList?: bool
    useIntegrationAllowList?: bool

schema ValuesNodeExporterNodeSelector:
    r"""
    ValuesNodeExporterNodeSelector

    Attributes
    ----------
    "kubernetes.io/os" : str, optional, default is "linux"
    """
    [...str]: any
    "kubernetes.io/os"?: str

schema ValuesNodeExporterPodAnnotations:
    r"""
    ValuesNodeExporterPodAnnotations

    Attributes
    ----------
    "k8s.grafana.com/logs.job" : str, optional, default is "integrations/node_exporter"
    """
    [...str]: any
    "k8s.grafana.com/logs.job"?: str

schema ValuesNodeExporterService:
    r"""
    Node Exporter service settings

    Attributes
    ----------
    annotations : ValuesNodeExporterServiceAnnotations, optional
        Disable the prometheus.io/scrape annotation
    portName : str, optional, default is "metrics"
        The port name used by Node Exporter.
    scheme : str, optional, default is "http"
        The scrape scheme used by Node Exporter.
    """
    [...str]: any
    annotations?: ValuesNodeExporterServiceAnnotations
    portName?: str
    scheme?: str

schema ValuesNodeExporterServiceAnnotations:
    r"""
    Disable the prometheus.io/scrape annotation

    Attributes
    ----------
    "prometheus.io/scrape" : str, optional, default is "false"
    """
    [...str]: any
    "prometheus.io/scrape"?: str

schema ValuesNodeLabels:
    r"""
    Log labels to set with values copied from the Kubernetes Node labels.
    Only used for "filelog" gather method.
    Format: `<log_label>: <kubernetes_node_label>`.

    Attributes
    ----------
    availabilityZone : bool, optional, default is False
        Whether or not to add the availability\_zone label
    instanceType : bool, optional, default is False
        Whether or not to add the instance\_type label
    nodeArchitecture : bool, optional, default is False
        Whether or not to add the node architecture label
    nodeOS : bool, optional, default is False
        Whether or not to add the os label
    nodePool : bool, optional, default is False
        Whether or not to attach the nodepool label
    nodeRole : bool, optional, default is False
        Whether or not to add the node\_role label
    region : bool, optional, default is False
        Whether or not to add the region label
    """
    [...str]: any
    availabilityZone?: bool
    instanceType?: bool
    nodeArchitecture?: bool
    nodeOS?: bool
    nodePool?: bool
    nodeRole?: bool
    region?: bool

schema ValuesNodeLogs:
    r"""
    Node logs.
    Requires a destination that supports logs.
    To see the valid options, please see the [Node Logs feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-node-logs).

    Attributes
    ----------
    collector : str, optional, default is "alloy-logs"
        Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    destinations : [any], optional
        The destinations where logs will be sent. If empty, all logs-capable destinations will be used.
    enabled : bool, optional, default is False
        Enable gathering Kubernetes Cluster Node logs.
    """
    [...str]: any
    collector?: str
    destinations?: [any]
    enabled?: bool

schema ValuesNodeSelector:
    r"""
    # Assign a nodeSelector if operating a hybrid cluster
    #

    Attributes
    ----------
    "kubernetes.io/os" : str, optional, default is "windows"
    """
    [...str]: any
    "kubernetes.io/os"?: str

schema ValuesNodeSelectors:
    r"""
    Filter the list of discovered nodes by labels. Only for the "volumes" gather method.
    Example: `nodeSelectors: { 'kubernetes.io/os': 'linux' }`
    """
    [...str]: any

schema ValuesOpenTelemetryConversion:
    r"""
    Settings for converting OpenTelemetry ecosystem metrics to Prometheus ecosystem metrics.

    Attributes
    ----------
    addMetricSuffixes : bool, optional
        Whether to add type and unit suffixes to metrics names.
    resourceToTelemetryConversion : bool, optional
        Whether to convert OTel resource attributes to Prometheus labels.
    """
    [...str]: any
    addMetricSuffixes?: bool
    resourceToTelemetryConversion?: bool

schema ValuesOpencost:
    r"""
    OpenCost gathers cost metrics for the Kubernetes Cluster and the objects running inside.

    Attributes
    ----------
    affinity : ValuesOpencostAffinity, optional
        Affinity settings for pod assignment
    carbonCost : ValuesOpencostCarbonCost, optional
    cloudCost : ValuesOpencostCloudCost, optional
    cloudIntegrationSecret : str, optional, default is ""
        <SECRET_NAME> for the secret containing the Cloud Costs cloud-integration.json https://www.opencost.io/docs/configuration/#cloud-costs
        kubectl create secret generic <SECRET_NAME> --from-file=cloud-integration.json -n opencost
    customPricing : ValuesOpencostCustomPricing, optional
    enabled : bool, optional, default is False
        Deploy and scrape OpenCost.
    exporter : ValuesOpencostExporter, optional
    extraContainers : [any], optional
        extra sidecars to add to the pod.  Useful for things like oauth-proxy for the UI
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for OpenCost.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with __ (i.e. __meta_kubernetes*) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for OpenCost. ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no __meta* labels are present.
    jobLabel : str, optional, default is "integrations/opencost"
        The value for the job label.
    labelMatchers : ValuesOpencostLabelMatchers, optional
        Label matchers used to select the OpenCost service
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for the prometheus.relabel component for OpenCost.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides global.maxCacheSize
    metrics : ValuesOpencostMetrics, optional
    metricsSource : str, optional, default is ""
        The name of the metric destination where OpenCost will query for required metrics. Setting this will enable
        guided setup for required OpenCost parameters. To skip guided setup, set this to "custom".
    metricsTuning : ValuesOpencostMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    nodeSelector : ValuesOpencostNodeSelector, optional
        Node labels for pod assignment
    opencost : ValuesOpencostOpencost, optional
    platforms : ValuesOpencostPlatforms, optional
    prometheus : ValuesOpencostPrometheus, optional
    retention1d : int, optional, default is 15
    retention1h : int, optional, default is 49
    scrapeInterval : str, optional, default is ""
        How frequently to scrape metrics from Kepler.
        Overrides global.scrapeInterval.
    scrapeTimeout : str, optional, default is ""
        The timeout for scraping OpenCost metrics.
    sigV4Proxy : ValuesOpencostSigV4Proxy, optional
    tolerations : [any], optional
        Toleration labels for pod assignment
    topologySpreadConstraints : [any], optional
        Assign custom TopologySpreadConstraints rules
    ui : ValuesOpencostUi, optional
    updateCaTrust : ValuesOpencostUpdateCaTrust, optional
    """
    [...str]: any
    affinity?: ValuesOpencostAffinity
    carbonCost?: ValuesOpencostCarbonCost
    cloudCost?: ValuesOpencostCloudCost
    cloudIntegrationSecret?: str
    customPricing?: ValuesOpencostCustomPricing
    enabled?: bool
    exporter?: ValuesOpencostExporter
    extraContainers?: [any]
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    jobLabel?: str
    labelMatchers?: ValuesOpencostLabelMatchers
    maxCacheSize?: any
    metrics?: ValuesOpencostMetrics
    metricsSource?: str
    metricsTuning?: ValuesOpencostMetricsTuning
    nodeSelector?: ValuesOpencostNodeSelector
    opencost?: ValuesOpencostOpencost
    platforms?: ValuesOpencostPlatforms
    prometheus?: ValuesOpencostPrometheus
    retention1d?: int
    retention1h?: int
    scrapeInterval?: str
    scrapeTimeout?: str
    sigV4Proxy?: ValuesOpencostSigV4Proxy
    tolerations?: [any]
    topologySpreadConstraints?: [any]
    ui?: ValuesOpencostUi
    updateCaTrust?: ValuesOpencostUpdateCaTrust

schema ValuesOpencostAffinity:
    r"""
    Affinity settings for pod assignment
    """
    [...str]: any

schema ValuesOpencostCarbonCost:
    r"""
    ValuesOpencostCarbonCost

    Attributes
    ----------
    enabled : bool, optional, default is False
        Enable carbon cost exposed in the API
    """
    [...str]: any
    enabled?: bool

schema ValuesOpencostCloudCost:
    r"""
    ValuesOpencostCloudCost

    Attributes
    ----------
    enabled : bool, optional, default is False
        Enable cloud cost ingestion and querying, dependant on valid integration credentials
    monthToDateInterval : int, optional, default is 6
        The number of standard runs before a Month-to-Date run occurs
    queryWindowDays : int, optional, default is 7
        The max number of days that any single query will be made to construct Cloud Costs
    refreshRateHours : int, optional, default is 6
        Number of hours between each run of the Cloud Cost pipeline
    runWindowDays : int, optional, default is 3
        Number of days into the past that a Cloud Cost standard run will query for
    """
    [...str]: any
    enabled?: bool
    monthToDateInterval?: int
    queryWindowDays?: int
    refreshRateHours?: int
    runWindowDays?: int

schema ValuesOpencostCustomPricing:
    r"""
    ValuesOpencostCustomPricing

    Attributes
    ----------
    configPath : str, optional, default is "/tmp/custom-config"
        Path for the pricing configuration.
    configmapName : str, optional, default is "custom-pricing-model"
        Customize the configmap name used for custom pricing
    costModel : ValuesOpencostCustomPricingCostModel, optional
        More information about these values here: https://www.opencost.io/docs/configuration/on-prem#custom-pricing-using-the-opencost-helm-chart
    createConfigmap : bool, optional, default is True
        Configures the pricing model provided in the values file.
    enabled : bool, optional, default is False
        Enables custom pricing configuration
    provider : str, optional, default is "custom"
        Sets the provider type for the custom pricing file.
    """
    [...str]: any
    configPath?: str
    configmapName?: str
    costModel?: ValuesOpencostCustomPricingCostModel
    createConfigmap?: bool
    enabled?: bool
    provider?: str

schema ValuesOpencostCustomPricingCostModel:
    r"""
    More information about these values here: https://www.opencost.io/docs/configuration/on-prem#custom-pricing-using-the-opencost-helm-chart

    Attributes
    ----------
    CPU : float, optional, default is 1.25
    GPU : float, optional, default is 0.95
    RAM : float, optional, default is 0.5
    description : str, optional, default is "Modified pricing configuration."
    internetNetworkEgress : float, optional, default is 0.12
    regionNetworkEgress : float, optional, default is 0.01
    spotCPU : float, optional, default is 0.006655
    spotRAM : float, optional, default is 0.000892
    storage : float, optional, default is 0.25
    zoneNetworkEgress : float, optional, default is 0.01
    """
    [...str]: any
    CPU?: float
    GPU?: float
    RAM?: float
    description?: str
    internetNetworkEgress?: float
    regionNetworkEgress?: float
    spotCPU?: float
    spotRAM?: float
    storage?: float
    zoneNetworkEgress?: float

schema ValuesOpencostExporter:
    r"""
    ValuesOpencostExporter

    Attributes
    ----------
    apiIngress : ValuesOpencostExporterApiIngress, optional
        FOO: BAR
        For example, if accessing mimir directly and getting 401 Unauthorized
        PROMETHEUS_HEADER_X_SCOPE_ORGID: anonymous
    apiPort : int, optional, default is 9003
        API_PORT for the cost-model to listen on
    aws : ValuesOpencostExporterAws, optional
    cloudProviderApiKey : str, optional, default is ""
        debugPort: 40000 # for development purposes (debugging with delve) and not for production.
        The GCP Pricing API requires a key. This is supplied just for evaluation.
    collectorDataSource : ValuesOpencostExporterCollectorDataSource, optional
        Collector DataSource collects cluster data without a dependency on Prometheus
        It is recommended that persistence is enabled alongside it to preserve the state
        between pod restarts
    command : [any], optional
        Optional command to override the default container command
    csv_path : str, optional, default is ""
        Path of CSV file
    defaultClusterId : str, optional, default is "default-cluster"
        Default cluster ID to use if cluster_id is not set in Prometheus metrics.
    env : [any], optional
        List of additional environment variables to set in the container
    extraArgs : [any], optional
        List of extra arguments for the command, e.g.: log-format=json
    extraEnv : ValuesOpencostExporterExtraEnv, optional
        Any extra environment variables you would like to pass on to the pod
    extraVolumeMounts : [any], optional
        A list of volume mounts to be added to the pod
    image : ValuesOpencostExporterImage, optional
        If clusterIdConfigmap is defined, use user-generated ConfigMap with key CLUSTER_ID as default cluster ID.
        This overrides the above defaultClusterId. Ensure the ConfigMap exists and contains the required CLUSTER_ID key.
        clusterIdConfigmap: cluster-id-configmap
    livenessProbe : ValuesOpencostExporterLivenessProbe, optional
        Liveness probe configuration
    persistence : ValuesOpencostExporterPersistence, optional
        Persistent volume claim for storing the data. eg: csv file
    prometheusDataSource : ValuesOpencostExporterPrometheusDataSource, optional
    readinessProbe : ValuesOpencostExporterReadinessProbe, optional
        Readiness probe configuration
    replicas : int, optional, default is 1
        Number of OpenCost replicas to run
    resources : ValuesOpencostExporterResources, optional
    securityContext : ValuesOpencostExporterSecurityContext, optional
        The security options the container should be run with
    startupProbe : ValuesOpencostExporterStartupProbe, optional
        Startup probe configuration
    """
    [...str]: any
    apiIngress?: ValuesOpencostExporterApiIngress
    apiPort?: int
    aws?: ValuesOpencostExporterAws
    cloudProviderApiKey?: str
    collectorDataSource?: ValuesOpencostExporterCollectorDataSource
    command?: [any]
    csv_path?: str
    defaultClusterId?: str
    env?: [any]
    extraArgs?: [any]
    extraEnv?: ValuesOpencostExporterExtraEnv
    extraVolumeMounts?: [any]
    image?: ValuesOpencostExporterImage
    livenessProbe?: ValuesOpencostExporterLivenessProbe
    persistence?: ValuesOpencostExporterPersistence
    prometheusDataSource?: ValuesOpencostExporterPrometheusDataSource
    readinessProbe?: ValuesOpencostExporterReadinessProbe
    replicas?: int
    resources?: ValuesOpencostExporterResources
    securityContext?: ValuesOpencostExporterSecurityContext
    startupProbe?: ValuesOpencostExporterStartupProbe

schema ValuesOpencostExporterApiIngress:
    r"""
    FOO: BAR
    For example, if accessing mimir directly and getting 401 Unauthorized
    PROMETHEUS_HEADER_X_SCOPE_ORGID: anonymous

    Attributes
    ----------
    annotations : ValuesOpencostExporterApiIngressAnnotations, optional
        Annotations for Ingress resource
    enabled : bool, optional, default is False
        Ingress for OpenCost API
    hosts : [ValuesOpencostExporterApiIngressHostsItems0], optional
        kubernetes.io/tls-acme: "true"
        A list of host rules used to configure the Ingress
    ingressClassName : str, optional, default is ""
        Ingress controller which implements the resource
    servicePort : str, optional, default is "http"
        Redirect ingress to an extraPort defined on the service such as oauth-proxy
    tls : [any], optional
        servicePort: oauth-proxy
        Ingress TLS configuration
    """
    [...str]: any
    annotations?: ValuesOpencostExporterApiIngressAnnotations
    enabled?: bool
    hosts?: [ValuesOpencostExporterApiIngressHostsItems0]
    ingressClassName?: str
    servicePort?: str
    tls?: [any]

schema ValuesOpencostExporterApiIngressAnnotations:
    r"""
    Annotations for Ingress resource
    """
    [...str]: any

schema ValuesOpencostExporterApiIngressHostsItems0:
    r"""
    ValuesOpencostExporterApiIngressHostsItems0

    Attributes
    ----------
    host : str, optional, default is "example.local"
    paths : [ValuesOpencostExporterApiIngressHostsItems0PathsItems0], optional
    """
    [...str]: any
    host?: str
    paths?: [ValuesOpencostExporterApiIngressHostsItems0PathsItems0]

schema ValuesOpencostExporterApiIngressHostsItems0PathsItems0:
    r"""
    ValuesOpencostExporterApiIngressHostsItems0PathsItems0

    Attributes
    ----------
    path : str, optional, default is "/"
    pathType : str, optional, default is "Prefix"
    """
    [...str]: any
    path?: str
    pathType?: str

schema ValuesOpencostExporterAws:
    r"""
    ValuesOpencostExporterAws

    Attributes
    ----------
    access_key_id : str, optional, default is ""
        AWS secret key id
    secret_access_key : str, optional, default is ""
        AWS secret access key
    """
    [...str]: any
    access_key_id?: str
    secret_access_key?: str

schema ValuesOpencostExporterCollectorDataSource:
    r"""
    Collector DataSource collects cluster data without a dependency on Prometheus
    It is recommended that persistence is enabled alongside it to preserve the state
    between pod restarts

    Attributes
    ----------
    enabled : bool, optional, default is False
    networkPort : int, optional, default is 3001
        The port at which network pods are open to egress
    retention10m : int, optional, default is 36
        The number of 10m intervals the Collector DataSource should maintain
    retention1d : int, optional, default is 15
        The number of 1d intervals the Collector DataSource should maintain
    retention1h : int, optional, default is 49
        The number of 1h intervals the Collector DataSource should maintain
    scrapeInterval : str, optional, default is "30s"
        define the interval at which the collector scrapes for data points (10s, 15s, 1m)
    """
    [...str]: any
    enabled?: bool
    networkPort?: int
    retention10m?: int
    retention1d?: int
    retention1h?: int
    scrapeInterval?: str

schema ValuesOpencostExporterExtraEnv:
    r"""
    Any extra environment variables you would like to pass on to the pod
    """
    [...str]: any

schema ValuesOpencostExporterImage:
    r"""
    If clusterIdConfigmap is defined, use user-generated ConfigMap with key CLUSTER_ID as default cluster ID.
    This overrides the above defaultClusterId. Ensure the ConfigMap exists and contains the required CLUSTER_ID key.
    clusterIdConfigmap: cluster-id-configmap

    Attributes
    ----------
    fullImageName : any, optional, default is "null"
        Override the full image name for development purposes
    pullPolicy : str, optional, default is "IfNotPresent"
        Exporter container image pull policy
    registry : str, optional, default is "ghcr.io"
        Exporter container image registry
    repository : str, optional, default is "opencost/opencost"
        Exporter container image name
    tag : str, optional, default is "1.117.6@sha256:6f1a0e6fe21559a77051e7b7f9e4ac6bc80277131492ae084e8365ada805af91"
        Exporter container image tag
    """
    [...str]: any
    fullImageName?: any
    pullPolicy?: str
    registry?: str
    repository?: str
    tag?: str

schema ValuesOpencostExporterLivenessProbe:
    r"""
    Liveness probe configuration

    Attributes
    ----------
    enabled : bool, optional, default is True
        Whether probe is enabled
    failureThreshold : int, optional, default is 3
        Number of failures for probe to be considered failed
    initialDelaySeconds : int, optional, default is 10
        Number of seconds before probe is initiated
    path : str, optional, default is "/healthz"
        Probe path
    periodSeconds : int, optional, default is 20
        Probe frequency in seconds
    """
    [...str]: any
    enabled?: bool
    failureThreshold?: int
    initialDelaySeconds?: int
    path?: str
    periodSeconds?: int

schema ValuesOpencostExporterPersistence:
    r"""
    Persistent volume claim for storing the data. eg: csv file

    Attributes
    ----------
    accessMode : str, optional, default is ""
        Access mode for persistent volume
    annotations : ValuesOpencostExporterPersistenceAnnotations, optional
        Annotations for persistent volume
    enabled : bool, optional, default is False
    mountPath : str, optional, default is "/mnt/export"
        The path that the PV will be mounted to the exporter at
    size : str, optional, default is ""
        Size for persistent volume
    storageClass : str, optional, default is ""
        Storage class for persistent volume
    """
    [...str]: any
    accessMode?: str
    annotations?: ValuesOpencostExporterPersistenceAnnotations
    enabled?: bool
    mountPath?: str
    size?: str
    storageClass?: str

schema ValuesOpencostExporterPersistenceAnnotations:
    r"""
    Annotations for persistent volume
    """
    [...str]: any

schema ValuesOpencostExporterPrometheusDataSource:
    r"""
    ValuesOpencostExporterPrometheusDataSource

    Attributes
    ----------
    queryResolutionSeconds : int, optional, default is 300
        Set the resolution in second that prometheus queries will be performed at
    """
    [...str]: any
    queryResolutionSeconds?: int

schema ValuesOpencostExporterReadinessProbe:
    r"""
    Readiness probe configuration

    Attributes
    ----------
    enabled : bool, optional, default is True
        Whether probe is enabled
    failureThreshold : int, optional, default is 3
        Number of failures for probe to be considered failed
    initialDelaySeconds : int, optional, default is 10
        Number of seconds before probe is initiated
    path : str, optional, default is "/healthz"
        Probe path
    periodSeconds : int, optional, default is 10
        Probe frequency in seconds
    """
    [...str]: any
    enabled?: bool
    failureThreshold?: int
    initialDelaySeconds?: int
    path?: str
    periodSeconds?: int

schema ValuesOpencostExporterResources:
    r"""
    ValuesOpencostExporterResources

    Attributes
    ----------
    limits : ValuesOpencostExporterResourcesLimits, optional
        CPU/Memory resource limits
    requests : ValuesOpencostExporterResourcesRequests, optional
        CPU/Memory resource requests
    """
    [...str]: any
    limits?: ValuesOpencostExporterResourcesLimits
    requests?: ValuesOpencostExporterResourcesRequests

schema ValuesOpencostExporterResourcesLimits:
    r"""
    CPU/Memory resource limits

    Attributes
    ----------
    memory : str, optional, default is "1Gi"
    """
    [...str]: any
    memory?: str

schema ValuesOpencostExporterResourcesRequests:
    r"""
    CPU/Memory resource requests

    Attributes
    ----------
    cpu : str, optional, default is "10m"
    memory : str, optional, default is "55Mi"
    """
    [...str]: any
    cpu?: str
    memory?: str

schema ValuesOpencostExporterSecurityContext:
    r"""
    The security options the container should be run with
    """
    [...str]: any

schema ValuesOpencostExporterStartupProbe:
    r"""
    Startup probe configuration

    Attributes
    ----------
    enabled : bool, optional, default is True
        Whether probe is enabled
    failureThreshold : int, optional, default is 30
        Number of failures for probe to be considered failed
    initialDelaySeconds : int, optional, default is 10
        Number of seconds before probe is initiated
    path : str, optional, default is "/healthz"
        Probe path
    periodSeconds : int, optional, default is 5
        Probe frequency in seconds
    """
    [...str]: any
    enabled?: bool
    failureThreshold?: int
    initialDelaySeconds?: int
    path?: str
    periodSeconds?: int

schema ValuesOpencostLabelMatchers:
    r"""
    Label matchers used to select the OpenCost service

    Attributes
    ----------
    "app.kubernetes.io/name" : str, optional, default is "opencost"
    """
    [...str]: any
    "app.kubernetes.io/name"?: str

schema ValuesOpencostMetrics:
    r"""
    ValuesOpencostMetrics

    Attributes
    ----------
    config : ValuesOpencostMetricsConfig, optional
    kubeStateMetrics : ValuesOpencostMetricsKubeStateMetrics, optional
    serviceMonitor : ValuesOpencostMetricsServiceMonitor, optional
    """
    [...str]: any
    config?: ValuesOpencostMetricsConfig
    kubeStateMetrics?: ValuesOpencostMetricsKubeStateMetrics
    serviceMonitor?: ValuesOpencostMetricsServiceMonitor

schema ValuesOpencostMetricsConfig:
    r"""
    ValuesOpencostMetricsConfig

    Attributes
    ----------
    configmapName : str, optional, default is "custom-metrics"
        Customize the configmap name used for metrics
    disabledMetrics : [any], optional
        List of metrics to be disabled
    enabled : bool, optional, default is False
        Enables creating the metrics.json configuration as a ConfigMap
    """
    [...str]: any
    configmapName?: str
    disabledMetrics?: [any]
    enabled?: bool

schema ValuesOpencostMetricsKubeStateMetrics:
    r"""
    ValuesOpencostMetricsKubeStateMetrics

    Attributes
    ----------
    emitKsmV1Metrics : any, optional, default is "~"
        (bool) Enable emission of KSM v1 metrics
    emitKsmV1MetricsOnly : any, optional, default is "~"
        (bool) Enable only emission of KSM v1 metrics that do not exist in KSM 2 by default
    emitNamespaceAnnotations : any, optional, default is "~"
        (bool) Enable emission of namespace annotations
    emitPodAnnotations : any, optional, default is "~"
        (bool) Enable emission of pod annotations
    """
    [...str]: any
    emitKsmV1Metrics?: any
    emitKsmV1MetricsOnly?: any
    emitNamespaceAnnotations?: any
    emitPodAnnotations?: any

schema ValuesOpencostMetricsServiceMonitor:
    r"""
    ValuesOpencostMetricsServiceMonitor

    Attributes
    ----------
    additionalLabels : ValuesOpencostMetricsServiceMonitorAdditionalLabels, optional
        Additional labels to add to the ServiceMonitor
    enabled : bool, optional, default is False
        Create ServiceMonitor resource for scraping metrics using PrometheusOperator
    extraEndpoints : [any], optional
        extra Endpoints to add to the ServiceMonitor.  Useful for scraping sidecars
    honorLabels : bool, optional, default is True
        HonorLabels chooses the metric's labels on collisions with target labels
    metricRelabelings : [any], optional
        MetricRelabelConfigs to apply to samples before ingestion
    namespace : str, optional, default is ""
        Specify if the ServiceMonitor will be deployed into a different namespace (blank deploys into same namespace as chart)
    relabelings : [any], optional
        RelabelConfigs to apply to samples before scraping. Prometheus Operator automatically adds relabelings for a few standard Kubernetes fields
    scheme : str, optional, default is "http"
        - port: oauth-metrics
          path: /metrics
        HTTP scheme used for scraping. Defaults to `http`
    scrapeInterval : str, optional, default is "30s"
        Interval at which metrics should be scraped
    scrapeTimeout : str, optional, default is "10s"
        Timeout after which the scrape is ended
    tlsConfig : ValuesOpencostMetricsServiceMonitorTlsConfig, optional
        TLS configuration for scraping metrics
    """
    [...str]: any
    additionalLabels?: ValuesOpencostMetricsServiceMonitorAdditionalLabels
    enabled?: bool
    extraEndpoints?: [any]
    honorLabels?: bool
    metricRelabelings?: [any]
    namespace?: str
    relabelings?: [any]
    scheme?: str
    scrapeInterval?: str
    scrapeTimeout?: str
    tlsConfig?: ValuesOpencostMetricsServiceMonitorTlsConfig

schema ValuesOpencostMetricsServiceMonitorAdditionalLabels:
    r"""
    Additional labels to add to the ServiceMonitor
    """
    [...str]: any

schema ValuesOpencostMetricsServiceMonitorTlsConfig:
    r"""
    TLS configuration for scraping metrics
    """
    [...str]: any

schema ValuesOpencostMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions.
    useDefaultAllowList : bool, optional, default is True
        Filter the list of metrics from OpenCost to the minimal set required for Kubernetes Monitoring.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]
    useDefaultAllowList?: bool

schema ValuesOpencostNodeSelector:
    r"""
    Node labels for pod assignment
    """
    [...str]: any

schema ValuesOpencostOpencost:
    r"""
    ValuesOpencostOpencost

    Attributes
    ----------
    carbonCost : ValuesOpencostOpencostCarbonCost, optional
    cloudCost : ValuesOpencostOpencostCloudCost, optional
    exporter : ValuesOpencostOpencostExporter, optional
    metrics : ValuesOpencostOpencostMetrics, optional
    nodeSelector : ValuesOpencostOpencostNodeSelector, optional
    prometheus : ValuesOpencostOpencostPrometheus, optional
    tolerations : [ValuesOpencostOpencostTolerationsItems0], optional
    ui : ValuesOpencostOpencostUi, optional
    """
    [...str]: any
    carbonCost?: ValuesOpencostOpencostCarbonCost
    cloudCost?: ValuesOpencostOpencostCloudCost
    exporter?: ValuesOpencostOpencostExporter
    metrics?: ValuesOpencostOpencostMetrics
    nodeSelector?: ValuesOpencostOpencostNodeSelector
    prometheus?: ValuesOpencostOpencostPrometheus
    tolerations?: [ValuesOpencostOpencostTolerationsItems0]
    ui?: ValuesOpencostOpencostUi

schema ValuesOpencostOpencostCarbonCost:
    r"""
    ValuesOpencostOpencostCarbonCost

    Attributes
    ----------
    enabled : bool, optional, default is False
    """
    [...str]: any
    enabled?: bool

schema ValuesOpencostOpencostCloudCost:
    r"""
    ValuesOpencostOpencostCloudCost

    Attributes
    ----------
    enabled : bool, optional, default is False
    """
    [...str]: any
    enabled?: bool

schema ValuesOpencostOpencostExporter:
    r"""
    ValuesOpencostOpencostExporter

    Attributes
    ----------
    defaultClusterId : str, optional, default is "default-cluster"
        Default cluster ID to use if cluster is not set in Prometheus metrics. It should match cluster.name.
    extraEnv : ValuesOpencostOpencostExporterExtraEnv, optional
    """
    [...str]: any
    defaultClusterId?: str
    extraEnv?: ValuesOpencostOpencostExporterExtraEnv

schema ValuesOpencostOpencostExporterExtraEnv:
    r"""
    ValuesOpencostOpencostExporterExtraEnv

    Attributes
    ----------
    CLOUD_PROVIDER_API_KEY : str, optional, default is "AIzaSyD29bGxmHAVEOBYtgd8sYM2gM2ekfxQX4U"
        Trial API Key used only with GCP.
        See https://www.opencost.io/docs/configuration/gcp-opencost for how to set for your environment
    CURRENT_CLUSTER_ID_FILTER_ENABLED : str, optional, default is "true"
    PROM_CLUSTER_ID_LABEL : str, optional, default is "cluster"
    """
    [...str]: any
    CLOUD_PROVIDER_API_KEY?: str
    CURRENT_CLUSTER_ID_FILTER_ENABLED?: str
    PROM_CLUSTER_ID_LABEL?: str

schema ValuesOpencostOpencostMetrics:
    r"""
    ValuesOpencostOpencostMetrics

    Attributes
    ----------
    kubeStateMetrics : ValuesOpencostOpencostMetricsKubeStateMetrics, optional
    """
    [...str]: any
    kubeStateMetrics?: ValuesOpencostOpencostMetricsKubeStateMetrics

schema ValuesOpencostOpencostMetricsKubeStateMetrics:
    r"""
    ValuesOpencostOpencostMetricsKubeStateMetrics

    Attributes
    ----------
    emitKsmV1Metrics : bool, optional, default is False
    emitKsmV1MetricsOnly : bool, optional, default is True
    """
    [...str]: any
    emitKsmV1Metrics?: bool
    emitKsmV1MetricsOnly?: bool

schema ValuesOpencostOpencostNodeSelector:
    r"""
    ValuesOpencostOpencostNodeSelector

    Attributes
    ----------
    "kubernetes.io/os" : str, optional, default is "linux"
    """
    [...str]: any
    "kubernetes.io/os"?: str

schema ValuesOpencostOpencostPrometheus:
    r"""
    ValuesOpencostOpencostPrometheus

    Attributes
    ----------
    existingSecretName : str, optional, default is ""
        The name of the secret containing the username and password for the metrics service. This must be in the same namespace as the OpenCost deployment.
    external : ValuesOpencostOpencostPrometheusExternal, optional
    internal : ValuesOpencostOpencostPrometheusInternal, optional
    password_key : str, optional, default is "password"
        The key for the password property in the secret.
    username_key : str, optional, default is "username"
        The key for the username property in the secret.
    """
    [...str]: any
    existingSecretName?: str
    external?: ValuesOpencostOpencostPrometheusExternal
    internal?: ValuesOpencostOpencostPrometheusInternal
    password_key?: str
    username_key?: str

schema ValuesOpencostOpencostPrometheusExternal:
    r"""
    ValuesOpencostOpencostPrometheusExternal

    Attributes
    ----------
    enabled : bool, optional, default is True
    url : str, optional, default is ""
        The URL for Prometheus queries. It should match externalServices.prometheus.host + "/api/prom"
    """
    [...str]: any
    enabled?: bool
    url?: str

schema ValuesOpencostOpencostPrometheusInternal:
    r"""
    ValuesOpencostOpencostPrometheusInternal

    Attributes
    ----------
    enabled : bool, optional, default is False
    """
    [...str]: any
    enabled?: bool

schema ValuesOpencostOpencostTolerationsItems0:
    r"""
    ValuesOpencostOpencostTolerationsItems0

    Attributes
    ----------
    effect : str, optional, default is "NoSchedule"
    key : str, optional, default is "kubernetes.io/arch"
    operator : str, optional, default is "Equal"
    value : str, optional, default is "arm64"
    """
    [...str]: any
    effect?: str
    key?: str
    operator?: str
    value?: str

schema ValuesOpencostOpencostUi:
    r"""
    ValuesOpencostOpencostUi

    Attributes
    ----------
    enabled : bool, optional, default is False
    """
    [...str]: any
    enabled?: bool

schema ValuesOpencostPlatforms:
    r"""
    ValuesOpencostPlatforms

    Attributes
    ----------
    openshift : ValuesOpencostPlatformsOpenshift, optional
    """
    [...str]: any
    openshift?: ValuesOpencostPlatformsOpenshift

schema ValuesOpencostPlatformsOpenshift:
    r"""
    ValuesOpencostPlatformsOpenshift

    Attributes
    ----------
    createMonitoringClusterRoleBinding : bool, optional, default is False
        OPTIONAL. The following configs only to be enabled when using a Prometheus instance already installed in the cluster.
        If true, the helm chart will create a ClusterRoleBinding to grant the OpenCost ServiceAccount access to query Prometheus.
    createMonitoringResourceReaderRoleBinding : bool, optional, default is False
        If true, create a Role and RoleBinding to allow Prometheus to list and watch OpenCost resources.
    enablePromAccess : bool, optional, default is False
        If true, enable internal prom access
    enableSCC : bool, optional, default is False
        If true, set Security Context Constraints on serviceaccount for read/write premissions
    enabled : bool, optional, default is False
        Enable OpenShift specific configurations
    monitoringServiceAccountName : str, optional, default is "prometheus-k8s"
        Name of the Prometheus serviceaccount to bind to the Resource Reader Role Binding.
    monitoringServiceAccountNamespace : str, optional, default is "openshift-monitoring"
        Namespace of the Prometheus serviceaccount to bind to the Resource Reader Role Binding.
    """
    [...str]: any
    createMonitoringClusterRoleBinding?: bool
    createMonitoringResourceReaderRoleBinding?: bool
    enablePromAccess?: bool
    enableSCC?: bool
    enabled?: bool
    monitoringServiceAccountName?: str
    monitoringServiceAccountNamespace?: str

schema ValuesOpencostPrometheus:
    r"""
    ValuesOpencostPrometheus

    Attributes
    ----------
    amp : ValuesOpencostPrometheusAmp, optional
    bearer_token : str, optional, default is ""
        Prometheus Bearer token
    bearer_token_key : str, optional, default is "DB_BEARER_TOKEN"
    existingSecretName : any, optional, default is "~"
        Existing secret name that contains credentials for Prometheus
    external : ValuesOpencostPrometheusExternal, optional
    insecureSkipVerify : bool, optional, default is False
        Whether to disable SSL certificate verification
    internal : ValuesOpencostPrometheusInternal, optional
    kubeRBACProxy : bool, optional, default is False
        If true, opencost will use kube-rbac-proxy to authenticate with in cluster Prometheus for openshift
    password : str, optional, default is ""
        Prometheus Basic auth password
    password_key : str, optional, default is "DB_BASIC_AUTH_PW"
        Key in the secret that references the password
    secret_name : any, optional, default is "~"
        Secret name that contains credentials for Prometheus
    thanos : ValuesOpencostPrometheusThanos, optional
    username : str, optional, default is ""
        Prometheus Basic auth username
    username_key : str, optional, default is "DB_BASIC_AUTH_USERNAME"
        Key in the secret that references the username
    """
    [...str]: any
    amp?: ValuesOpencostPrometheusAmp
    bearer_token?: str
    bearer_token_key?: str
    existingSecretName?: any
    external?: ValuesOpencostPrometheusExternal
    insecureSkipVerify?: bool
    internal?: ValuesOpencostPrometheusInternal
    kubeRBACProxy?: bool
    password?: str
    password_key?: str
    secret_name?: any
    thanos?: ValuesOpencostPrometheusThanos
    username?: str
    username_key?: str

schema ValuesOpencostPrometheusAmp:
    r"""
    ValuesOpencostPrometheusAmp

    Attributes
    ----------
    enabled : bool, optional, default is False
        Use Amazon Managed Service for Prometheus (AMP)
    workspaceId : str, optional, default is ""
        Workspace ID for AMP
    """
    [...str]: any
    enabled?: bool
    workspaceId?: str

schema ValuesOpencostPrometheusExternal:
    r"""
    ValuesOpencostPrometheusExternal

    Attributes
    ----------
    enabled : bool, optional, default is False
        Use external Prometheus (eg. Grafana Cloud)
    url : str, optional, default is "https://prometheus.example.com/prometheus"
        External Prometheus url
    """
    [...str]: any
    enabled?: bool
    url?: str

schema ValuesOpencostPrometheusInternal:
    r"""
    ValuesOpencostPrometheusInternal

    Attributes
    ----------
    enabled : bool, optional, default is True
        Use in-cluster Prometheus
    namespaceName : str, optional, default is "prometheus-system"
        Namespace of in-cluster Prometheus
    path : str, optional, default is ""
        Path to access the Prometheus API, this is neccesary if the Prometheus server is behind a reverse proxy(mimir) or has a different path.
    port : int, optional, default is 80
        Service port of in-cluster Prometheus
    scheme : str, optional, default is "http"
        Scheme to use for in-cluster Prometheus
    serviceName : str, optional, default is "prometheus-server"
        Service name of in-cluster Prometheus
    """
    [...str]: any
    enabled?: bool
    namespaceName?: str
    path?: str
    port?: int
    scheme?: str
    serviceName?: str

schema ValuesOpencostPrometheusThanos:
    r"""
    ValuesOpencostPrometheusThanos

    Attributes
    ----------
    enabled : bool, optional, default is False
    external : ValuesOpencostPrometheusThanosExternal, optional
    internal : ValuesOpencostPrometheusThanosInternal, optional
    maxSourceResolution : str, optional, default is ""
    queryOffset : str, optional, default is ""
    """
    [...str]: any
    enabled?: bool
    external?: ValuesOpencostPrometheusThanosExternal
    internal?: ValuesOpencostPrometheusThanosInternal
    maxSourceResolution?: str
    queryOffset?: str

schema ValuesOpencostPrometheusThanosExternal:
    r"""
    ValuesOpencostPrometheusThanosExternal

    Attributes
    ----------
    enabled : bool, optional, default is False
    url : str, optional, default is "https://thanos-query.example.com/thanos"
    """
    [...str]: any
    enabled?: bool
    url?: str

schema ValuesOpencostPrometheusThanosInternal:
    r"""
    ValuesOpencostPrometheusThanosInternal

    Attributes
    ----------
    enabled : bool, optional, default is True
    namespaceName : str, optional, default is "opencost"
    port : int, optional, default is 10901
    scheme : str, optional, default is "http"
    serviceName : str, optional, default is "my-thanos-query"
    """
    [...str]: any
    enabled?: bool
    namespaceName?: str
    port?: int
    scheme?: str
    serviceName?: str

schema ValuesOpencostSigV4Proxy:
    r"""
    ValuesOpencostSigV4Proxy

    Attributes
    ----------
    extraEnv : any, optional, default is ""
        role_arn: arn:aws:iam::<account>:role/role-name # The AWS IAM role to assume.
    host : str, optional, default is "aps-workspaces.us-west-2.amazonaws.com"
    image : str, optional, default is "public.ecr.aws/aws-observability/aws-sigv4-proxy:latest"
    imagePullPolicy : str, optional, default is "IfNotPresent"
    name : str, optional, default is "aps"
    port : int, optional, default is 8005
    region : str, optional, default is "us-west-2"
    resources : ValuesOpencostSigV4ProxyResources, optional
        - name: AWS_ACCESS_KEY_ID
          value: <access_key>
        - name: AWS_SECRET_ACCESS_KEY
          value: <secret_key>
    securityContext : ValuesOpencostSigV4ProxySecurityContext, optional
        limits:
          cpu: 200m
          memory: 500Mi
        requests:
          cpu: 20m
          memory: 32Mi
    """
    [...str]: any
    extraEnv?: any
    host?: str
    image?: str
    imagePullPolicy?: str
    name?: str
    port?: int
    region?: str
    resources?: ValuesOpencostSigV4ProxyResources
    securityContext?: ValuesOpencostSigV4ProxySecurityContext

schema ValuesOpencostSigV4ProxyResources:
    r"""
    - name: AWS_ACCESS_KEY_ID
      value: <access_key>
    - name: AWS_SECRET_ACCESS_KEY
      value: <secret_key>
    """
    [...str]: any

schema ValuesOpencostSigV4ProxySecurityContext:
    r"""
    limits:
      cpu: 200m
      memory: 500Mi
    requests:
      cpu: 20m
      memory: 32Mi
    """
    [...str]: any

schema ValuesOpencostUi:
    r"""
    ValuesOpencostUi

    Attributes
    ----------
    enabled : bool, optional, default is True
        Enable OpenCost UI
    extraEnv : [any], optional
        A list of environment variables to be added to the pod
    extraVolumeMounts : [any], optional
        A list of volume mounts to be added to the pod
    image : ValuesOpencostUiImage, optional
    ingress : ValuesOpencostUiIngress, optional
        Set the model fqdn to use for the upstream
        modelFqdn: opencost.opencost.svc.cluster.local:9003
    livenessProbe : ValuesOpencostUiLivenessProbe, optional
        Liveness probe configuration
    readinessProbe : ValuesOpencostUiReadinessProbe, optional
        Readiness probe configuration
    resources : ValuesOpencostUiResources, optional
    route : ValuesOpencostUiRoute, optional
    securityContext : ValuesOpencostUiSecurityContext, optional
        The security options the container should be run with
    uiPath : str, optional, default is "/"
        Base path for serving the UI.
        Requires building a custom image using the build argument "ui_path".
    uiPort : int, optional, default is 9090
        used in the default.nginx.conf if you want to switch for using with Docker
        apiServer: 0.0.0.0
    useDefaultFqdn : bool, optional, default is False
        set to true to set upstream to use <service>.<namespace>.svc.cluster.local instead of just <service>.<namespace>
    useIPv6 : bool, optional, default is True
        Set to true to use IPv6
    """
    [...str]: any
    enabled?: bool
    extraEnv?: [any]
    extraVolumeMounts?: [any]
    image?: ValuesOpencostUiImage
    ingress?: ValuesOpencostUiIngress
    livenessProbe?: ValuesOpencostUiLivenessProbe
    readinessProbe?: ValuesOpencostUiReadinessProbe
    resources?: ValuesOpencostUiResources
    route?: ValuesOpencostUiRoute
    securityContext?: ValuesOpencostUiSecurityContext
    uiPath?: str
    uiPort?: int
    useDefaultFqdn?: bool
    useIPv6?: bool

schema ValuesOpencostUiImage:
    r"""
    ValuesOpencostUiImage

    Attributes
    ----------
    fullImageName : any, optional, default is "null"
        Override the full image name for development purposes
    pullPolicy : str, optional, default is "IfNotPresent"
        UI container image pull policy
    registry : str, optional, default is "ghcr.io"
        UI container image registry
    repository : str, optional, default is "opencost/opencost-ui"
        UI container image name
    tag : str, optional, default is "1.117.6@sha256:fd26f004b2b2565e22240fc2a9f6adb078fdb4de3fc1a1b16c611a3c3b80683e"
        UI container image tag
    """
    [...str]: any
    fullImageName?: any
    pullPolicy?: str
    registry?: str
    repository?: str
    tag?: str

schema ValuesOpencostUiIngress:
    r"""
    Set the model fqdn to use for the upstream
    modelFqdn: opencost.opencost.svc.cluster.local:9003

    Attributes
    ----------
    annotations : ValuesOpencostUiIngressAnnotations, optional
        Annotations for Ingress resource
    enabled : bool, optional, default is False
        Ingress for OpenCost UI
    hosts : [ValuesOpencostUiIngressHostsItems0], optional
        kubernetes.io/tls-acme: "true"
        A list of host rules used to configure the Ingress
    ingressClassName : str, optional, default is ""
        Ingress controller which implements the resource
    servicePort : str, optional, default is "http-ui"
        Redirect ingress to an extraPort defined on the service such as oauth-proxy
    tls : [any], optional
        servicePort: oauth-proxy
        Ingress TLS configuration
    """
    [...str]: any
    annotations?: ValuesOpencostUiIngressAnnotations
    enabled?: bool
    hosts?: [ValuesOpencostUiIngressHostsItems0]
    ingressClassName?: str
    servicePort?: str
    tls?: [any]

schema ValuesOpencostUiIngressAnnotations:
    r"""
    Annotations for Ingress resource
    """
    [...str]: any

schema ValuesOpencostUiIngressHostsItems0:
    r"""
    ValuesOpencostUiIngressHostsItems0

    Attributes
    ----------
    host : str, optional, default is "example.local"
    paths : [str], optional
    """
    [...str]: any
    host?: str
    paths?: [str]

schema ValuesOpencostUiLivenessProbe:
    r"""
    Liveness probe configuration

    Attributes
    ----------
    enabled : bool, optional, default is True
        Whether probe is enabled
    failureThreshold : int, optional, default is 3
        Number of failures for probe to be considered failed
    initialDelaySeconds : int, optional, default is 30
        Number of seconds before probe is initiated
    path : str, optional, default is "/healthz"
        Probe path
    periodSeconds : int, optional, default is 10
        Probe frequency in seconds
    """
    [...str]: any
    enabled?: bool
    failureThreshold?: int
    initialDelaySeconds?: int
    path?: str
    periodSeconds?: int

schema ValuesOpencostUiReadinessProbe:
    r"""
    Readiness probe configuration

    Attributes
    ----------
    enabled : bool, optional, default is True
        Whether probe is enabled
    failureThreshold : int, optional, default is 3
        Number of failures for probe to be considered failed
    initialDelaySeconds : int, optional, default is 30
        Number of seconds before probe is initiated
    path : str, optional, default is "/healthz"
        Probe path
    periodSeconds : int, optional, default is 10
        Probe frequency in seconds
    """
    [...str]: any
    enabled?: bool
    failureThreshold?: int
    initialDelaySeconds?: int
    path?: str
    periodSeconds?: int

schema ValuesOpencostUiResources:
    r"""
    ValuesOpencostUiResources

    Attributes
    ----------
    limits : ValuesOpencostUiResourcesLimits, optional
        CPU/Memory resource limits
    requests : ValuesOpencostUiResourcesRequests, optional
        CPU/Memory resource requests
    """
    [...str]: any
    limits?: ValuesOpencostUiResourcesLimits
    requests?: ValuesOpencostUiResourcesRequests

schema ValuesOpencostUiResourcesLimits:
    r"""
    CPU/Memory resource limits

    Attributes
    ----------
    memory : str, optional, default is "1Gi"
    """
    [...str]: any
    memory?: str

schema ValuesOpencostUiResourcesRequests:
    r"""
    CPU/Memory resource requests

    Attributes
    ----------
    cpu : str, optional, default is "10m"
    memory : str, optional, default is "55Mi"
    """
    [...str]: any
    cpu?: str
    memory?: str

schema ValuesOpencostUiRoute:
    r"""
    ValuesOpencostUiRoute

    Attributes
    ----------
    annotations : ValuesOpencostUiRouteAnnotations, optional
        Annotations for Ingress resource
    enabled : bool, optional, default is False
        OpenShift route for OpenCost UI
    host : str, optional, default is "example.local"
        haproxy.router.openshift.io/timeout: 1m
    path : any, optional, default is ""
    targetPort : str, optional, default is "http-ui"
        Redirect ingress to an extraPort defined on the service such as oauth-proxy
    tls : [any], optional
        targetPort: oauth-proxy
        Ingress TLS configuration
    """
    [...str]: any
    annotations?: ValuesOpencostUiRouteAnnotations
    enabled?: bool
    host?: str
    path?: any
    targetPort?: str
    tls?: [any]

schema ValuesOpencostUiRouteAnnotations:
    r"""
    Annotations for Ingress resource
    """
    [...str]: any

schema ValuesOpencostUiSecurityContext:
    r"""
    The security options the container should be run with
    """
    [...str]: any

schema ValuesOpencostUpdateCaTrust:
    r"""
    ValuesOpencostUpdateCaTrust

    Attributes
    ----------
    caCertsSecret : str, optional, default is "ca-certs-secret"
    enabled : bool, optional, default is False
    resources : ValuesOpencostUpdateCaTrustResources, optional
        caCertsConfig: ca-certs-config  # The name of the ConfigMap containing the CA trust configuration.
    securityContext : ValuesOpencostUpdateCaTrustSecurityContext, optional
        # Security context settings for the init container.
    """
    [...str]: any
    caCertsSecret?: str
    enabled?: bool
    resources?: ValuesOpencostUpdateCaTrustResources
    securityContext?: ValuesOpencostUpdateCaTrustSecurityContext

schema ValuesOpencostUpdateCaTrustResources:
    r"""
    caCertsConfig: ca-certs-config  # The name of the ConfigMap containing the CA trust configuration.
    """
    [...str]: any

schema ValuesOpencostUpdateCaTrustSecurityContext:
    r"""
    # Security context settings for the init container.

    Attributes
    ----------
    allowPrivilegeEscalation : bool, optional, default is False
    readOnlyRootFilesystem : bool, optional, default is True
    runAsGroup : int, optional, default is 0
    runAsNonRoot : bool, optional, default is False
    runAsUser : int, optional, default is 0
    seccompProfile : ValuesOpencostUpdateCaTrustSecurityContextSeccompProfile, optional
    """
    [...str]: any
    allowPrivilegeEscalation?: bool
    readOnlyRootFilesystem?: bool
    runAsGroup?: int
    runAsNonRoot?: bool
    runAsUser?: int
    seccompProfile?: ValuesOpencostUpdateCaTrustSecurityContextSeccompProfile

schema ValuesOpencostUpdateCaTrustSecurityContextSeccompProfile:
    r"""
    ValuesOpencostUpdateCaTrustSecurityContextSeccompProfile

    Attributes
    ----------
    $type : str, optional, default is "RuntimeDefault"
    """
    [...str]: any
    $type?: str

schema ValuesPdb:
    r"""
    PodDisruptionBudget for high availability

    Attributes
    ----------
    enabled : bool, optional, default is False
    maxUnavailable : any, optional, default is "~"
        Maximum number of pods that can be unavailable after the eviction
    minAvailable : any, optional, default is "~"
        Minimum number of pods that must be available after the eviction
    """
    [...str]: any
    enabled?: bool
    maxUnavailable?: any
    minAvailable?: any

schema ValuesPlugins:
    r"""
    ValuesPlugins

    Attributes
    ----------
    configs : any, optional, default is ""
        leave this commented to always download most recent version of plugins
        version: <INSERT_SPECIFIC_PLUGINS_VERSION>
    enabled : bool, optional, default is False
    folder : str, optional, default is "/opt/opencost/plugin"
    install : ValuesPluginsInstall, optional
    """
    [...str]: any
    configs?: any
    enabled?: bool
    folder?: str
    install?: ValuesPluginsInstall

schema ValuesPluginsInstall:
    r"""
    ValuesPluginsInstall

    Attributes
    ----------
    enabled : bool, optional, default is True
    fullImageName : str, optional, default is "curlimages/curl:latest"
    securityContext : ValuesPluginsInstallSecurityContext, optional
    """
    [...str]: any
    enabled?: bool
    fullImageName?: str
    securityContext?: ValuesPluginsInstallSecurityContext

schema ValuesPluginsInstallSecurityContext:
    r"""
    ValuesPluginsInstallSecurityContext

    Attributes
    ----------
    allowPrivilegeEscalation : bool, optional, default is False
    capabilities : ValuesPluginsInstallSecurityContextCapabilities, optional
    readOnlyRootFilesystem : bool, optional, default is True
    runAsNonRoot : bool, optional, default is True
    runAsUser : int, optional, default is 1000
    seccompProfile : ValuesPluginsInstallSecurityContextSeccompProfile, optional
    """
    [...str]: any
    allowPrivilegeEscalation?: bool
    capabilities?: ValuesPluginsInstallSecurityContextCapabilities
    readOnlyRootFilesystem?: bool
    runAsNonRoot?: bool
    runAsUser?: int
    seccompProfile?: ValuesPluginsInstallSecurityContextSeccompProfile

schema ValuesPluginsInstallSecurityContextCapabilities:
    r"""
    ValuesPluginsInstallSecurityContextCapabilities

    Attributes
    ----------
    drop : [str], optional
    """
    [...str]: any
    drop?: [str]

schema ValuesPluginsInstallSecurityContextSeccompProfile:
    r"""
    ValuesPluginsInstallSecurityContextSeccompProfile

    Attributes
    ----------
    $type : str, optional, default is "RuntimeDefault"
    """
    [...str]: any
    $type?: str

schema ValuesPodAnnotations:
    r"""
    Annotations to be added to windows exporter pods

    Attributes
    ----------
    "cluster-autoscaler.kubernetes.io/safe-to-evict" : str, optional, default is "true"
        Fix for very slow GKE cluster upgrades
    """
    [...str]: any
    "cluster-autoscaler.kubernetes.io/safe-to-evict"?: str

schema ValuesPodDisruptionBudget:
    r"""
    Ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
    """
    [...str]: any

schema ValuesPodLabels:
    r"""
    Extra labels to be added to windows exporter pods
    """
    [...str]: any

schema ValuesPodLogs:
    r"""
    Pod logs.
    Requires a destination that supports logs.
    To see the valid options, please see the [Pod Logs feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-pod-logs).

    Attributes
    ----------
    collector : str, optional, default is "alloy-logs"
        Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    destinations : [any], optional
        The destinations where logs will be sent. If empty, all logs-capable destinations will be used.
    enabled : bool, optional, default is False
        Enable gathering Kubernetes Pod logs.
    """
    [...str]: any
    collector?: str
    destinations?: [any]
    enabled?: bool

schema ValuesPodLogsViaKubernetesApi:
    r"""
    Pod logs via Kubernetes API.
    Requires a destination that supports logs.
    To see the valid options, please see the [Pod Logs via Kubernetes API feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-pod-logs-via-kubernetes-api).

    Attributes
    ----------
    collector : str, optional, default is "alloy-logs"
        Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    destinations : [any], optional
        The destinations where logs will be sent. If empty, all logs-capable destinations will be used.
    enabled : bool, optional, default is False
        Enable gathering Kubernetes Pod logs.
    """
    [...str]: any
    collector?: str
    destinations?: [any]
    enabled?: bool

schema ValuesPodMonitors:
    r"""
    Prometheus Operator PodMonitors

    Attributes
    ----------
    enabled : bool, optional, default is True
        Enable discovery of Prometheus Operator PodMonitor objects.
    excludeNamespaces : [any], optional
        Which namespaces to not look for PodMonitor objects.
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.operator.podmonitors component for PodMonitors.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        The relabelings defined in the PodMonitor object are applied first, then these relabelings are applied.
        Before the scrape, any remaining target labels that start with `__` (i.e. `__meta_kubernetes*`) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for PodMonitor objects.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    labelExpressions : [any], optional
        Complex label selectors to filter which PodMonitor objects to use.
        Example: `[{key: "app.kubernetes.io/name", operator: "NotIn", values: ["secret-app", "admin-app"]}]`
    labelSelectors : ValuesPodMonitorsLabelSelectors, optional
        Label selectors to filter which PodMonitor objects to use.
        Example: `app.kubernetes.io/name: my-app`
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for cadvisor prometheus.relabel component.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides global.maxCacheSize
    metricsTuning : ValuesPodMonitorsMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    namespaces : [any], optional
        Which namespaces to look for PodMonitor objects.
    scrapeInterval : str, optional, default is ""
        The default interval between scraping targets. Used as the default if the target resource doesn’t provide a
        scrape interval.
        Overrides global.scrapeInterval
    scrapeTimeout : str, optional, default is ""
        The default timeout for scrape requests. Used as the default if the target resource doesn’t provide a scrape
        timeout.
    """
    [...str]: any
    enabled?: bool
    excludeNamespaces?: [any]
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    labelExpressions?: [any]
    labelSelectors?: ValuesPodMonitorsLabelSelectors
    maxCacheSize?: any
    metricsTuning?: ValuesPodMonitorsMetricsTuning
    namespaces?: [any]
    scrapeInterval?: str
    scrapeTimeout?: str

schema ValuesPodMonitorsLabelSelectors:
    r"""
    Label selectors to filter which PodMonitor objects to use.
    Example: `app.kubernetes.io/name: my-app`
    """
    [...str]: any

schema ValuesPodMonitorsMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]

schema ValuesPodSecurityContext:
    r"""
    Holds pod-level security attributes and common container settings

    Attributes
    ----------
    fsGroup : int, optional, default is 1000
    runAsGroup : int, optional, default is 1000
    runAsNonRoot : bool, optional, default is True
    runAsUser : int, optional, default is 1000
    seccompProfile : ValuesPodSecurityContextSeccompProfile, optional
    """
    [...str]: any
    fsGroup?: int
    runAsGroup?: int
    runAsNonRoot?: bool
    runAsUser?: int
    seccompProfile?: ValuesPodSecurityContextSeccompProfile

schema ValuesPodSecurityContextSeccompProfile:
    r"""
    ValuesPodSecurityContextSeccompProfile

    Attributes
    ----------
    $type : str, optional, default is "RuntimeDefault"
    """
    [...str]: any
    $type?: str

schema ValuesPods:
    r"""
    ValuesPods

    Attributes
    ----------
    enabled : bool, optional, default is True
        Enable discovering Pods with annotations.
    labelSelectors : ValuesPodsLabelSelectors, optional
        Filter the list of discovered Pods by labels.
        Example: `labelSelectors: { 'app': 'myapp' }` will only discover Pods with the label `app=myapp`.
        Example: `labelSelectors: { 'app': ['myapp', 'myotherapp'] }` will only discover Pods with the label `app=myapp` or `app=myotherapp`.
    labels : ValuesPodsLabels, optional
        Add labels to metrics from discovered Pods. Runs during discovery, so __meta_ labels are available. See the
        [documentation](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.kubernetes/#pod-role)
        for the full list of meta labels.
    staticLabels : ValuesPodsStaticLabels, optional
        Metric labels to set with static data for discovered Pods.
    staticLabelsFrom : ValuesPodsStaticLabelsFrom, optional
        Static labels to set on metrics from discovered Pods, not quoted so it can reference config components.
    """
    [...str]: any
    enabled?: bool
    labelSelectors?: ValuesPodsLabelSelectors
    labels?: ValuesPodsLabels
    staticLabels?: ValuesPodsStaticLabels
    staticLabelsFrom?: ValuesPodsStaticLabelsFrom

schema ValuesPodsLabelSelectors:
    r"""
    Filter the list of discovered Pods by labels.
    Example: `labelSelectors: { 'app': 'myapp' }` will only discover Pods with the label `app=myapp`.
    Example: `labelSelectors: { 'app': ['myapp', 'myotherapp'] }` will only discover Pods with the label `app=myapp` or `app=myotherapp`.
    """
    [...str]: any

schema ValuesPodsLabels:
    r"""
    Add labels to metrics from discovered Pods. Runs during discovery, so __meta_ labels are available. See the
    [documentation](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.kubernetes/#pod-role)
    for the full list of meta labels.
    """
    [...str]: any

schema ValuesPodsStaticLabels:
    r"""
    Metric labels to set with static data for discovered Pods.
    """
    [...str]: any

schema ValuesPodsStaticLabelsFrom:
    r"""
    Static labels to set on metrics from discovered Pods, not quoted so it can reference config components.
    """
    [...str]: any

schema ValuesPprof:
    r"""
    ValuesPprof

    Attributes
    ----------
    annotationSelectors : ValuesPprofAnnotationSelectors, optional
        Select pods to profile based on pod annotations.
        Example: `color: "green"` will select pods with the annotation `color="green"`.
        Example with multiple values: `color: ["blue", "green"]` will select pods with the annotation `color="blue"` or
        `color="green"`.
    annotations : ValuesPprofAnnotations, optional
        Configure the annotations that will control how the pprof targets are discovered and how profiles are scraped.
        All annotations will be `<prefix>/<type>.<action>`, for example, to "enable" scraping of CPU profiles, set the
        annotation `profiles.grafana.com/cpu.scrape: "true"` on the pod. To set the path for memory profiles, set the
        annotation `profiles.grafana.com/memory.path: "/debug/pprof/mem"` on the pod.
    bearerTokenFile : str, optional, default is "/var/run/secrets/kubernetes.io/serviceaccount/token"
        The bearer token file to use when scraping profiles.
    enabled : bool, optional, default is True
        Gather profiles by scraping pprof HTTP endpoints
    excludeNamespaces : [any], optional
        Which namespaces to exclude looking for pods.
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for eBPF profile sources.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with `__` (i.e. `__meta_kubernetes*`) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    labelSelectors : ValuesPprofLabelSelectors, optional
        Select pods to profile based on pod labels.
        Example: `app.kubernetes.io/name: myapp` will select pods with the label `app.kubernetes.io/name=myapp`.
        Example with multiple values: `app.kubernetes.io/name: [myapp, myapp2]` will select pods with the label
        `app.kubernetes.io/name=myapp` or `app.kubernetes.io/name=myapp2`.
    namespaces : [any], optional
        Select pods to profile based on their namespaces.
    scrapeInterval : str, optional, default is "15s"
        How frequently to collect profiles.
    scrapeTimeout : str, optional, default is "18s"
        Timeout for collecting profiles.
        Must be larger than the scrape interval.
    types : ValuesPprofTypes, optional
        Profile types to gather
    """
    [...str]: any
    annotationSelectors?: ValuesPprofAnnotationSelectors
    annotations?: ValuesPprofAnnotations
    bearerTokenFile?: str
    enabled?: bool
    excludeNamespaces?: [any]
    extraDiscoveryRules?: str
    labelSelectors?: ValuesPprofLabelSelectors
    namespaces?: [any]
    scrapeInterval?: str
    scrapeTimeout?: str
    types?: ValuesPprofTypes

schema ValuesPprofAnnotationSelectors:
    r"""
    Select pods to profile based on pod annotations.
    Example: `color: "green"` will select pods with the annotation `color="green"`.
    Example with multiple values: `color: ["blue", "green"]` will select pods with the annotation `color="blue"` or
    `color="green"`.
    """
    [...str]: any

schema ValuesPprofAnnotations:
    r"""
    Configure the annotations that will control how the pprof targets are discovered and how profiles are scraped.
    All annotations will be `<prefix>/<type>.<action>`, for example, to "enable" scraping of CPU profiles, set the
    annotation `profiles.grafana.com/cpu.scrape: "true"` on the pod. To set the path for memory profiles, set the
    annotation `profiles.grafana.com/memory.path: "/debug/pprof/mem"` on the pod.

    Attributes
    ----------
    container : str, optional, default is "container"
        The annotation action for choosing the container for scraping profiles of a given type.
    enable : str, optional, default is "scrape"
        The annotation action for enabling or disabling scraping of profiles of a given type.
    path : str, optional, default is "path"
        The annotation action for choosing the path for scraping profiles of a given type.
    portName : str, optional, default is "port_name"
        The annotation action for choosing the port name for scraping profiles of a given type.
    portNumber : str, optional, default is "port"
        The annotation action for choosing the port number for scraping profiles of a given type.
    scheme : str, optional, default is "scheme"
        The annotation action for choosing the scheme for scraping profiles of a given type.
    """
    [...str]: any
    container?: str
    enable?: str
    path?: str
    portName?: str
    portNumber?: str
    scheme?: str

schema ValuesPprofLabelSelectors:
    r"""
    Select pods to profile based on pod labels.
    Example: `app.kubernetes.io/name: myapp` will select pods with the label `app.kubernetes.io/name=myapp`.
    Example with multiple values: `app.kubernetes.io/name: [myapp, myapp2]` will select pods with the label
    `app.kubernetes.io/name=myapp` or `app.kubernetes.io/name=myapp2`.
    """
    [...str]: any

schema ValuesPprofTypes:
    r"""
    Profile types to gather

    Attributes
    ----------
    block : bool, optional, default is True
    cpu : bool, optional, default is True
    fgprof : bool, optional, default is True
    godeltaprof_block : bool, optional, default is False
    godeltaprof_memory : bool, optional, default is False
    godeltaprof_mutex : bool, optional, default is False
    goroutine : bool, optional, default is True
    memory : bool, optional, default is True
    mutex : bool, optional, default is True
    """
    [...str]: any
    block?: bool
    cpu?: bool
    fgprof?: bool
    godeltaprof_block?: bool
    godeltaprof_memory?: bool
    godeltaprof_mutex?: bool
    goroutine?: bool
    memory?: bool
    mutex?: bool

schema ValuesProbes:
    r"""
    Prometheus Operator Probes

    Attributes
    ----------
    enabled : bool, optional, default is True
        Enable discovery of Prometheus Operator Probe objects.
    excludeNamespaces : [any], optional
        Which namespaces to not look for Probe objects.
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.operator.probes component for Probes.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        The relabelings defined in the PodMonitor object are applied first, then these relabelings are applied.
        Before the scrape, any remaining target labels that start with `__` (i.e. `__meta_kubernetes*`) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for Probe objects.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    labelExpressions : [any], optional
        Complex label selectors to filter which Probe objects to use.
        Example: `[{key: "app.kubernetes.io/name", operator: "NotIn", values: ["secret-app", "admin-app"]}]`
    labelSelectors : ValuesProbesLabelSelectors, optional
        Label selectors to filter which Probe objects to use.
        Example: `app.kubernetes.io/name: my-app`
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for cadvisor prometheus.relabel component.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides global.maxCacheSize
    metricsTuning : ValuesProbesMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    namespaces : [any], optional
        Which namespaces to look for Probe objects.
    scrapeInterval : str, optional, default is ""
        The default interval between scraping targets. Used as the default if the target resource doesn’t provide a
        scrape interval.
        Overrides global.scrapeInterval
    scrapeTimeout : str, optional, default is ""
        The default timeout for scrape requests. Used as the default if the target resource doesn’t provide a scrape
        timeout.
    """
    [...str]: any
    enabled?: bool
    excludeNamespaces?: [any]
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    labelExpressions?: [any]
    labelSelectors?: ValuesProbesLabelSelectors
    maxCacheSize?: any
    metricsTuning?: ValuesProbesMetricsTuning
    namespaces?: [any]
    scrapeInterval?: str
    scrapeTimeout?: str

schema ValuesProbesLabelSelectors:
    r"""
    Label selectors to filter which Probe objects to use.
    Example: `app.kubernetes.io/name: my-app`
    """
    [...str]: any

schema ValuesProbesMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]

schema ValuesProcessors:
    r"""
    Processors to apply to the data before delivering it to its destination.

    Attributes
    ----------
    attributes : ValuesProcessorsAttributes, optional
    batch : ValuesProcessorsBatch, optional
    $filter : ValuesProcessorsFilter, optional
        Filter processor settings.
        To set individual filters, use `metrics.filters`, `logs.filters`, or `traces.filters`.
    filters : ValuesProcessorsFilters, optional
    interval : ValuesProcessorsInterval, optional
    k8sattributes : ValuesProcessorsK8Sattributes, optional
    memoryLimiter : ValuesProcessorsMemoryLimiter, optional
    resourceAttributes : ValuesProcessorsResourceAttributes, optional
    resourceDetection : ValuesProcessorsResourceDetection, optional
        Capture Resource attributes from various sources. You can add more than is listed here. For example:
        resourceDetection:
          sourceType:
            enabled: true
            resourceAttributes:
              host.name:
                enabled: true
    serviceGraphMetrics : ValuesProcessorsServiceGraphMetrics, optional
    tailSampling : ValuesProcessorsTailSampling, optional
    transform : ValuesProcessorsTransform, optional
        Transform processor settings.
        To set individual transforms, use `metrics.transforms`, `logs.transforms`, or `traces.transforms`.
    """
    [...str]: any
    attributes?: ValuesProcessorsAttributes
    batch?: ValuesProcessorsBatch
    $filter?: ValuesProcessorsFilter
    filters?: ValuesProcessorsFilters
    interval?: ValuesProcessorsInterval
    k8sattributes?: ValuesProcessorsK8Sattributes
    memoryLimiter?: ValuesProcessorsMemoryLimiter
    resourceAttributes?: ValuesProcessorsResourceAttributes
    resourceDetection?: ValuesProcessorsResourceDetection
    serviceGraphMetrics?: ValuesProcessorsServiceGraphMetrics
    tailSampling?: ValuesProcessorsTailSampling
    transform?: ValuesProcessorsTransform

schema ValuesProcessorsAttributes:
    r"""
    ValuesProcessorsAttributes

    Attributes
    ----------
    actions : [any], optional
        Attribute processor actions
        Format: { key: "", value: "", action: "", pattern: "", fromAttribute: "", fromContext: "", convertedType: "" }
        Can also use `valueFrom` instead of value to use a raw reference.
    """
    [...str]: any
    actions?: [any]

schema ValuesProcessorsBatch:
    r"""
    ValuesProcessorsBatch

    Attributes
    ----------
    enabled : bool, optional
        Whether to use a batch processor.
    maxSize : int, optional, default is 0
        Maximum number of spans, metric data points, or log records to send in a single batch. This number must be
        greater than or equal to the `size` setting. If set to 0, the batch processor will not enforce a maximum size.
    size : int, optional, default is 8192
        Number of spans, metric data points, or log records after which a batch will be sent regardless of the timeout.
        This setting acts as a trigger and does not affect the size of the batch. If you need to enforce batch size limit,
        use `maxSize`.
    timeout : str, optional, default is "2s"
        How long to wait before flushing the batch.
    """
    [...str]: any
    enabled?: bool
    maxSize?: int
    size?: int
    timeout?: str

schema ValuesProcessorsFilter:
    r"""
    Filter processor settings.
    To set individual filters, use `metrics.filters`, `logs.filters`, or `traces.filters`.

    Attributes
    ----------
    errorMode : str, optional, default is "ignore"
        How to react to errors if they occur while processing a statement. Valid options are "ignore", "silent", and
        "propagate".
    """
    [...str]: any
    errorMode?: str

schema ValuesProcessorsFilters:
    r"""
    ValuesProcessorsFilters

    Attributes
    ----------
    enabled : bool, optional
        Enable the filter processor. Any rules that evaluate to true will drop the matching telemetry data.
    errorMode : str, optional
        How to react to errors if they occur while processing a statement. Valid options are "ignore", "silent", and
        "propagate".
    logs : ValuesProcessorsFiltersLogs, optional
        Log filters
    metrics : ValuesProcessorsFiltersMetrics, optional
        Metric filters
    traces : ValuesProcessorsFiltersTraces, optional
        Trace filters
    """
    [...str]: any
    enabled?: bool
    errorMode?: str
    logs?: ValuesProcessorsFiltersLogs
    metrics?: ValuesProcessorsFiltersMetrics
    traces?: ValuesProcessorsFiltersTraces

schema ValuesProcessorsFiltersLogs:
    r"""
    Log filters

    Attributes
    ----------
    logRecord : [any], optional
    """
    [...str]: any
    logRecord?: [any]

schema ValuesProcessorsFiltersMetrics:
    r"""
    Metric filters

    Attributes
    ----------
    datapoint : [any], optional
    metric : [any], optional
    """
    [...str]: any
    datapoint?: [any]
    metric?: [any]

schema ValuesProcessorsFiltersTraces:
    r"""
    Trace filters

    Attributes
    ----------
    span : [any], optional
    spanevent : [any], optional
    """
    [...str]: any
    span?: [any]
    spanevent?: [any]

schema ValuesProcessorsInterval:
    r"""
    ValuesProcessorsInterval

    Attributes
    ----------
    enabled : bool, optional, default is False
        Utilize an interval processor to aggregate metrics and periodically forward the latest values to the next
        component in the pipeline.
    interval : str, optional, default is "60s"
        The interval at which to emit aggregated metrics.
    passthrough : ValuesProcessorsIntervalPassthrough, optional
    """
    [...str]: any
    enabled?: bool
    interval?: str
    passthrough?: ValuesProcessorsIntervalPassthrough

schema ValuesProcessorsIntervalPassthrough:
    r"""
    ValuesProcessorsIntervalPassthrough

    Attributes
    ----------
    gauge : bool, optional, default is False
        Determines whether gauge metrics should be passed through as they are or aggregated.
    summary : bool, optional, default is False
        Determines whether summary metrics should be passed through as they are or aggregated.
    """
    [...str]: any
    gauge?: bool
    summary?: bool

schema ValuesProcessorsK8Sattributes:
    r"""
    ValuesProcessorsK8Sattributes

    Attributes
    ----------
    annotations : [any], optional
        Kubernetes annotations to extract and add to the attributes of the received telemetry data in the form of a
        list of otelcol.processor.k8sattributes extract > annotation blocks. See the
        [Alloy documentation](https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.processor.k8sattributes/#annotation-block)
        for details on how to configure annotation blocks.
    labels : [any], optional
        Kubernetes labels to extract and add to the attributes of the received telemetry data in the form of a list of
        otelcol.processor.k8sattributes extract > label blocks. See the
        [Alloy documentation](https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.processor.k8sattributes/#extract-label-block)
        for details on how to configure label blocks.
    metadata : [str], optional
        Kubernetes metadata to extract and add to the attributes of the received telemetry data.
    passthrough : bool, optional, default is False
        Pass through signals as-is, only adding a `k8s.pod.ip` resource attribute.
    podAssociation : [ValuesProcessorsK8SattributesPodAssociationItems0], optional
        Defines the rules on how to associate logs/traces/metrics to Pods.
    """
    [...str]: any
    annotations?: [any]
    labels?: [any]
    metadata?: [str]
    passthrough?: bool
    podAssociation?: [ValuesProcessorsK8SattributesPodAssociationItems0]

schema ValuesProcessorsK8SattributesPodAssociationItems0:
    r"""
    ValuesProcessorsK8SattributesPodAssociationItems0

    Attributes
    ----------
    from : str, optional, default is "connection"
    name : str, optional, default is "k8s.pod.uid"
    """
    [...str]: any
    from?: str
    name?: str

schema ValuesProcessorsMemoryLimiter:
    r"""
    ValuesProcessorsMemoryLimiter

    Attributes
    ----------
    checkInterval : str, optional, default is "1s"
        How often to check memory usage.
    enabled : bool, optional, default is False
        Whether to use a memory limiter.
    limit : str, optional, default is "0MiB"
        Maximum amount of memory targeted to be allocated by the process heap.
    """
    [...str]: any
    checkInterval?: str
    enabled?: bool
    limit?: str

schema ValuesProcessorsResourceAttributes:
    r"""
    ValuesProcessorsResourceAttributes

    Attributes
    ----------
    removeList : [any], optional
        List of additional resource attribute names to remove from OTEL signals
        These attributes will be deleted from the resource context for all signal types (metrics, logs, traces)
    useDefaultRemoveList : bool, optional
        Whether to use the default remove list for resource attributes
    """
    [...str]: any
    removeList?: [any]
    useDefaultRemoveList?: bool

schema ValuesProcessorsResourceDetection:
    r"""
    Capture Resource attributes from various sources. You can add more than is listed here. For example:
    resourceDetection:
      sourceType:
        enabled: true
        resourceAttributes:
          host.name:
            enabled: true

    Attributes
    ----------
    env : ValuesProcessorsResourceDetectionEnv, optional
    kubernetesNode : ValuesProcessorsResourceDetectionKubernetesNode, optional
    override : bool, optional, default is True
        Configures whether existing resource attributes should be overridden or preserved.
    system : ValuesProcessorsResourceDetectionSystem, optional
    """
    [...str]: any
    env?: ValuesProcessorsResourceDetectionEnv
    kubernetesNode?: ValuesProcessorsResourceDetectionKubernetesNode
    override?: bool
    system?: ValuesProcessorsResourceDetectionSystem

schema ValuesProcessorsResourceDetectionEnv:
    r"""
    ValuesProcessorsResourceDetectionEnv

    Attributes
    ----------
    enabled : bool, optional, default is True
        Enable getting resource attributes from the OTEL_RESOURCE_ATTRIBUTES environment variable.
    """
    [...str]: any
    enabled?: bool

schema ValuesProcessorsResourceDetectionKubernetesNode:
    r"""
    ValuesProcessorsResourceDetectionKubernetesNode

    Attributes
    ----------
    authType : str, optional, default is "serviceAccount"
        The authentication method. This should not be changed.
    enabled : bool, optional, default is False
        Enable getting resource attributes about the Kubernetes node from the API server.
    nodeFromEnvVar : str, optional, default is "K8S_NODE_NAME"
        The name of an environment variable from which to retrieve the node name.
    """
    [...str]: any
    authType?: str
    enabled?: bool
    nodeFromEnvVar?: str

schema ValuesProcessorsResourceDetectionSystem:
    r"""
    ValuesProcessorsResourceDetectionSystem

    Attributes
    ----------
    enabled : bool, optional, default is True
        Enable getting resource attributes from the host machine.
    hostnameSources : [str], optional
        The priority list of sources from which the hostname will be determined.
        Options: ["dns", "os", "cname", "lookup"].
    resourceAttributes : ValuesProcessorsResourceDetectionSystemResourceAttributes, optional
        The list of resource attributes to add for system resource detection. See the
        [Alloy documentation](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.resourcedetection/#system--resource_attributes)
        for a list of available attributes.
    """
    [...str]: any
    enabled?: bool
    hostnameSources?: [str]
    resourceAttributes?: ValuesProcessorsResourceDetectionSystemResourceAttributes

schema ValuesProcessorsResourceDetectionSystemResourceAttributes:
    r"""
    The list of resource attributes to add for system resource detection. See the
    [Alloy documentation](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.resourcedetection/#system--resource_attributes)
    for a list of available attributes.
    """
    [...str]: any

schema ValuesProcessorsServiceGraphMetrics:
    r"""
    ValuesProcessorsServiceGraphMetrics

    Attributes
    ----------
    cacheLoop : str, optional
        Configures how often to delete series which haven’t been updated.
    collector : ValuesProcessorsServiceGraphMetricsCollector, optional
        Settings for the Alloy instance that will handle service graph metrics.
    databaseNameAttribute : str, optional
        The attribute name used to identify the database name from span attributes.
        DEPRECATED: Please use databaseNameAttributes instead. If this is provided, it will override
        databaseNameAttributes as the only attribute to used.
    databaseNameAttributes : [str], optional
        The attribute names used to identify the database name from span attributes.
    destinations : [any], optional
        The destinations where service graph metrics will be sent. If empty, all metrics-capable destinations will be used.
    dimensions : [str], optional
        A list of dimensions to add with the default dimensions.
    enabled : bool, optional
        Generate service graph metrics from traces. This will deploy an additional Alloy
        instance to handle service graph metrics generation. Traces sent to this destination will
        be aumatically forwarded, using a load balancer component, to this Alloy instance.
    latencyHistogramBuckets : [str], optional
        Buckets for latency histogram metrics.
    metricsFlushInterval : str, optional
        The interval at which metrics are flushed to downstream components.
    receiver : ValuesProcessorsServiceGraphMetricsReceiver, optional
        The service graph otlp receiver configuration.
    storeExpirationLoop : str, optional
        The time to expire old entries from the store periodically.
    """
    [...str]: any
    cacheLoop?: str
    collector?: ValuesProcessorsServiceGraphMetricsCollector
    databaseNameAttribute?: str
    databaseNameAttributes?: [str]
    destinations?: [any]
    dimensions?: [str]
    enabled?: bool
    latencyHistogramBuckets?: [str]
    metricsFlushInterval?: str
    receiver?: ValuesProcessorsServiceGraphMetricsReceiver
    storeExpirationLoop?: str

schema ValuesProcessorsServiceGraphMetricsCollector:
    r"""
    Settings for the Alloy instance that will handle service graph metrics.

    Attributes
    ----------
    alloy : ValuesProcessorsServiceGraphMetricsCollectorAlloy, optional
    controller : ValuesProcessorsServiceGraphMetricsCollectorController, optional
    """
    [...str]: any
    alloy?: ValuesProcessorsServiceGraphMetricsCollectorAlloy
    controller?: ValuesProcessorsServiceGraphMetricsCollectorController

schema ValuesProcessorsServiceGraphMetricsCollectorAlloy:
    r"""
    ValuesProcessorsServiceGraphMetricsCollectorAlloy
    """
    [...str]: any

schema ValuesProcessorsServiceGraphMetricsCollectorController:
    r"""
    ValuesProcessorsServiceGraphMetricsCollectorController

    Attributes
    ----------
    replicas : int, optional
    $type : str, optional
    """
    [...str]: any
    replicas?: int
    $type?: str

schema ValuesProcessorsServiceGraphMetricsReceiver:
    r"""
    The service graph otlp receiver configuration.

    Attributes
    ----------
    otlp : ValuesProcessorsServiceGraphMetricsReceiverOtlp, optional
    """
    [...str]: any
    otlp?: ValuesProcessorsServiceGraphMetricsReceiverOtlp

schema ValuesProcessorsServiceGraphMetricsReceiverOtlp:
    r"""
    ValuesProcessorsServiceGraphMetricsReceiverOtlp

    Attributes
    ----------
    grpc : ValuesProcessorsServiceGraphMetricsReceiverOtlpGrpc, optional
    """
    [...str]: any
    grpc?: ValuesProcessorsServiceGraphMetricsReceiverOtlpGrpc

schema ValuesProcessorsServiceGraphMetricsReceiverOtlpGrpc:
    r"""
    ValuesProcessorsServiceGraphMetricsReceiverOtlpGrpc

    Attributes
    ----------
    maxReceivedMessageSize : str, optional
    """
    [...str]: any
    maxReceivedMessageSize?: str

schema ValuesProcessorsTailSampling:
    r"""
    ValuesProcessorsTailSampling

    Attributes
    ----------
    collector : ValuesProcessorsTailSamplingCollector, optional
        Settings for the Alloy instance that will handle tail sampling.
    decisionCache : ValuesProcessorsTailSamplingDecisionCache, optional
        The decision cache for the tail sampling. When you use decision_cache, configure it with a much higher value
        than num_traces so decisions for trace IDs are kept longer than the span data for the trace.
    decisionWait : str, optional
        Wait time since the first span of a trace before making a sampling decision.
    enabled : bool, optional
        Apply tail sampling policies to the traces before delivering them to this destination. This will create an
        additional Alloy instance to handle the tail sampling, and traces sent to this destination will be automatically
        forwarded, using a load balancer component, to the new sampling Alloy instance.
    expectedNewTracesPerSec : int, optional
        Expected number of new traces (helps in allocating data structures).
    numTraces : int, optional
         Determines the buffer size of the trace delete channel which is composed of trace IDs that are being deleted.
        Default is 0, which means no buffer is used.
    policies : [any], optional
        Tail sampling policies to apply.
    receiver : ValuesProcessorsTailSamplingReceiver, optional
        The tail sampling otlp receiver configuration.
    """
    [...str]: any
    collector?: ValuesProcessorsTailSamplingCollector
    decisionCache?: ValuesProcessorsTailSamplingDecisionCache
    decisionWait?: str
    enabled?: bool
    expectedNewTracesPerSec?: int
    numTraces?: int
    policies?: [any]
    receiver?: ValuesProcessorsTailSamplingReceiver

schema ValuesProcessorsTailSamplingCollector:
    r"""
    Settings for the Alloy instance that will handle tail sampling.

    Attributes
    ----------
    alloy : ValuesProcessorsTailSamplingCollectorAlloy, optional
    controller : ValuesProcessorsTailSamplingCollectorController, optional
    """
    [...str]: any
    alloy?: ValuesProcessorsTailSamplingCollectorAlloy
    controller?: ValuesProcessorsTailSamplingCollectorController

schema ValuesProcessorsTailSamplingCollectorAlloy:
    r"""
    ValuesProcessorsTailSamplingCollectorAlloy
    """
    [...str]: any

schema ValuesProcessorsTailSamplingCollectorController:
    r"""
    ValuesProcessorsTailSamplingCollectorController

    Attributes
    ----------
    replicas : int, optional
    $type : str, optional
    """
    [...str]: any
    replicas?: int
    $type?: str

schema ValuesProcessorsTailSamplingDecisionCache:
    r"""
    The decision cache for the tail sampling. When you use decision_cache, configure it with a much higher value
    than num_traces so decisions for trace IDs are kept longer than the span data for the trace.

    Attributes
    ----------
    nonSampledCacheSize : int, optional
        Configures amount of trace IDs to be kept in an LRU cache, persisting the "drop" decisions for traces that
        may have already been released from memory. By default, the size is 0 and the cache is inactive.
    sampledCacheSize : int, optional
        Configures amount of trace IDs to be kept in an LRU cache, persisting the "keep" decisions for traces that
        may have already been released from memory. By default, the size is 0 and the cache is inactive.
    """
    [...str]: any
    nonSampledCacheSize?: int
    sampledCacheSize?: int

schema ValuesProcessorsTailSamplingReceiver:
    r"""
    The tail sampling otlp receiver configuration.

    Attributes
    ----------
    otlp : ValuesProcessorsTailSamplingReceiverOtlp, optional
    """
    [...str]: any
    otlp?: ValuesProcessorsTailSamplingReceiverOtlp

schema ValuesProcessorsTailSamplingReceiverOtlp:
    r"""
    ValuesProcessorsTailSamplingReceiverOtlp

    Attributes
    ----------
    grpc : ValuesProcessorsTailSamplingReceiverOtlpGrpc, optional
    """
    [...str]: any
    grpc?: ValuesProcessorsTailSamplingReceiverOtlpGrpc

schema ValuesProcessorsTailSamplingReceiverOtlpGrpc:
    r"""
    ValuesProcessorsTailSamplingReceiverOtlpGrpc

    Attributes
    ----------
    maxReceivedMessageSize : str, optional
    """
    [...str]: any
    maxReceivedMessageSize?: str

schema ValuesProcessorsTransform:
    r"""
    Transform processor settings.
    To set individual transforms, use `metrics.transforms`, `logs.transforms`, or `traces.transforms`.

    Attributes
    ----------
    errorMode : str, optional, default is "ignore"
        How to react to errors if they occur while processing a statement. Valid options are "ignore", "silent", and
        "propagate".
    logs : ValuesProcessorsTransformLogs, optional
        Log transforms
    metrics : ValuesProcessorsTransformMetrics, optional
        Metric transforms
    traces : ValuesProcessorsTransformTraces, optional
        Trace transforms
    """
    [...str]: any
    errorMode?: str
    logs?: ValuesProcessorsTransformLogs
    metrics?: ValuesProcessorsTransformMetrics
    traces?: ValuesProcessorsTransformTraces

schema ValuesProcessorsTransformLogs:
    r"""
    Log transforms

    Attributes
    ----------
    log : [any], optional
        Log transforms
    logFrom : [any], optional
        Raw log transforms
    logToResource : ValuesProcessorsTransformLogsLogToResource, optional
        Promote certain log attributes to resource attributes. This is helpful for translating log data from Loki
        sources to OTLP format.
        Format: `{ <log attribute name>: <resource attribute name> }`.
        Will not copy if the resource attribute already exists.
    resource : [any], optional
        Log resource transforms
    resourceFrom : [any], optional
        Raw log resource transforms
    """
    [...str]: any
    log?: [any]
    logFrom?: [any]
    logToResource?: ValuesProcessorsTransformLogsLogToResource
    resource?: [any]
    resourceFrom?: [any]

schema ValuesProcessorsTransformLogsLogToResource:
    r"""
    Promote certain log attributes to resource attributes. This is helpful for translating log data from Loki
    sources to OTLP format.
    Format: `{ <log attribute name>: <resource attribute name> }`.
    Will not copy if the resource attribute already exists.

    Attributes
    ----------
    container : str, optional
    cronjob : str, optional
    daemonset : str, optional
    deployment : str, optional
    deployment_environment : str, optional
    deployment_environment_name : str, optional
    job_name : str, optional
    namespace : str, optional
    pod : str, optional
    replicaset : str, optional
    service_name : str, optional
    service_namespace : str, optional
    statefulset : str, optional
    """
    [...str]: any
    container?: str
    cronjob?: str
    daemonset?: str
    deployment?: str
    deployment_environment?: str
    deployment_environment_name?: str
    job_name?: str
    namespace?: str
    pod?: str
    replicaset?: str
    service_name?: str
    service_namespace?: str
    statefulset?: str

schema ValuesProcessorsTransformMetrics:
    r"""
    Metric transforms

    Attributes
    ----------
    datapoint : [any], optional
        Metric datapoint transforms
    datapointFrom : [any], optional
        Raw metric datapoint transforms
    datapointToResource : ValuesProcessorsTransformMetricsDatapointToResource, optional
        Promote certain metric datapoint attributes to resource attributes. This is helpful for translating metric
        data from Prometheus sources to OTLP format.
        Format: `{ <datapoint attribute name>: <resource attribute name> }`.
        Will not copy if the resource attribute already exists.
    metric : [any], optional
        Metric transforms
    metricFrom : [any], optional
        Raw metric transforms
    resource : [any], optional
        Metric resource transforms
    resourceFrom : [any], optional
        Raw metric resource transforms
    """
    [...str]: any
    datapoint?: [any]
    datapointFrom?: [any]
    datapointToResource?: ValuesProcessorsTransformMetricsDatapointToResource
    metric?: [any]
    metricFrom?: [any]
    resource?: [any]
    resourceFrom?: [any]

schema ValuesProcessorsTransformMetricsDatapointToResource:
    r"""
    Promote certain metric datapoint attributes to resource attributes. This is helpful for translating metric
    data from Prometheus sources to OTLP format.
    Format: `{ <datapoint attribute name>: <resource attribute name> }`.
    Will not copy if the resource attribute already exists.

    Attributes
    ----------
    deployment_environment : str, optional
    deployment_environment_name : str, optional
    service_name : str, optional
    service_namespace : str, optional
    """
    [...str]: any
    deployment_environment?: str
    deployment_environment_name?: str
    service_name?: str
    service_namespace?: str

schema ValuesProcessorsTransformTraces:
    r"""
    Trace transforms

    Attributes
    ----------
    resource : [any], optional
        Trace resource transforms
    resourceFrom : [any], optional
        Raw trace resource transforms
    span : [any], optional
        Trace span transforms
    spanFrom : [any], optional
        Raw trace span transforms
    spanevent : [any], optional
        Trace spanevent transforms
    spaneventFrom : [any], optional
        Raw trace spanevent transforms
    """
    [...str]: any
    resource?: [any]
    resourceFrom?: [any]
    span?: [any]
    spanFrom?: [any]
    spanevent?: [any]
    spaneventFrom?: [any]

schema ValuesProfiles:
    r"""
    ValuesProfiles

    Attributes
    ----------
    enabled : bool, optional
        Enable sending profiles to this destination.
        @ section -- Profiles
    target : str, optional
        The Alloy component reference for sending profiles.
        @ section -- Profiles
    """
    [...str]: any
    enabled?: bool
    target?: str

schema ValuesProfilesReceiver:
    r"""
    Profiles Receiver enables receiving profiles from applications.
    Requires a destination that supports profiles.
    To see the valid options, please see the [Profiles Receiver feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-profiles-receiver).

    Attributes
    ----------
    collector : str, optional, default is "alloy-receiver"
        Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    destinations : [any], optional
        The destinations where profiles will be sent. If empty, all profiles-capable destinations will be used.
    enabled : bool, optional, default is False
        Enable gathering profiles from applications.
    """
    [...str]: any
    collector?: str
    destinations?: [any]
    enabled?: bool

schema ValuesProfiling:
    r"""
    Profiling enables gathering profiles from applications.
    Requires a destination that supports profiles.
    To see the valid options, please see the [Profiling feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-profiling).

    Attributes
    ----------
    collector : str, optional, default is "alloy-profiles"
        Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    destinations : [any], optional
        The destinations where profiles will be sent. If empty, all profiles-capable destinations will be used.
    enabled : bool, optional, default is False
        Enable gathering profiles from applications.
    """
    [...str]: any
    collector?: str
    destinations?: [any]
    enabled?: bool

schema ValuesPrometheus:
    r"""
    ValuesPrometheus

    Attributes
    ----------
    monitor : ValuesPrometheusMonitor, optional
    podMonitor : ValuesPrometheusPodMonitor, optional
        PodMonitor defines monitoring for a set of pods.
        ref. https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api-reference/api.md#podmonitor
        Using a PodMonitor may be preferred in some environments where there is very large number
        of Windows Exporter endpoints (1000+) behind a single service.
        The PodMonitor is disabled by default. When switching from ServiceMonitor to PodMonitor,
        the time series resulting from the configuration through PodMonitor may have different labels.
        For instance, there will not be the service label any longer which might
        affect PromQL queries selecting that label.
    scrapeconfig : ValuesPrometheusScrapeconfig, optional
        # Create a scrapeConfig resource for scraping the kube-state-metrics service. Use this instead of serviceMonitor
        # to have more instances of kube-state-metrics safety.
    """
    [...str]: any
    monitor?: ValuesPrometheusMonitor
    podMonitor?: ValuesPrometheusPodMonitor
    scrapeconfig?: ValuesPrometheusScrapeconfig

schema ValuesPrometheusMonitor:
    r"""
    ValuesPrometheusMonitor

    Attributes
    ----------
    additionalLabels : ValuesPrometheusMonitorAdditionalLabels, optional
    annotations : ValuesPrometheusMonitorAnnotations, optional
    apiVersion : str, optional, default is ""
        # prometheus.monitor.apiVersion ApiVersion for the serviceMonitor Resource(defaults to "monitoring.coreos.com/v1")
    attachMetadata : ValuesPrometheusMonitorAttachMetadata, optional
        # Attach node metadata to discovered targets. Requires Prometheus v2.35.0 and above.
        #
    basicAuth : ValuesPrometheusMonitorBasicAuth, optional
    bearerTokenFile : any, optional, default is ""
    enabled : bool, optional, default is False
    http : ValuesPrometheusMonitorHttp, optional
        # kube-state-metrics endpoint
    interval : str, optional, default is ""
    jobLabel : str, optional, default is ""
    labelLimit : int, optional, default is 0
        # Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.
        #
    labelNameLengthLimit : int, optional, default is 0
        # Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.
        #
    labelValueLengthLimit : int, optional, default is 0
        # Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.
        #
    metricRelabelings : [any], optional
    metrics : ValuesPrometheusMonitorMetrics, optional
        # selfMonitor endpoint
    namespace : str, optional, default is ""
    namespaceSelector : [any], optional
    podTargetLabels : [any], optional
        List of pod labels to add to windows exporter metrics
        https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api-reference/api.md#servicemonitor
    proxyUrl : str, optional, default is ""
        # proxyUrl: URL of a proxy that should be used for scraping.
        #
    relabelings : [any], optional
    sampleLimit : int, optional, default is 0
        # SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.
        #
    scheme : str, optional, default is "http"
    scrapeTimeout : str, optional, default is "10s"
    selectorOverride : ValuesPrometheusMonitorSelectorOverride, optional
        # Override serviceMonitor selector
        #
    targetLabels : [any], optional
        List of target labels to add to node exporter metrics
        https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api-reference/api.md#servicemonitor
    targetLimit : int, optional, default is 0
        # TargetLimit defines a limit on the number of scraped targets that will be accepted.
        #
    tlsConfig : ValuesPrometheusMonitorTlsConfig, optional
    """
    [...str]: any
    additionalLabels?: ValuesPrometheusMonitorAdditionalLabels
    annotations?: ValuesPrometheusMonitorAnnotations
    apiVersion?: str
    attachMetadata?: ValuesPrometheusMonitorAttachMetadata
    basicAuth?: ValuesPrometheusMonitorBasicAuth
    bearerTokenFile?: any
    enabled?: bool
    http?: ValuesPrometheusMonitorHttp
    interval?: str
    jobLabel?: str
    labelLimit?: int
    labelNameLengthLimit?: int
    labelValueLengthLimit?: int
    metricRelabelings?: [any]
    metrics?: ValuesPrometheusMonitorMetrics
    namespace?: str
    namespaceSelector?: [any]
    podTargetLabels?: [any]
    proxyUrl?: str
    relabelings?: [any]
    sampleLimit?: int
    scheme?: str
    scrapeTimeout?: str
    selectorOverride?: ValuesPrometheusMonitorSelectorOverride
    targetLabels?: [any]
    targetLimit?: int
    tlsConfig?: ValuesPrometheusMonitorTlsConfig

schema ValuesPrometheusMonitorAdditionalLabels:
    r"""
    ValuesPrometheusMonitorAdditionalLabels
    """
    [...str]: any

schema ValuesPrometheusMonitorAnnotations:
    r"""
    ValuesPrometheusMonitorAnnotations
    """
    [...str]: any

schema ValuesPrometheusMonitorAttachMetadata:
    r"""
    # Attach node metadata to discovered targets. Requires Prometheus v2.35.0 and above.
    #

    Attributes
    ----------
    node : bool, optional, default is False
    """
    [...str]: any
    node?: bool

schema ValuesPrometheusMonitorBasicAuth:
    r"""
    ValuesPrometheusMonitorBasicAuth
    """
    [...str]: any

schema ValuesPrometheusMonitorHttp:
    r"""
    # kube-state-metrics endpoint

    Attributes
    ----------
    bearerTokenFile : str, optional, default is ""
        # File to read bearer token for scraping targets
    bearerTokenSecret : ValuesPrometheusMonitorHttpBearerTokenSecret, optional
        # Secret to mount to read bearer token for scraping targets. The secret needs
        # to be in the same namespace as the service monitor and accessible by the
        # Prometheus Operator
    enableHttp2 : bool, optional, default is False
        # Whether to enable HTTP2 for servicemonitor
    honorLabels : bool, optional, default is False
    interval : str, optional, default is ""
    metricRelabelings : [any], optional
    proxyUrl : str, optional, default is ""
    relabelings : [any], optional
    scheme : str, optional, default is ""
    scrapeTimeout : str, optional, default is ""
    tlsConfig : ValuesPrometheusMonitorHttpTlsConfig, optional
        name: secret-name
        key:  key-name
    """
    [...str]: any
    bearerTokenFile?: str
    bearerTokenSecret?: ValuesPrometheusMonitorHttpBearerTokenSecret
    enableHttp2?: bool
    honorLabels?: bool
    interval?: str
    metricRelabelings?: [any]
    proxyUrl?: str
    relabelings?: [any]
    scheme?: str
    scrapeTimeout?: str
    tlsConfig?: ValuesPrometheusMonitorHttpTlsConfig

schema ValuesPrometheusMonitorHttpBearerTokenSecret:
    r"""
    # Secret to mount to read bearer token for scraping targets. The secret needs
    # to be in the same namespace as the service monitor and accessible by the
    # Prometheus Operator
    """
    [...str]: any

schema ValuesPrometheusMonitorHttpTlsConfig:
    r"""
    name: secret-name
    key:  key-name
    """
    [...str]: any

schema ValuesPrometheusMonitorMetrics:
    r"""
    # selfMonitor endpoint

    Attributes
    ----------
    bearerTokenFile : str, optional, default is ""
        # File to read bearer token for scraping targets
    bearerTokenSecret : ValuesPrometheusMonitorMetricsBearerTokenSecret, optional
        # Secret to mount to read bearer token for scraping targets. The secret needs
        # to be in the same namespace as the service monitor and accessible by the
        # Prometheus Operator
    enableHttp2 : bool, optional, default is False
        # Whether to enable HTTP2 for servicemonitor
    honorLabels : bool, optional, default is False
    interval : str, optional, default is ""
    metricRelabelings : [any], optional
    proxyUrl : str, optional, default is ""
    relabelings : [any], optional
    scheme : str, optional, default is ""
    scrapeTimeout : str, optional, default is ""
    tlsConfig : ValuesPrometheusMonitorMetricsTlsConfig, optional
        name: secret-name
        key:  key-name
    """
    [...str]: any
    bearerTokenFile?: str
    bearerTokenSecret?: ValuesPrometheusMonitorMetricsBearerTokenSecret
    enableHttp2?: bool
    honorLabels?: bool
    interval?: str
    metricRelabelings?: [any]
    proxyUrl?: str
    relabelings?: [any]
    scheme?: str
    scrapeTimeout?: str
    tlsConfig?: ValuesPrometheusMonitorMetricsTlsConfig

schema ValuesPrometheusMonitorMetricsBearerTokenSecret:
    r"""
    # Secret to mount to read bearer token for scraping targets. The secret needs
    # to be in the same namespace as the service monitor and accessible by the
    # Prometheus Operator
    """
    [...str]: any

schema ValuesPrometheusMonitorMetricsTlsConfig:
    r"""
    name: secret-name
    key:  key-name
    """
    [...str]: any

schema ValuesPrometheusMonitorSelectorOverride:
    r"""
    # Override serviceMonitor selector
    #
    """
    [...str]: any

schema ValuesPrometheusMonitorTlsConfig:
    r"""
    ValuesPrometheusMonitorTlsConfig
    """
    [...str]: any

schema ValuesPrometheusOperatorObjects:
    r"""
    Prometheus Operator Objects enables the gathering of metrics from objects like Probes, PodMonitors, and
    ServiceMonitors. Requires a destination that supports metrics.
    To see the valid options, please see the [Prometheus Operator Objects feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-prometheus-operator-objects).

    Attributes
    ----------
    collector : str, optional, default is "alloy-metrics"
        Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    destinations : [any], optional
        The destinations where metrics will be sent. If empty, all metrics-capable destinations will be used.
    enabled : bool, optional, default is False
        Enable gathering metrics from Prometheus Operator Objects.
    """
    [...str]: any
    collector?: str
    destinations?: [any]
    enabled?: bool

schema ValuesPrometheusPodMonitor:
    r"""
    PodMonitor defines monitoring for a set of pods.
    ref. https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api-reference/api.md#podmonitor
    Using a PodMonitor may be preferred in some environments where there is very large number
    of Windows Exporter endpoints (1000+) behind a single service.
    The PodMonitor is disabled by default. When switching from ServiceMonitor to PodMonitor,
    the time series resulting from the configuration through PodMonitor may have different labels.
    For instance, there will not be the service label any longer which might
    affect PromQL queries selecting that label.

    Attributes
    ----------
    additionalLabels : ValuesPrometheusPodMonitorAdditionalLabels, optional
        Additional labels, e.g. setting a label for pod monitor selector as set in prometheus
    apiVersion : str, optional, default is ""
        apiVersion defaults to monitoring.coreos.com/v1.
    attachMetadata : ValuesPrometheusPodMonitorAttachMetadata, optional
        Attach node metadata to discovered targets. Requires Prometheus v2.35.0 and above.
    authorization : ValuesPrometheusPodMonitorAuthorization, optional
        Authorization section for this endpoint.
        https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api-reference/api.md#safeauthorization
    basicAuth : ValuesPrometheusPodMonitorBasicAuth, optional
        BasicAuth allow an endpoint to authenticate over basic authentication.
        More info: https://prometheus.io/docs/operating/configuration/#endpoint
    bearerTokenSecret : ValuesPrometheusPodMonitorBearerTokenSecret, optional
        Secret to mount to read bearer token for scraping targets.
        The secret needs to be in the same namespace as the pod monitor and accessible by the Prometheus Operator.
        https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#secretkeyselector-v1-core
    enableHttp2 : str, optional, default is ""
        Whether to enable HTTP2. Default false.
    enabled : bool, optional, default is False
    filterRunning : str, optional, default is ""
        Drop pods that are not running. (Failed, Succeeded).
        Enabled by default. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-phase
    followRedirects : str, optional, default is ""
        FollowRedirects configures whether scrape requests follow HTTP 3xx redirects. Default false.
    honorLabels : bool, optional, default is True
        HonorLabels chooses the metric's labels on collisions with target labels.
    honorTimestamps : bool, optional, default is True
        HonorTimestamps controls whether Prometheus respects the timestamps present in scraped data.
    interval : str, optional, default is ""
        Interval at which endpoints should be scraped. If not specified Prometheus' global scrape interval is used.
    jobLabel : str, optional, default is ""
        The label to use to retrieve the job name from. Defaults to label app.kubernetes.io/name.
    labelLimit : int, optional, default is 0
        Per-scrape limit on number of labels that will be accepted for a sample.
        Only valid in Prometheus versions 2.27.0 and newer.
    labelNameLengthLimit : int, optional, default is 0
        Per-scrape limit on length of labels name that will be accepted for a sample.
        Only valid in Prometheus versions 2.27.0 and newer.
    labelValueLengthLimit : int, optional, default is 0
        Per-scrape limit on length of labels value that will be accepted for a sample.
        Only valid in Prometheus versions 2.27.0 and newer.
    metricRelabelings : [any], optional
        MetricRelabelConfigs to apply to samples before ingestion.
    namespace : str, optional, default is ""
        Namespace in which to deploy the pod monitor. Defaults to the release namespace.
    oauth2 : ValuesPrometheusPodMonitorOauth2, optional
        OAuth2 for the URL. Only valid in Prometheus versions 2.27.0 and newer.
        https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api-reference/api.md#oauth2
    params : ValuesPrometheusPodMonitorParams, optional
        Optional HTTP URL parameters
    path : str, optional, default is "/metrics"
        Path to scrape metrics at.
    podTargetLabels : [any], optional
         release: kube-prometheus-stack
        PodTargetLabels transfers labels of the Kubernetes Pod onto the target.
    proxyUrl : str, optional, default is ""
        ProxyURL eg http://proxyserver:2195. Directs scrapes through proxy to this endpoint.
    relabelings : [any], optional
        RelabelConfigs to apply to samples before scraping. Prometheus Operator automatically adds
        relabelings for a few standard Kubernetes fields. The original scrape job's name
        is available via the __tmp_prometheus_job_name label.
        More info: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
    sampleLimit : int, optional, default is 0
        SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.
    scheme : str, optional, default is "http"
        Scheme/protocol to use for scraping.
    scrapeTimeout : str, optional, default is ""
        Timeout after which the scrape is ended. If not specified, the Prometheus global scrape interval is used.
    selectorOverride : ValuesPrometheusPodMonitorSelectorOverride, optional
        Override pod selector to select pod objects.
    targetLimit : int, optional, default is 0
        TargetLimit defines a limit on the number of scraped targets that will be accepted.
    tlsConfig : ValuesPrometheusPodMonitorTlsConfig, optional
        TLS configuration to use when scraping the endpoint.
    """
    [...str]: any
    additionalLabels?: ValuesPrometheusPodMonitorAdditionalLabels
    apiVersion?: str
    attachMetadata?: ValuesPrometheusPodMonitorAttachMetadata
    authorization?: ValuesPrometheusPodMonitorAuthorization
    basicAuth?: ValuesPrometheusPodMonitorBasicAuth
    bearerTokenSecret?: ValuesPrometheusPodMonitorBearerTokenSecret
    enableHttp2?: str
    enabled?: bool
    filterRunning?: str
    followRedirects?: str
    honorLabels?: bool
    honorTimestamps?: bool
    interval?: str
    jobLabel?: str
    labelLimit?: int
    labelNameLengthLimit?: int
    labelValueLengthLimit?: int
    metricRelabelings?: [any]
    namespace?: str
    oauth2?: ValuesPrometheusPodMonitorOauth2
    params?: ValuesPrometheusPodMonitorParams
    path?: str
    podTargetLabels?: [any]
    proxyUrl?: str
    relabelings?: [any]
    sampleLimit?: int
    scheme?: str
    scrapeTimeout?: str
    selectorOverride?: ValuesPrometheusPodMonitorSelectorOverride
    targetLimit?: int
    tlsConfig?: ValuesPrometheusPodMonitorTlsConfig

schema ValuesPrometheusPodMonitorAdditionalLabels:
    r"""
    Additional labels, e.g. setting a label for pod monitor selector as set in prometheus
    """
    [...str]: any

schema ValuesPrometheusPodMonitorAttachMetadata:
    r"""
    Attach node metadata to discovered targets. Requires Prometheus v2.35.0 and above.

    Attributes
    ----------
    node : bool, optional, default is False
    """
    [...str]: any
    node?: bool

schema ValuesPrometheusPodMonitorAuthorization:
    r"""
    Authorization section for this endpoint.
    https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api-reference/api.md#safeauthorization
    """
    [...str]: any

schema ValuesPrometheusPodMonitorBasicAuth:
    r"""
    BasicAuth allow an endpoint to authenticate over basic authentication.
    More info: https://prometheus.io/docs/operating/configuration/#endpoint
    """
    [...str]: any

schema ValuesPrometheusPodMonitorBearerTokenSecret:
    r"""
    Secret to mount to read bearer token for scraping targets.
    The secret needs to be in the same namespace as the pod monitor and accessible by the Prometheus Operator.
    https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#secretkeyselector-v1-core
    """
    [...str]: any

schema ValuesPrometheusPodMonitorOauth2:
    r"""
    OAuth2 for the URL. Only valid in Prometheus versions 2.27.0 and newer.
    https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api-reference/api.md#oauth2
    """
    [...str]: any

schema ValuesPrometheusPodMonitorParams:
    r"""
    Optional HTTP URL parameters
    """
    [...str]: any

schema ValuesPrometheusPodMonitorSelectorOverride:
    r"""
    Override pod selector to select pod objects.
    """
    [...str]: any

schema ValuesPrometheusPodMonitorTlsConfig:
    r"""
    TLS configuration to use when scraping the endpoint.
    """
    [...str]: any

schema ValuesPrometheusScrapeconfig:
    r"""
    # Create a scrapeConfig resource for scraping the kube-state-metrics service. Use this instead of serviceMonitor
    # to have more instances of kube-state-metrics safety.

    Attributes
    ----------
    additionalLabels : ValuesPrometheusScrapeconfigAdditionalLabels, optional
    annotations : ValuesPrometheusScrapeconfigAnnotations, optional
    enableHttp2 : bool, optional, default is False
        # Whether to enable HTTP2 for scrapeconfig
    enabled : bool, optional, default is False
        # To avoid duplicate metrics, first disable the serviceMonitor creation via prometheus.monitor.enabled=false
    honorLabels : bool, optional, default is True
    jobName : str, optional, default is "kube-state-metrics"
    labelLimit : int, optional, default is 0
        # Per-scrape limit on number of labels that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.
        #
    labelNameLengthLimit : int, optional, default is 0
        # Per-scrape limit on length of labels name that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.
        #
    labelValueLengthLimit : int, optional, default is 0
        # Per-scrape limit on length of labels value that will be accepted for a sample. Only valid in Prometheus versions 2.27.0 and newer.
        #
    metricRelabelings : [any], optional
    proxyUrl : str, optional, default is ""
    relabelings : [any], optional
    sampleLimit : int, optional, default is 0
        # SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.
        #
    scheme : str, optional, default is ""
    scrapeInterval : str, optional, default is ""
    scrapeTimeout : str, optional, default is ""
    staticConfigLabels : ValuesPrometheusScrapeconfigStaticConfigLabels, optional
        # StaticConfigLabels defines the labels to be used in the Prometheus static configuration for scraping.
    targetLimit : int, optional, default is 0
        # TargetLimit defines a limit on the number of scraped targets that will be accepted.
        #
    tlsConfig : ValuesPrometheusScrapeconfigTlsConfig, optional
    """
    [...str]: any
    additionalLabels?: ValuesPrometheusScrapeconfigAdditionalLabels
    annotations?: ValuesPrometheusScrapeconfigAnnotations
    enableHttp2?: bool
    enabled?: bool
    honorLabels?: bool
    jobName?: str
    labelLimit?: int
    labelNameLengthLimit?: int
    labelValueLengthLimit?: int
    metricRelabelings?: [any]
    proxyUrl?: str
    relabelings?: [any]
    sampleLimit?: int
    scheme?: str
    scrapeInterval?: str
    scrapeTimeout?: str
    staticConfigLabels?: ValuesPrometheusScrapeconfigStaticConfigLabels
    targetLimit?: int
    tlsConfig?: ValuesPrometheusScrapeconfigTlsConfig

schema ValuesPrometheusScrapeconfigAdditionalLabels:
    r"""
    ValuesPrometheusScrapeconfigAdditionalLabels
    """
    [...str]: any

schema ValuesPrometheusScrapeconfigAnnotations:
    r"""
    ValuesPrometheusScrapeconfigAnnotations
    """
    [...str]: any

schema ValuesPrometheusScrapeconfigStaticConfigLabels:
    r"""
    # StaticConfigLabels defines the labels to be used in the Prometheus static configuration for scraping.
    """
    [...str]: any

schema ValuesPrometheusScrapeconfigTlsConfig:
    r"""
    ValuesPrometheusScrapeconfigTlsConfig
    """
    [...str]: any

schema ValuesProxyConnectHeader:
    r"""
    Specifies headers to send to proxies during CONNECT requests.
    """
    [...str]: any

schema ValuesQueueConfig:
    r"""
    ValuesQueueConfig

    Attributes
    ----------
    batchSendDeadline : str, optional
        Maximum time samples will wait in the buffer before sending.
    capacity : int, optional
        Number of samples to buffer per shard.
    maxBackoff : str, optional
        Maximum retry delay.
    maxSamplesPerSend : int, optional
        Maximum number of samples per send.
    maxShards : int, optional
        Maximum amount of concurrent shards sending samples to the endpoint.
    minBackoff : str, optional
        Initial retry delay. The backoff time gets doubled for each retry.
    minShards : int, optional
        Minimum amount of concurrent shards sending samples to the endpoint.
    retryOnHttp429 : bool, optional
        Retry when an HTTP 429 status code is received.
    sampleAgeLimit : str, optional
        Maximum age of samples to send.
    """
    [...str]: any
    batchSendDeadline?: str
    capacity?: int
    maxBackoff?: str
    maxSamplesPerSend?: int
    maxShards?: int
    minBackoff?: str
    minShards?: int
    retryOnHttp429?: bool
    sampleAgeLimit?: str

schema ValuesRbac:
    r"""
    Create cluster role policies

    Attributes
    ----------
    create : bool, optional, default is True
        Whether to create RBAC resources for Alloy.
    createClusterRoles : bool, optional, default is True
        Create ClusterRoles for the Alloy Operator. If set to false, only Roles and RoleBindings will be created. This
        setting requires the use of `namespaces` or `ownNamespaceOnly` to be set.
    enabled : bool, optional, default is True
    extraClusterRoleRules : [any], optional
        Extra custer roles to be created for Belya
    extraRules : [any], optional
        Add permissions for CustomResources' apiGroups in Role/ClusterRole. Should be used in conjunction with Custom Resource State Metrics configuration
        Example:
        - apiGroups: ["monitoring.coreos.com"]
          resources: ["prometheuses"]
          verbs: ["list", "watch"]
    useClusterRole : bool, optional, default is True
        If set to false - Run without Cluteradmin privs needed - ONLY works if namespace is also set (if useExistingRole is set this name is used as ClusterRole or Role to bind to)
    """
    [...str]: any
    create?: bool
    createClusterRoles?: bool
    enabled?: bool
    extraClusterRoleRules?: [any]
    extraRules?: [any]
    useClusterRole?: bool

schema ValuesReadinessProbe:
    r"""
    # Readiness probe
    #

    Attributes
    ----------
    failureThreshold : int, optional, default is 3
    httpGet : ValuesReadinessProbeHttpGet, optional
    initialDelaySeconds : int, optional, default is 0
    periodSeconds : int, optional, default is 10
    successThreshold : int, optional, default is 1
    timeoutSeconds : int, optional, default is 1
    """
    [...str]: any
    failureThreshold?: int
    httpGet?: ValuesReadinessProbeHttpGet
    initialDelaySeconds?: int
    periodSeconds?: int
    successThreshold?: int
    timeoutSeconds?: int

schema ValuesReadinessProbeHttpGet:
    r"""
    ValuesReadinessProbeHttpGet

    Attributes
    ----------
    httpHeaders : [any], optional
    path : str, optional, default is "/health"
    scheme : str, optional, default is "http"
    """
    [...str]: any
    httpHeaders?: [any]
    path?: str
    scheme?: str

schema ValuesReceivers:
    r"""
    ValuesReceivers

    Attributes
    ----------
    jaeger : ValuesReceiversJaeger, optional
    otlp : ValuesReceiversOtlp, optional
    zipkin : ValuesReceiversZipkin, optional
        The Zipkin receiver configuration.
    """
    [...str]: any
    jaeger?: ValuesReceiversJaeger
    otlp?: ValuesReceiversOtlp
    zipkin?: ValuesReceiversZipkin

schema ValuesReceiversJaeger:
    r"""
    ValuesReceiversJaeger

    Attributes
    ----------
    grpc : ValuesReceiversJaegerGrpc, optional
        Configuration for the Jaeger receiver using the gRPC protocol.
    includeDebugMetrics : bool, optional, default is False
        Whether to include high-cardinality debug metrics.
    thriftBinary : ValuesReceiversJaegerThriftBinary, optional
        Configuration for the Jaeger receiver using the Thrift binary protocol.
    thriftCompact : ValuesReceiversJaegerThriftCompact, optional
        Configuration for the Jaeger receiver using the Thrift compact protocol.
    thriftHttp : ValuesReceiversJaegerThriftHttp, optional
        Configuration for the Jaeger receiver using the Thrift HTTP protocol.
    """
    [...str]: any
    grpc?: ValuesReceiversJaegerGrpc
    includeDebugMetrics?: bool
    thriftBinary?: ValuesReceiversJaegerThriftBinary
    thriftCompact?: ValuesReceiversJaegerThriftCompact
    thriftHttp?: ValuesReceiversJaegerThriftHttp

schema ValuesReceiversJaegerGrpc:
    r"""
    Configuration for the Jaeger receiver using the gRPC protocol.

    Attributes
    ----------
    enabled : bool, optional, default is False
    port : int, optional, default is 14250
    """
    [...str]: any
    enabled?: bool
    port?: int

schema ValuesReceiversJaegerThriftBinary:
    r"""
    Configuration for the Jaeger receiver using the Thrift binary protocol.

    Attributes
    ----------
    enabled : bool, optional, default is False
    port : int, optional, default is 6832
    """
    [...str]: any
    enabled?: bool
    port?: int

schema ValuesReceiversJaegerThriftCompact:
    r"""
    Configuration for the Jaeger receiver using the Thrift compact protocol.

    Attributes
    ----------
    enabled : bool, optional, default is False
    port : int, optional, default is 6831
    """
    [...str]: any
    enabled?: bool
    port?: int

schema ValuesReceiversJaegerThriftHttp:
    r"""
    Configuration for the Jaeger receiver using the Thrift HTTP protocol.

    Attributes
    ----------
    enabled : bool, optional, default is False
    port : int, optional, default is 14268
    """
    [...str]: any
    enabled?: bool
    port?: int

schema ValuesReceiversOtlp:
    r"""
    ValuesReceiversOtlp

    Attributes
    ----------
    grpc : ValuesReceiversOtlpGrpc, optional
        The OTLP gRPC receiver configuration.
    http : ValuesReceiversOtlpHttp, optional
        The OTLP HTTP receiver configuration.
    includeDebugMetrics : bool, optional, default is False
        Whether to include high-cardinality debug metrics.
    """
    [...str]: any
    grpc?: ValuesReceiversOtlpGrpc
    http?: ValuesReceiversOtlpHttp
    includeDebugMetrics?: bool

schema ValuesReceiversOtlpGrpc:
    r"""
    The OTLP gRPC receiver configuration.

    Attributes
    ----------
    enabled : bool, optional, default is False
        Accept application data over OTLP gRPC.
    includeMetadata : bool, optional, default is False
        Propagate incoming connection metadata to downstream consumers.
    keepalive : ValuesReceiversOtlpGrpcKeepalive, optional
    maxConcurrentStreams : int, optional, default is 0
        Limit the number of concurrent streaming gRPC calls. 0 means no limit.
    maxReceivedMessageSize : str, optional, default is "4MiB"
        Maximum size of messages the gRPC server will accept.
    port : int, optional, default is 4317
        The port to listen on for OTLP gRPC requests.
    readBufferSize : str, optional, default is "512KiB"
        Size of the read buffer the gRPC server will use for reading from clients.
    writeBufferSize : str, optional, default is "32KiB"
        Size of the write buffer the gRPC server will use for writing to clients.
    """
    [...str]: any
    enabled?: bool
    includeMetadata?: bool
    keepalive?: ValuesReceiversOtlpGrpcKeepalive
    maxConcurrentStreams?: int
    maxReceivedMessageSize?: str
    port?: int
    readBufferSize?: str
    writeBufferSize?: str

schema ValuesReceiversOtlpGrpcKeepalive:
    r"""
    ValuesReceiversOtlpGrpcKeepalive

    Attributes
    ----------
    enforcementPolicy : ValuesReceiversOtlpGrpcKeepaliveEnforcementPolicy, optional
    serverParameters : ValuesReceiversOtlpGrpcKeepaliveServerParameters, optional
    """
    [...str]: any
    enforcementPolicy?: ValuesReceiversOtlpGrpcKeepaliveEnforcementPolicy
    serverParameters?: ValuesReceiversOtlpGrpcKeepaliveServerParameters

schema ValuesReceiversOtlpGrpcKeepaliveEnforcementPolicy:
    r"""
    ValuesReceiversOtlpGrpcKeepaliveEnforcementPolicy

    Attributes
    ----------
    minTime : str, optional, default is ""
        Minimum time clients should wait before sending a keepalive ping. Default is 5 minutes.
    permitWithoutStream : bool, optional, default is False
        Allow clients to send keepalive pings when there are no active streams.
    """
    [...str]: any
    minTime?: str
    permitWithoutStream?: bool

schema ValuesReceiversOtlpGrpcKeepaliveServerParameters:
    r"""
    ValuesReceiversOtlpGrpcKeepaliveServerParameters

    Attributes
    ----------
    maxConnectionAge : str, optional, default is ""
        Maximum age for non-idle connections. Default is infinity.
    maxConnectionAgeGrace : str, optional, default is ""
        Time to wait before forcibly closing connections. Default is infinity.
    maxConnectionIdle : str, optional, default is ""
        Maximum age for idle connections. Default is infinity.
    time : str, optional, default is ""
        How often to ping inactive clients to check for liveness. Default is 2 hours.
    timeout : str, optional, default is ""
        Time to wait before closing inactive clients that don’t respond to liveness checks.
        Default is 20 seconds.
    """
    [...str]: any
    maxConnectionAge?: str
    maxConnectionAgeGrace?: str
    maxConnectionIdle?: str
    time?: str
    timeout?: str

schema ValuesReceiversOtlpHttp:
    r"""
    The OTLP HTTP receiver configuration.

    Attributes
    ----------
    enabled : bool, optional, default is False
        Accept application data over OTLP HTTP.
    includeMetadata : bool, optional, default is False
        Propagate incoming connection metadata to downstream consumers.
    maxRequestBodySize : str, optional, default is "20MiB"
        Maximum request body size the server will allow.
    port : int, optional, default is 4318
        The port to listen on for OTLP HTTP requests.
    """
    [...str]: any
    enabled?: bool
    includeMetadata?: bool
    maxRequestBodySize?: str
    port?: int

schema ValuesReceiversZipkin:
    r"""
    The Zipkin receiver configuration.

    Attributes
    ----------
    enabled : bool, optional, default is False
    includeDebugMetrics : bool, optional, default is False
        Whether to include high-cardinality debug metrics.
    port : int, optional, default is 9411
    """
    [...str]: any
    enabled?: bool
    includeDebugMetrics?: bool
    port?: int

schema ValuesRedfish:
    r"""
    ValuesRedfish

    Attributes
    ----------
    annotations : ValuesRedfishAnnotations, optional
    enabled : bool, optional, default is False
    fileContent : str, optional, default is "your_kubelet_node1_name,redfish_username,redfish_password,https://node1_redfish_ip_or_hostname\nyour_kubelet_node2_name,redfish_username,redfish_password,https://node2_redfish_ip_or_hostname"
    labels : ValuesRedfishLabels, optional
    name : str, optional, default is "redfish"
    """
    [...str]: any
    annotations?: ValuesRedfishAnnotations
    enabled?: bool
    fileContent?: str
    labels?: ValuesRedfishLabels
    name?: str

schema ValuesRedfishAnnotations:
    r"""
    ValuesRedfishAnnotations
    """
    [...str]: any

schema ValuesRedfishLabels:
    r"""
    ValuesRedfishLabels
    """
    [...str]: any

schema ValuesRemoteConfig:
    r"""
    Remote configuration from a remote config server.

    Attributes
    ----------
    auth : ValuesRemoteConfigAuth, optional
    enabled : bool, optional
        Enable fetching configuration from a remote config server.
    extraAttributes : ValuesRemoteConfigExtraAttributes, optional
        Attributes to be added to this collector when requesting configuration.
    noProxy : str, optional
        Comma-separated list of IP addresses, CIDR notations, and domain names to exclude from proxying.
    pollFrequency : str, optional
        The frequency at which to poll the remote config server for updates.
    proxyConnectHeader : ValuesRemoteConfigProxyConnectHeader, optional
        Specifies headers to send to proxies during CONNECT requests.
    proxyFromEnvironment : bool, optional
        Use the proxy URL indicated by environment variables.
    proxyURL : str, optional
        The proxy URL to use of the remote config server.
    secret : ValuesRemoteConfigSecret, optional
    tls : ValuesRemoteConfigTls, optional
    url : str, optional
        The URL of the remote config server.
    urlFrom : str, optional
        Raw config for accessing the URL. Lets you insert raw Alloy references so you can load the URL from any number of
        places, such as loading values from environment variables or config maps. For example: `urlFrom: sys.env("ALLOY_REMOTE_CONFIG_URL")`
    """
    [...str]: any
    auth?: ValuesRemoteConfigAuth
    enabled?: bool
    extraAttributes?: ValuesRemoteConfigExtraAttributes
    noProxy?: str
    pollFrequency?: str
    proxyConnectHeader?: ValuesRemoteConfigProxyConnectHeader
    proxyFromEnvironment?: bool
    proxyURL?: str
    secret?: ValuesRemoteConfigSecret
    tls?: ValuesRemoteConfigTls
    url?: str
    urlFrom?: str

schema ValuesRemoteConfigAuth:
    r"""
    ValuesRemoteConfigAuth

    Attributes
    ----------
    password : str, optional
        The password to use for the remote config server.
    passwordFrom : str, optional
        Raw config for accessing the password.
    passwordKey : str, optional
        The key for storing the password in the secret.
    $type : str, optional
        The type of authentication to use for the remote config server.
    username : str, optional
        The username to use for the remote config server.
    usernameFrom : str, optional
        Raw config for accessing the password.
    usernameKey : str, optional
        The key for storing the username in the secret.
    """
    [...str]: any
    password?: str
    passwordFrom?: str
    passwordKey?: str
    $type?: str
    username?: str
    usernameFrom?: str
    usernameKey?: str

schema ValuesRemoteConfigExtraAttributes:
    r"""
    Attributes to be added to this collector when requesting configuration.
    """
    [...str]: any

schema ValuesRemoteConfigProxyConnectHeader:
    r"""
    Specifies headers to send to proxies during CONNECT requests.
    """
    [...str]: any

schema ValuesRemoteConfigSecret:
    r"""
    ValuesRemoteConfigSecret

    Attributes
    ----------
    create : bool, optional
        Whether to create a secret for the remote config server.
    embed : bool, optional
        If true, skip secret creation and embed the credentials directly into the configuration.
    name : str, optional
        The name of the secret to create.
    namespace : str, optional
        The namespace for the secret.
    """
    [...str]: any
    create?: bool
    embed?: bool
    name?: str
    namespace?: str

schema ValuesRemoteConfigTls:
    r"""
    ValuesRemoteConfigTls

    Attributes
    ----------
    ca : str, optional
        The CA certificate for the server (as a string).
    caFile : str, optional
        The CA certificate for the server (as a path to a file).
    caFrom : str, optional
        Raw config for accessing the server CA certificate.
    cert : str, optional
        The client certificate for the server (as a string).
    certFile : str, optional
        The client certificate for the server (as a path to a file).
    certFrom : str, optional
        Raw config for accessing the client certificate.
    insecureSkipVerify : bool, optional
        Disables validation of the server certificate.
    key : str, optional
        The client key for the server (as a string).
    keyFile : str, optional
        The client key for the server (as a path to a file).
    keyFrom : str, optional
        Raw config for accessing the client key.
    """
    [...str]: any
    ca?: str
    caFile?: str
    caFrom?: str
    cert?: str
    certFile?: str
    certFrom?: str
    insecureSkipVerify?: bool
    key?: str
    keyFile?: str
    keyFrom?: str

schema ValuesResources:
    r"""
    CPU/MEM resources

    Attributes
    ----------
    limits : ValuesResourcesLimits, optional
        Set the resource limits for the Alloy Operator pods.
    requests : ValuesResourcesRequests, optional
        Set the resource requests for the Alloy Operator pods.
    """
    [...str]: any
    limits?: ValuesResourcesLimits
    requests?: ValuesResourcesRequests

schema ValuesResourcesLimits:
    r"""
    Set the resource limits for the Alloy Operator pods.
    """
    [...str]: any

schema ValuesResourcesRequests:
    r"""
    Set the resource requests for the Alloy Operator pods.
    """
    [...str]: any

schema ValuesRetryOnFailure:
    r"""
    ValuesRetryOnFailure

    Attributes
    ----------
    enabled : bool, optional
        Should failed requests be retried?
    initialInterval : str, optional
        The initial time to wait before retrying a failed request to the OTLP destination.
    maxElapsedTime : str, optional
        The maximum amount of time to wait before discarding a failed batch.
    maxInterval : str, optional
        The maximum time to wait before retrying a failed request to the OTLP destination.
    """
    [...str]: any
    enabled?: bool
    initialInterval?: str
    maxElapsedTime?: str
    maxInterval?: str

schema ValuesSecret:
    r"""
    ValuesSecret

    Attributes
    ----------
    create : bool, optional
        Whether to create a secret for this Pyroscope destination.
    embed : bool, optional
        If true, skip secret creation and embed the credentials directly into the configuration.
    name : str, optional
        The name of the secret to create.
    namespace : str, optional
        The namespace for the secret.
    sigv4 : ValuesSecretSigv4, optional
        Authentication using AWS Signature Version 4
    """
    [...str]: any
    create?: bool
    embed?: bool
    name?: str
    namespace?: str
    sigv4?: ValuesSecretSigv4

schema ValuesSecretAnnotations:
    r"""
     Annotations to add to the Secret
    """
    [...str]: any

schema ValuesSecretFilter:
    r"""
    Check logs for secrets and mask them.

    Attributes
    ----------
    allowlist : [any], optional
        List of regular expressions to allowlist matching secrets.
    enabled : bool, optional, default is False
        Enable secret filtering.
    includeGeneric : bool, optional, default is False
        Include the generic API key rule.
    partialMask : int, optional, default is 0
        Show the first N characters of the secret.
    """
    [...str]: any
    allowlist?: [any]
    enabled?: bool
    includeGeneric?: bool
    partialMask?: int

schema ValuesSecretSigv4:
    r"""
    Authentication using AWS Signature Version 4

    Attributes
    ----------
    assumeRole : ValuesSecretSigv4AssumeRole, optional
    region : str, optional
        The AWS region for sigv4 authentication.
    service : str, optional
        The AWS service for sigv4 authentication.
    """
    [...str]: any
    assumeRole?: ValuesSecretSigv4AssumeRole
    region?: str
    service?: str

schema ValuesSecretSigv4AssumeRole:
    r"""
    ValuesSecretSigv4AssumeRole

    Attributes
    ----------
    arn : str, optional
        The Amazon Resource Name (ARN) of a role to assume.
    sessionName : str, optional
        The name of a role session.
    stsRegion : str, optional
        The AWS region where STS is used to assume the configured role.
    """
    [...str]: any
    arn?: str
    sessionName?: str
    stsRegion?: str

schema ValuesSecurityContext:
    r"""
    Privileges and access control settings for a container

    Attributes
    ----------
    allowPrivilegeEscalation : bool, optional, default is False
    capabilities : ValuesSecurityContextCapabilities, optional
    enabled : bool, optional, default is True
    fsGroup : int, optional, default is 65534
    privileged : bool, optional, default is True
    readOnlyRootFilesystem : bool, optional, default is True
    runAsGroup : int, optional, default is 65534
    runAsNonRoot : bool, optional, default is True
    runAsUser : int, optional, default is 65534
    seccompProfile : ValuesSecurityContextSeccompProfile, optional
    windowsOptions : ValuesSecurityContextWindowsOptions, optional
    """
    [...str]: any
    allowPrivilegeEscalation?: bool
    capabilities?: ValuesSecurityContextCapabilities
    enabled?: bool
    fsGroup?: int
    privileged?: bool
    readOnlyRootFilesystem?: bool
    runAsGroup?: int
    runAsNonRoot?: bool
    runAsUser?: int
    seccompProfile?: ValuesSecurityContextSeccompProfile
    windowsOptions?: ValuesSecurityContextWindowsOptions

schema ValuesSecurityContextCapabilities:
    r"""
    ValuesSecurityContextCapabilities

    Attributes
    ----------
    drop : [str], optional
    """
    [...str]: any
    drop?: [str]

schema ValuesSecurityContextSeccompProfile:
    r"""
    ValuesSecurityContextSeccompProfile

    Attributes
    ----------
    $type : str, optional, default is "RuntimeDefault"
    """
    [...str]: any
    $type?: str

schema ValuesSecurityContextWindowsOptions:
    r"""
    ValuesSecurityContextWindowsOptions

    Attributes
    ----------
    hostProcess : bool, optional, default is True
    runAsUserName : str, optional, default is "NT AUTHORITY\\system"
    """
    [...str]: any
    hostProcess?: bool
    runAsUserName?: str

schema ValuesSelectorOverride:
    r"""
    # Override selector labels
    """
    [...str]: any

schema ValuesSelfMonitor:
    r"""
    Enable self metrics configuration for service and Service Monitor
    Default values for telemetry configuration can be overridden
    If you set telemetryNodePort, you must also set service.type to NodePort

    Attributes
    ----------
    enabled : bool, optional, default is False
    """
    [...str]: any
    enabled?: bool

schema ValuesSelfReporting:
    r"""
    Self-reporting creates a single metric and log that reports anonymized information about how this Helm chart was
    configured. It reports features enabled, destinations types used, and alloy instances enabled. It does not report any
    actual telemetry data, credentials or configuration, or send any data to any destination other than the ones
    configured above.

    Attributes
    ----------
    destinations : [any], optional
        The destinations where self-report metrics will be sent. If empty, all metrics-capable destinations will be used.
    enabled : bool, optional, default is True
        Enable Self-reporting.
    scrapeInterval : str, optional, default is ""
        How frequently to generate self-report metrics. This does utilize the global scrapeInterval setting.
    """
    [...str]: any
    destinations?: [any]
    enabled?: bool
    scrapeInterval?: str

schema ValuesService:
    r"""
    # Service configuration

    Attributes
    ----------
    annotations : ValuesServiceAnnotations, optional
        # Additional annotations and labels for the service.
    appProtocol : str, optional, default is ""
        Adds the appProtocol field to the service. This allows to work with istio protocol selection. Ex: "http" or "tcp"
    clusterIP : str, optional, default is ""
        Cluster IP, can be set to None, empty "" or an IP address
    enabled : bool, optional, default is True
        Creates a Service for the controller's pods.
    externalTrafficPolicy : str, optional, default is ""
        # External/Internal traffic policy setting (Cluster, Local)
        # https://kubernetes.io/docs/reference/networking/virtual-ips/#traffic-policies
    extraPorts : [any], optional
        extra ports.  Useful for sidecar pods such as oauth-proxy
    health : ValuesServiceHealth, optional
    internalMetrics : ValuesServiceInternalMetrics, optional
    internalTrafficPolicy : str, optional, default is ""
        Value for internal traffic policy. 'Cluster' or 'Local'
    ipDualStack : ValuesServiceIpDualStack, optional
        # Dual stack settings for the service
        # https://kubernetes.io/docs/concepts/services-networking/dual-stack/#services
    labels : ValuesServiceLabels, optional
         Labels to add to the service account
    listenOnAllInterfaces : bool, optional, default is True
        # If true, node exporter will listen on all interfaces
    loadBalancerClass : str, optional, default is ""
        loadbalancer class name
    loadBalancerIP : str, optional, default is ""
        loadbalancer IP
    loadBalancerSourceRanges : [any], optional
        - name: oauth-proxy
          port: 8081
          targetPort: 8081
        - name: oauth-metrics
          port: 8082
          targetPort: 8082
        LoadBalancer Source IP CIDR if service type is LoadBalancer and cloud provider supports this
    metrics : ValuesServiceMetrics, optional
    nodePort : int, optional, default is ""
        NodePort port. Only takes effect when `service.type: NodePort`
    port : int, optional, default is 9182
        # Default service port. Sets the port of the exposed container as well (windows-exporter).
    portName : str, optional, default is "metrics"
        # Name of the service port. Sets the port name of the main container (windows-exporter) as well.
    servicePort : str, optional, default is ""
        # Service port. Use this field if you wish to set a different service port
        # without changing the container port ("port" above).
    targetPort : int, optional, default is 9100
        # Targeted port in the pod. Must refer to an open container port ("port" or "portName").
        # (IntOrString)
    $type : str, optional, default is "ClusterIP"
        Service type
    """
    [...str]: any
    annotations?: ValuesServiceAnnotations
    appProtocol?: str
    clusterIP?: str
    enabled?: bool
    externalTrafficPolicy?: str
    extraPorts?: [any]
    health?: ValuesServiceHealth
    internalMetrics?: ValuesServiceInternalMetrics
    internalTrafficPolicy?: str
    ipDualStack?: ValuesServiceIpDualStack
    labels?: ValuesServiceLabels
    listenOnAllInterfaces?: bool
    loadBalancerClass?: str
    loadBalancerIP?: str
    loadBalancerSourceRanges?: [any]
    metrics?: ValuesServiceMetrics
    nodePort?: int
    port?: int
    portName?: str
    servicePort?: str
    targetPort?: int
    $type?: str

schema ValuesServiceAccount:
    r"""
    Service Account settings

    Attributes
    ----------
    additionalLabels : ValuesServiceAccountAdditionalLabels, optional
        Additional labels to add to the created service account.
    annotations : ValuesServiceAccountAnnotations, optional
        Annotations to add to the created service account.
    automount : bool, optional, default is True
        Automatically mount a ServiceAccount's API credentials?
    automountServiceAccountToken : bool, optional, default is False
        Whether the Alloy pod should automatically mount the service account token.
    create : bool, optional, default is True
        Whether to create a service account for the Grafana Alloy deployment.
    imagePullSecrets : [any], optional
        Reference to one or more secrets to be used when pulling images
        ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    labels : ValuesServiceAccountLabels, optional
        ServiceAccount labels.
    name : any, optional, default is ""
        The name of the existing service account to use when
        serviceAccount.create is false.
    """
    [...str]: any
    additionalLabels?: ValuesServiceAccountAdditionalLabels
    annotations?: ValuesServiceAccountAnnotations
    automount?: bool
    automountServiceAccountToken?: bool
    create?: bool
    imagePullSecrets?: [any]
    labels?: ValuesServiceAccountLabels
    name?: any

schema ValuesServiceAccountAdditionalLabels:
    r"""
    Additional labels to add to the created service account.
    """
    [...str]: any

schema ValuesServiceAccountAnnotations:
    r"""
    Annotations to add to the created service account.
    """
    [...str]: any

schema ValuesServiceAccountLabels:
    r"""
    ServiceAccount labels.
    """
    [...str]: any

schema ValuesServiceAnnotations:
    r"""
    # Additional annotations and labels for the service.

    Attributes
    ----------
    "prometheus.io/scrape" : str, optional, default is "true"
    """
    [...str]: any
    "prometheus.io/scrape"?: str

schema ValuesServiceHealth:
    r"""
    ValuesServiceHealth

    Attributes
    ----------
    port : int, optional, default is 8081
        The port number for the health probes.
    """
    [...str]: any
    port?: int

schema ValuesServiceInternalMetrics:
    r"""
    ValuesServiceInternalMetrics

    Attributes
    ----------
    appProtocol : str, optional, default is ""
        Adds the appProtocol field to the service. This allows to work with istio protocol selection. Ex: "http" or "tcp"
    port : int, optional, default is 8080
        internal metrics service port
    portName : str, optional, default is "int-metrics"
        name of the port for internal metrics.
    targetPort : any, optional, default is "null"
        targetPort overrides the internal metrics port. It defaults to the value of `internal_metrics.prometheus.port`
        from the Beyla configuration file.
    """
    [...str]: any
    appProtocol?: str
    port?: int
    portName?: str
    targetPort?: any

schema ValuesServiceIpDualStack:
    r"""
    # Dual stack settings for the service
    # https://kubernetes.io/docs/concepts/services-networking/dual-stack/#services

    Attributes
    ----------
    enabled : bool, optional, default is False
    ipFamilies : [str], optional
    ipFamilyPolicy : str, optional, default is "PreferDualStack"
    """
    [...str]: any
    enabled?: bool
    ipFamilies?: [str]
    ipFamilyPolicy?: str

schema ValuesServiceLabels:
    r"""
     Labels to add to the service account
    """
    [...str]: any

schema ValuesServiceMetrics:
    r"""
    ValuesServiceMetrics

    Attributes
    ----------
    port : int, optional, default is 8082
        The port number for the metrics service.
    """
    [...str]: any
    port?: int

schema ValuesServiceMonitor:
    r"""
    Enable creation of ServiceMonitor for scraping of prometheus HTTP endpoint

    Attributes
    ----------
    additionalLabels : ValuesServiceMonitorAdditionalLabels, optional
        Additional labels for the service monitor.
    annotations : ValuesServiceMonitorAnnotations, optional
        ServiceMonitor annotations
    attachMetadata : ValuesServiceMonitorAttachMetadata, optional
    enabled : bool, optional, default is False
        Whether to create a ServiceMonitor
    internalMetrics : ValuesServiceMonitorInternalMetrics, optional
    interval : str, optional, default is "30s"
        Scrape interval. If not set, the Prometheus default scrape interval is used.
    jobLabel : str, optional, default is ""
        Prometheus job label.
        If empty, chart release name is used
    labels : ValuesServiceMonitorLabels, optional
    metricRelabelings : [any], optional
        MetricRelabelConfigs to apply to samples after scraping, but before ingestion.
        ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig
    metrics : ValuesServiceMonitorMetrics, optional
    namespace : str, optional, default is ""
    relabelings : [ValuesServiceMonitorRelabelingsItems0], optional
        RelabelConfigs to apply to samples before scraping
        ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig
    scrapeTimeout : str, optional, default is "5s"
        Set timeout for scrape
    targetLabels : [any], optional
        Set of labels to transfer from the Kubernetes Service onto the target
    telemetryPath : str, optional, default is "/metrics"
        Set path to metrics path
    tlsConfig : ValuesServiceMonitorTlsConfig, optional
        Customize tls parameters for the service monitor
    """
    [...str]: any
    additionalLabels?: ValuesServiceMonitorAdditionalLabels
    annotations?: ValuesServiceMonitorAnnotations
    attachMetadata?: ValuesServiceMonitorAttachMetadata
    enabled?: bool
    internalMetrics?: ValuesServiceMonitorInternalMetrics
    interval?: str
    jobLabel?: str
    labels?: ValuesServiceMonitorLabels
    metricRelabelings?: [any]
    metrics?: ValuesServiceMonitorMetrics
    namespace?: str
    relabelings?: [ValuesServiceMonitorRelabelingsItems0]
    scrapeTimeout?: str
    targetLabels?: [any]
    telemetryPath?: str
    tlsConfig?: ValuesServiceMonitorTlsConfig

schema ValuesServiceMonitorAdditionalLabels:
    r"""
    Additional labels for the service monitor.
    """
    [...str]: any

schema ValuesServiceMonitorAnnotations:
    r"""
    ServiceMonitor annotations
    """
    [...str]: any

schema ValuesServiceMonitorAttachMetadata:
    r"""
    ValuesServiceMonitorAttachMetadata

    Attributes
    ----------
    node : bool, optional, default is False
    """
    [...str]: any
    node?: bool

schema ValuesServiceMonitorInternalMetrics:
    r"""
    ValuesServiceMonitorInternalMetrics

    Attributes
    ----------
    endpoint : ValuesServiceMonitorInternalMetricsEndpoint, optional
        ServiceMonitor internal metrics scraping endpoint.
        Target port and path is set based on service and `internal_metrics` values.
        For additional values, see the ServiceMonitor spec
    """
    [...str]: any
    endpoint?: ValuesServiceMonitorInternalMetricsEndpoint

schema ValuesServiceMonitorInternalMetricsEndpoint:
    r"""
    ServiceMonitor internal metrics scraping endpoint.
    Target port and path is set based on service and `internal_metrics` values.
    For additional values, see the ServiceMonitor spec

    Attributes
    ----------
    interval : str, optional, default is "15s"
    """
    [...str]: any
    interval?: str

schema ValuesServiceMonitorLabels:
    r"""
    ValuesServiceMonitorLabels
    """
    [...str]: any

schema ValuesServiceMonitorMetrics:
    r"""
    ValuesServiceMonitorMetrics

    Attributes
    ----------
    endpoint : ValuesServiceMonitorMetricsEndpoint, optional
        ServiceMonitor Prometheus scraping endpoint.
        Target port and path is set based on service and `prometheus_export` values.
        For additional values, see the ServiceMonitor spec
    """
    [...str]: any
    endpoint?: ValuesServiceMonitorMetricsEndpoint

schema ValuesServiceMonitorMetricsEndpoint:
    r"""
    ServiceMonitor Prometheus scraping endpoint.
    Target port and path is set based on service and `prometheus_export` values.
    For additional values, see the ServiceMonitor spec

    Attributes
    ----------
    interval : str, optional, default is "15s"
    """
    [...str]: any
    interval?: str

schema ValuesServiceMonitorRelabelingsItems0:
    r"""
    ValuesServiceMonitorRelabelingsItems0

    Attributes
    ----------
    action : str, optional, default is "replace"
    regex : str, optional, default is "(.*)"
    replacement : str, optional, default is "$1"
    sourceLabels : [str], optional
    targetLabel : str, optional, default is "instance"
    """
    [...str]: any
    action?: str
    regex?: str
    replacement?: str
    sourceLabels?: [str]
    targetLabel?: str

schema ValuesServiceMonitorTlsConfig:
    r"""
    Customize tls parameters for the service monitor
    """
    [...str]: any

schema ValuesServiceMonitors:
    r"""
    Prometheus Operator ServiceMonitors

    Attributes
    ----------
    enabled : bool, optional, default is True
        Enable discovery of Prometheus Operator ServiceMonitor objects.
    excludeNamespaces : [any], optional
        Which namespaces to not look for ServiceMonitor objects.
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.operator.probes component for Probes.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        The relabelings defined in the PodMonitor object are applied first, then these relabelings are applied.
        Before the scrape, any remaining target labels that start with `__` (i.e. `__meta_kubernetes*`) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for ServiceMonitor objects.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    labelExpressions : [any], optional
        Complex label selectors to filter which ServiceMonitor objects to use.
        Example: `[{key: "app.kubernetes.io/name", operator: "NotIn", values: ["secret-app", "admin-app"]}]`
    labelSelectors : ValuesServiceMonitorsLabelSelectors, optional
        Label selectors to filter which ServiceMonitor objects to use.
        Example: `app.kubernetes.io/name: my-app`
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for cadvisor prometheus.relabel component.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides global.maxCacheSize
    metricsTuning : ValuesServiceMonitorsMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    namespaces : [any], optional
        Which namespaces to look for ServiceMonitor objects.
    scrapeInterval : str, optional, default is ""
        The default interval between scraping targets. Used as the default if the target resource doesn’t provide a
        scrape interval.
        Overrides global.scrapeInterval
    scrapeTimeout : str, optional, default is ""
        The default timeout for scrape requests. Used as the default if the target resource doesn’t provide a scrape
        timeout.
    """
    [...str]: any
    enabled?: bool
    excludeNamespaces?: [any]
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    labelExpressions?: [any]
    labelSelectors?: ValuesServiceMonitorsLabelSelectors
    maxCacheSize?: any
    metricsTuning?: ValuesServiceMonitorsMetricsTuning
    namespaces?: [any]
    scrapeInterval?: str
    scrapeTimeout?: str

schema ValuesServiceMonitorsLabelSelectors:
    r"""
    Label selectors to filter which ServiceMonitor objects to use.
    Example: `app.kubernetes.io/name: my-app`
    """
    [...str]: any

schema ValuesServiceMonitorsMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]

schema ValuesServices:
    r"""
    ValuesServices

    Attributes
    ----------
    enabled : bool, optional, default is True
        Enable discovering Services with annotations.
    labelSelectors : ValuesServicesLabelSelectors, optional
        Filter the list of discovered Services by labels.
        Example: `labelSelectors: { 'app': 'myapp' }` will only discover Services with the label `app=myapp`.
        Example: `labelSelectors: { 'app': ['myapp', 'myotherapp'] }` will only discover Services with the label `app=myapp` or `app=myotherapp`.
    labels : ValuesServicesLabels, optional
        Add labels to metrics from discovered Services. Run during discovery, so __meta_ labels are available. See the
        [documentation](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.kubernetes/#service-role)
        for the full list of meta labels.
    staticLabels : ValuesServicesStaticLabels, optional
        Metric labels to set with static data for discovered Services.
    staticLabelsFrom : ValuesServicesStaticLabelsFrom, optional
        Static labels to set on metrics from discovered Services, not quoted so it can reference config components.
    """
    [...str]: any
    enabled?: bool
    labelSelectors?: ValuesServicesLabelSelectors
    labels?: ValuesServicesLabels
    staticLabels?: ValuesServicesStaticLabels
    staticLabelsFrom?: ValuesServicesStaticLabelsFrom

schema ValuesServicesLabelSelectors:
    r"""
    Filter the list of discovered Services by labels.
    Example: `labelSelectors: { 'app': 'myapp' }` will only discover Services with the label `app=myapp`.
    Example: `labelSelectors: { 'app': ['myapp', 'myotherapp'] }` will only discover Services with the label `app=myapp` or `app=myotherapp`.
    """
    [...str]: any

schema ValuesServicesLabels:
    r"""
    Add labels to metrics from discovered Services. Run during discovery, so __meta_ labels are available. See the
    [documentation](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.kubernetes/#service-role)
    for the full list of meta labels.
    """
    [...str]: any

schema ValuesServicesStaticLabels:
    r"""
    Metric labels to set with static data for discovered Services.
    """
    [...str]: any

schema ValuesServicesStaticLabelsFrom:
    r"""
    Static labels to set on metrics from discovered Services, not quoted so it can reference config components.
    """
    [...str]: any

schema ValuesStartupProbe:
    r"""
    # Startup probe can optionally be enabled.
    #

    Attributes
    ----------
    enabled : bool, optional, default is False
    failureThreshold : int, optional, default is 3
    httpGet : ValuesStartupProbeHttpGet, optional
    initialDelaySeconds : int, optional, default is 0
    periodSeconds : int, optional, default is 10
    successThreshold : int, optional, default is 1
    timeoutSeconds : int, optional, default is 5
    """
    [...str]: any
    enabled?: bool
    failureThreshold?: int
    httpGet?: ValuesStartupProbeHttpGet
    initialDelaySeconds?: int
    periodSeconds?: int
    successThreshold?: int
    timeoutSeconds?: int

schema ValuesStartupProbeHttpGet:
    r"""
    ValuesStartupProbeHttpGet

    Attributes
    ----------
    httpHeaders : [any], optional
    scheme : str, optional, default is "http"
    """
    [...str]: any
    httpHeaders?: [any]
    scheme?: str

schema ValuesStaticLabels:
    r"""
    Log labels to set with static values.
    """
    [...str]: any

schema ValuesStaticLabelsFrom:
    r"""
    Log labels to set with static values, not quoted so it can reference config components.
    """
    [...str]: any

schema ValuesStructuredMetadata:
    r"""
    The structured metadata mappings to set.
    Format: `<key>: <extracted_key>`.
    Example:
    structuredMetadata:
      component: component
      kind: kind
      name: name

    Attributes
    ----------
    "k8s.pod.name" : str, optional, default is "k8s.pod.name"
    name : str, optional, default is "name"
    pod : str, optional, default is "pod"
    "service.instance.id" : str, optional, default is "service.instance.id"
    """
    [...str]: any
    "k8s.pod.name"?: str
    name?: str
    pod?: str
    "service.instance.id"?: str

schema ValuesTempo:
    r"""
    Scrape metrics/logs from Tempo

    Attributes
    ----------
    instances : [any], optional
    """
    [...str]: any
    instances?: [any]

schema ValuesTerminationMessageParams:
    r"""
    Enable or disable container termination message settings
    https://kubernetes.io/docs/tasks/debug/debug-application/determine-reason-pod-failure/

    Attributes
    ----------
    enabled : bool, optional, default is False
    terminationMessagePath : str, optional, default is "/dev/termination-log"
        If enabled, specify the path for termination messages
    terminationMessagePolicy : str, optional, default is "File"
        If enabled, specify the policy for termination messages
    """
    [...str]: any
    enabled?: bool
    terminationMessagePath?: str
    terminationMessagePolicy?: str

schema ValuesTls:
    r"""
    ValuesTls

    Attributes
    ----------
    ca : str, optional
        The CA certificate for the server (as a string).
    caFile : str, optional
        The CA certificate for the server (as a path to a file).
    caFrom : str, optional
        Raw config for accessing the server CA certificate.
    cert : str, optional
        The client certificate for the server (as a string).
    certFile : str, optional
        The client certificate for the server (as a path to a file).
    certFrom : str, optional
        Raw config for accessing the client certificate.
    insecure : bool, optional
        Whether to use TLS for the OTLP destination.
    insecureSkipVerify : bool, optional
        Disables validation of the server certificate.
    key : str, optional
        The client key for the server (as a string).
    keyFile : str, optional
        The client key for the server (as a path to a file).
    keyFrom : str, optional
        Raw config for accessing the client key.
    """
    [...str]: any
    ca?: str
    caFile?: str
    caFrom?: str
    cert?: str
    certFile?: str
    certFrom?: str
    insecure?: bool
    insecureSkipVerify?: bool
    key?: str
    keyFile?: str
    keyFrom?: str

schema ValuesTlsSecret:
    r"""
    # tlsSecret refers to an existing secret holding TLS items: client CA certificate, private key and certificate.
    # secretName and volumeName can be templated.
    # If enabled, volume volumeName gets created on secret secretName.
    # The volume's resources will be used by kube-rbac-proxy if kubeRBACProxy.tls.enabled is set.

    Attributes
    ----------
    caItem : str, optional, default is ""
        # Key with client CA certificate (optional)
    certItem : str, optional, default is "tls.crt"
        # Key with certificate
    enabled : bool, optional, default is False
    keyItem : str, optional, default is "tls.key"
        # Key with private key
    secretName : str, optional, default is "prometheus-node-exporter-tls"
        # Name of an existing secret
    volumeName : str, optional, default is "prometheus-node-exporter-tls"
        # Name of the volume to be created
    """
    [...str]: any
    caItem?: str
    certItem?: str
    enabled?: bool
    keyItem?: str
    secretName?: str
    volumeName?: str

schema ValuesTolerationsItems0:
    r"""
    ValuesTolerationsItems0

    Attributes
    ----------
    effect : str, optional, default is "NoSchedule"
    key : str, optional, default is "node-role.kubernetes.io/control-plane"
    operator : str, optional, default is "Exists"
    """
    [...str]: any
    effect?: str
    key?: str
    operator?: str

schema ValuesTraces:
    r"""
    ValuesTraces

    Attributes
    ----------
    enabled : bool, optional, default is True
        Whether to send traces to the OTLP destination.
    filters : ValuesTracesFilters, optional
        Apply a filter to traces received via the OTLP or OTLP HTTP receivers.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.filter/))
    target : str, optional
        The Alloy component reference for sending traces.
        @ section -- Traces
    transforms : ValuesTracesTransforms, optional
        Apply a transformation to traces received via the OTLP or OTLP HTTP receivers.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.transform/))
    """
    [...str]: any
    enabled?: bool
    filters?: ValuesTracesFilters
    target?: str
    transforms?: ValuesTracesTransforms

schema ValuesTracesFilters:
    r"""
    Apply a filter to traces received via the OTLP or OTLP HTTP receivers.
    ([docs](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.filter/))

    Attributes
    ----------
    span : [any], optional
    spanevent : [any], optional
    """
    [...str]: any
    span?: [any]
    spanevent?: [any]

schema ValuesTracesTransforms:
    r"""
    Apply a transformation to traces received via the OTLP or OTLP HTTP receivers.
    ([docs](https://grafana.com/docs/alloy/latest/reference/components/otelcol/otelcol.processor.transform/))

    Attributes
    ----------
    resource : [any], optional
    span : [any], optional
    spanevent : [any], optional
    """
    [...str]: any
    resource?: [any]
    span?: [any]
    spanevent?: [any]

schema ValuesUpdateStrategy:
    r"""
    # Customize the updateStrategy if set

    Attributes
    ----------
    rollingUpdate : ValuesUpdateStrategyRollingUpdate, optional
    $type : str, optional, default is "RollingUpdate"
        update strategy type
    """
    [...str]: any
    rollingUpdate?: ValuesUpdateStrategyRollingUpdate
    $type?: str

schema ValuesUpdateStrategyRollingUpdate:
    r"""
    ValuesUpdateStrategyRollingUpdate

    Attributes
    ----------
    maxSurge : int, optional, default is 1
    maxUnavailable : int, optional, default is 1
    """
    [...str]: any
    maxSurge?: int
    maxUnavailable?: int

schema ValuesVerticalPodAutoscaler:
    r"""
    Enable vertical pod autoscaler support for prometheus-node-exporter

    Attributes
    ----------
    controlledResources : [any], optional
        List of resources that the vertical pod autoscaler can control. Defaults to cpu and memory
    enabled : bool, optional, default is False
    maxAllowed : ValuesVerticalPodAutoscalerMaxAllowed, optional
        Define the max allowed resources for the pod
    minAllowed : ValuesVerticalPodAutoscalerMinAllowed, optional
        cpu: 200m
        memory: 100Mi
        Define the min allowed resources for the pod
    """
    [...str]: any
    controlledResources?: [any]
    enabled?: bool
    maxAllowed?: ValuesVerticalPodAutoscalerMaxAllowed
    minAllowed?: ValuesVerticalPodAutoscalerMinAllowed

schema ValuesVerticalPodAutoscalerMaxAllowed:
    r"""
    Define the max allowed resources for the pod
    """
    [...str]: any

schema ValuesVerticalPodAutoscalerMinAllowed:
    r"""
    cpu: 200m
    memory: 100Mi
    Define the min allowed resources for the pod
    """
    [...str]: any

schema ValuesVolumeGatherSettings:
    r"""
    Settings specific for gathering Pod logs using the "volumes" gather method.

    Attributes
    ----------
    onlyGatherNewLogLines : bool, optional, default is False
        Only gather new log lines since this was deployed. Do not gather historical log lines.
    """
    [...str]: any
    onlyGatherNewLogLines?: bool

schema ValuesWindowsExporter:
    r"""
    Windows Exporter metrics gathers hardware information about Windows nodes.

    Attributes
    ----------
    config : str, optional, default is "collectors:\n  enabled: cpu,container,logical_disk,memory,net,os\ncollector:\n  service:\n    include: \"containerd|kubelet\""
        Windows Exporter configuration
    deploy : bool, optional, default is True
        Deploy Windows Exporter. Set to false if your cluster already has Windows Exporter deployed.
    enabled : bool, optional, default is True
        Scrape node metrics
    extraDiscoveryRules : str, optional, default is ""
        Rule blocks to be added to the discovery.relabel component for Windows Exporter.
        These relabeling rules are applied pre-scrape against the targets from service discovery.
        Before the scrape, any remaining target labels that start with __ (i.e. __meta_kubernetes*) are dropped.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/discovery/discovery.relabel/#rule-block))
    extraMetricProcessingRules : str, optional, default is ""
        Rule blocks to be added to the prometheus.relabel component for Windows Exporter metrics.
        These relabeling rules are applied post-scrape against the metrics returned from the scraped target, no `__meta*` labels are present.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#rule-block))
    jobLabel : str, optional, default is "integrations/windows-exporter"
        The value for the job label.
    labelMatchers : ValuesWindowsExporterLabelMatchers, optional
        Labels used to select the Windows Exporter pods.
    maxCacheSize : any, optional, default is ""
        Sets the max_cache_size for the Windows Exporter prometheus.relabel component.
        This should be at least 2x-5x your largest scrape target or samples appended rate.
        ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
        Overrides global.maxCacheSize
    metricsTuning : ValuesWindowsExporterMetricsTuning, optional
        Adjustments to the scraped metrics to filter the amount of data sent to storage.
    namespace : str, optional, default is ""
        Namespace to locate Windows Exporter pods. If `deploy` is set to `true`, this will automatically be set to the
        namespace where this Helm chart is deployed.
    podAnnotations : ValuesWindowsExporterPodAnnotations, optional
    releaseLabel : bool, optional, default is True
    scrapeInterval : str, optional, default is ""
        How frequently to scrape metrics from Windows Exporter.
    scrapeTimeout : str, optional, default is ""
        The timeout for scraping Windows Exporter metrics.
    service : ValuesWindowsExporterService, optional
        Windows Exporter service settings
    """
    [...str]: any
    config?: str
    deploy?: bool
    enabled?: bool
    extraDiscoveryRules?: str
    extraMetricProcessingRules?: str
    jobLabel?: str
    labelMatchers?: ValuesWindowsExporterLabelMatchers
    maxCacheSize?: any
    metricsTuning?: ValuesWindowsExporterMetricsTuning
    namespace?: str
    podAnnotations?: ValuesWindowsExporterPodAnnotations
    releaseLabel?: bool
    scrapeInterval?: str
    scrapeTimeout?: str
    service?: ValuesWindowsExporterService

schema ValuesWindowsExporterLabelMatchers:
    r"""
    Labels used to select the Windows Exporter pods.

    Attributes
    ----------
    "app.kubernetes.io/name" : str, optional, default is "windows-exporter"
    """
    [...str]: any
    "app.kubernetes.io/name"?: str

schema ValuesWindowsExporterMetricsTuning:
    r"""
    Adjustments to the scraped metrics to filter the amount of data sent to storage.

    Attributes
    ----------
    excludeMetrics : [any], optional
        Metrics to drop. Can use regular expressions.
    includeMetrics : [any], optional
        Metrics to keep. Can use regular expressions.
    useDefaultAllowList : bool, optional, default is True
        Filter the list of metrics from Windows Exporter to the minimal set required for Kubernetes Monitoring.
    """
    [...str]: any
    excludeMetrics?: [any]
    includeMetrics?: [any]
    useDefaultAllowList?: bool

schema ValuesWindowsExporterPodAnnotations:
    r"""
    ValuesWindowsExporterPodAnnotations

    Attributes
    ----------
    "k8s.grafana.com/logs.job" : str, optional, default is "integrations/windows_exporter"
    """
    [...str]: any
    "k8s.grafana.com/logs.job"?: str

schema ValuesWindowsExporterService:
    r"""
    Windows Exporter service settings

    Attributes
    ----------
    portName : str, optional, default is "metrics"
        The port name used by Windows Exporter.
    """
    [...str]: any
    portName?: str

schema ValuesWriteAheadLog:
    r"""
    Write-Ahead Log (WAL) settings. Only applies when protocol is "remote_write"

    Attributes
    ----------
    maxKeepaliveTime : str, optional
        Maximum time to keep data in the write-ahead log before removing it.
    minKeepaliveTime : str, optional
        Minimum time to keep data in the write-ahead log before it can be removed.
    truncateFrequency : str, optional
        How frequently to clean up the write-ahead log.
    """
    [...str]: any
    maxKeepaliveTime?: str
    minKeepaliveTime?: str
    truncateFrequency?: str

