replicaCount: 1

deployment:
  image:
    repository: quay.io/go-skynet/local-ai
    tag: latest
  env:
    threads: 8
    context_size: 512

resources:
  limits:
    cpu: 8
    memory: 48Gi
  requests:
    cpu: 4
    memory: 48Gi

# Prompt templates to include
# Note: the keys of this map will be the names of the prompt template files
promptTemplates:
  {}
  # ggml-gpt4all-j.tmpl: |
  #   The prompt below is a question to answer, a task to complete, or a conversation to respond to; decide which and write an appropriate response.
  #   ### Prompt:
  #   {{.Input}}
  #   ### Response:

# Models to download at runtime
models:
  # Whether to force download models even if they already exist
  forceDownload: false

  # The list of URLs to download models from
  # Note: the name of the file will be the name of the loaded model
  list:
    - url: "https://gpt4all.io/models/ggml-gpt4all-j.bin"
    - url: "github:go-skynet/model-gallery/stablediffusion.yaml"
    - url: "https://huggingface.co/TheBloke/WizardLM-70B-V1.0-GGML/resolve/main/wizardlm-70b-v1.0.ggmlv3.q5_K_S.bin"
    - url: "https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGML/resolve/main/WizardLM-7B-uncensored.ggmlv3.q8_0.bin"

# Persistent storage for models and prompt templates.
# PVC and HostPath are mutually exclusive. If both are enabled,
# PVC configuration takes precedence. If neither are enabled, ephemeral
# storage is used.
persistence:
  models:
    enabled: true
    storageClass: ceph-block
    accessModes: ReadWriteOnce
    size: 300Gi
  output:
    enabled: true
    storageClass: ceph-block
    accessModes: ReadWriteOnce
    size: 50Gi

ingress:
  enabled: false

nodeSelector: {}
