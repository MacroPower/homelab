apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: observability

helmCharts:
  - name: kube-prometheus-stack
    repo: https://prometheus-community.github.io/helm-charts
    version: 41.9.1
    releaseName: kube-prometheus-stack
    namespace: observability
    includeCRDs: true
    valuesInline:
      global:
        rbac:
          create: true
          createAggregateClusterRoles: true

      grafana:
        enabled: false
        forceDeployDatasources: true
        forceDeployDashboards: true

      kubeStateMetrics:
        enabled: true

      nodeExporter:
        enabled: true

      prometheusOperator:
        admissionWebhooks:
          certManager:
            enabled: true
        prometheusConfigReloader:
          resources:
            requests:
              cpu: 10m
              memory: 50Mi
            limits:
              memory: 50Mi

      prometheus:
        prometheusSpec:
          serviceMonitorSelectorNilUsesHelmValues: false
          serviceMonitorSelector: {}

          podMonitorSelectorNilUsesHelmValues: false
          podMonitorSelector: {}

          probeSelectorNilUsesHelmValues: false
          probeSelector: {}

          # remoteRead:
          #   - url: http://promscale.timescale.svc.cluster.local:9201/read

          # remoteWrite:
          #   - url: http://promscale.timescale.svc.cluster.local:9201/write

          extraArgs:
            enable-feature: exemplar-storage

          resources:
            requests:
              cpu: 500m
              memory: 1496Mi
            limits:
              memory: 1496Mi

          additionalScrapeConfigs:
            - job_name: 'linkerd-controller'
              kubernetes_sd_configs:
                - role: pod
                  namespaces:
                    names:
                      - 'linkerd'
              relabel_configs:
                - source_labels:
                    - __meta_kubernetes_pod_container_port_name
                  action: keep
                  regex: admin-http
                - source_labels: [__meta_kubernetes_pod_container_name]
                  action: replace
                  target_label: component

            - job_name: 'linkerd-service-mirror'
              kubernetes_sd_configs:
                - role: pod
              relabel_configs:
                - source_labels:
                    - __meta_kubernetes_pod_label_linkerd_io_control_plane_component
                    - __meta_kubernetes_pod_container_port_name
                  action: keep
                  regex: linkerd-service-mirror;admin-http$
                - source_labels: [__meta_kubernetes_pod_container_name]
                  action: replace
                  target_label: component

            - job_name: 'linkerd-proxy'
              kubernetes_sd_configs:
                - role: pod
              relabel_configs:
                - source_labels:
                    - __meta_kubernetes_pod_container_name
                    - __meta_kubernetes_pod_container_port_name
                    - __meta_kubernetes_pod_label_linkerd_io_control_plane_ns
                  action: keep
                  regex: ^linkerd-proxy;linkerd-admin;linkerd$
                - source_labels: [__meta_kubernetes_namespace]
                  action: replace
                  target_label: namespace
                - source_labels: [__meta_kubernetes_pod_name]
                  action: replace
                  target_label: pod
                # special case k8s' "job" label, to not interfere with prometheus' "job"
                # label
                # __meta_kubernetes_pod_label_linkerd_io_proxy_job=foo =>
                # k8s_job=foo
                - source_labels:
                    [__meta_kubernetes_pod_label_linkerd_io_proxy_job]
                  action: replace
                  target_label: k8s_job
                # drop __meta_kubernetes_pod_label_linkerd_io_proxy_job
                - action: labeldrop
                  regex: __meta_kubernetes_pod_label_linkerd_io_proxy_job
                # __meta_kubernetes_pod_label_linkerd_io_proxy_deployment=foo =>
                # deployment=foo
                - action: labelmap
                  regex: __meta_kubernetes_pod_label_linkerd_io_proxy_(.+)
                # drop all labels that we just made copies of in the previous labelmap
                - action: labeldrop
                  regex: __meta_kubernetes_pod_label_linkerd_io_proxy_(.+)
                # __meta_kubernetes_pod_label_linkerd_io_foo=bar =>
                # foo=bar
                - action: labelmap
                  regex: __meta_kubernetes_pod_label_linkerd_io_(.+)
                # Copy all pod labels to tmp labels
                - action: labelmap
                  regex: __meta_kubernetes_pod_label_(.+)
                  replacement: __tmp_pod_label_$1
                # Take `linkerd_io_` prefixed labels and copy them without the prefix
                - action: labelmap
                  regex: __tmp_pod_label_linkerd_io_(.+)
                  replacement: __tmp_pod_label_$1
                # Drop the `linkerd_io_` originals
                - action: labeldrop
                  regex: __tmp_pod_label_linkerd_io_(.+)
                # Copy tmp labels into real labels
                - action: labelmap
                  regex: __tmp_pod_label_(.+)

      alertmanager:
        config:
          global:
            resolve_timeout: 5m
          inhibit_rules:
            - source_matchers:
                - 'severity = critical'
              target_matchers:
                - 'severity =~ warning|info'
              equal:
                - 'namespace'
                - 'alertname'
            - source_matchers:
                - 'severity = warning'
              target_matchers:
                - 'severity = info'
              equal:
                - 'namespace'
                - 'alertname'
            - source_matchers:
                - 'alertname = InfoInhibitor'
              target_matchers:
                - 'severity = info'
              equal:
                - 'namespace'
          route:
            group_by: ['namespace']
            group_wait: 30s
            group_interval: 5m
            repeat_interval: 12h
            receiver: 'null'
            routes:
              - receiver: 'null'
                matchers:
                  - alertname =~ "InfoInhibitor|Watchdog"
              - receiver: 'robusta'
                group_by: ['...']
                matchers:
                  - alertname =~ ".+"
                repeat_interval: 4h
                continue: true
          receivers:
            - name: 'null'
            - name: 'robusta'
              webhook_configs:
                - url: 'http://robusta-runner.observability.svc.cluster.local/api/alerts'
                  send_resolved: true
          templates:
            - '/etc/alertmanager/config/*.tmpl'

        alertmanagerSpec:
          resources:
            requests:
              cpu: 50m
              memory: 128Mi
            limits:
              memory: 128Mi

      # # Max series is 10k.
      # prometheus:
      #   prometheusSpec:
      #     remoteWrite:
      #       - url: https://prometheus-us-central1.grafana.net/api/prom/push
      #         basicAuth:
      #           username:
      #             name: grafana-cloud-prom-credentials
      #             key: GRAFANA_PROM_USER
      #           password:
      #             name: grafana-cloud-prom-credentials
      #             key: GRAFANA_PROM_PASS

patches:
  - target:
      group: apiextensions.k8s.io
      version: v1
      kind: CustomResourceDefinition
      name: prometheuses.monitoring.coreos.com
    patch: |-
      - op: add
        path: /metadata/annotations
        value:
          'argocd.argoproj.io/sync-options': 'Replace=true'
